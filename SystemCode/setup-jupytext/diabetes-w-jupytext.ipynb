{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing dependencies\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "\n",
    "#abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3977359aa7f65cc9d96fdf0ede4e99116fb314c6"
   },
   "outputs": [],
   "source": [
    "#Loading the dataset\n",
    "diabetes_data = pd.read_csv('./diabetes.csv')\n",
    "\n",
    "#Print the first 5 rows of the dataframe.\n",
    "diabetes_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8322614f5de4888d713c0468a43ae2a3eb1b8862"
   },
   "outputs": [],
   "source": [
    "## observing the shape of the data --> (#_rows, #_cols)\n",
    "diabetes_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9d9bd9ecd9612fb32f0629a8a3c0a85a14b034cf"
   },
   "outputs": [],
   "source": [
    "X = diabetes_data.drop(\"Outcome\",axis = 1)\n",
    "y = diabetes_data.Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e10c79fe13861fb0fbe714c977f93bb8ed90a5fd"
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f14c88ae0a061de30566d336608d195ba89993d9"
   },
   "outputs": [],
   "source": [
    "%pip install sklearn\n",
    "\n",
    "#importing train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=1/3,random_state=42, stratify=y)\n",
    "\n",
    "# 'test_size' — This parameter decides the size of the data that has to be split as the test dataset. This is given as a fraction\n",
    "# 'random_state' - an integer, which will act as the seed for the random number generator during the split. Setting the random_state is desirable for reproducibility\n",
    "# 'stratify' - makes a split so that the proportion of values in the sample produced will be the same as the proportion of values provided to parameter stratify. For example, if variable y is a binary categorical variable with values 0 and 1 and there are 25% of zeros and 75% of ones, stratify=y will make sure that your random split has 25% of 0's and 75% of 1's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaler() will normalize the features i.e. each column of X, INDIVIDUALLY (!!!) so that each column/feature/variable will have μ = 0 and σ = 1.\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "\n",
    "# Compute the mean and std to be used for later scaling.\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Perform standardization by centering and scaling\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression essentially adapts the linear regression formula to allow it to act as a classifier\n",
    "# Ref: https://towardsdatascience.com/the-basics-logistic-regression-and-regularization-828b0d2d206c\n",
    "\n",
    "# If the logistic regression model used for addressing the binary classification kind of problems it’s known as the binary logistic regression classifier. Whereas the logistic regression model used for multiclassification kind of problems, it’s called the multinomial logistic regression classifier.\n",
    "# - Sigmoid function: used in the logistic regression model for binary classification.\n",
    "# - Softmax function: used in the logistic regression model for multiclassification.\n",
    "\n",
    "# Ref: https://dataaspirant.com/2017/03/14/multinomial-logistic-regression-model-works-machine-learning/\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=0.01).fit(X_train, y_train)\n",
    "\n",
    "# C: Regularization. Regularization is any modification we make to a learning algorithm that is intended to reduce its generalization error but not its training error.\n",
    "# Given how Scikit cites it as being: C = 1/λ. The relationship, would be that lowering C - would strengthen the Lambda regulator.\n",
    "\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.intercept_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.coef_.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "y_pred = logreg.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) \n",
    "\n",
    "# Format of sklearn confusion_matrix:\n",
    "#                  Class Predicted by the model\n",
    "#                  0       1\n",
    "#  Actual  0       150     17\n",
    "#  Class   1       53      36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "print(\"Accuracy=\", metrics.accuracy_score(y_test, y_pred))\n",
    " \n",
    "y_pred_proba = logreg.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "plt.plot(fpr,tpr,label=\"logreg, auc=\"+str(auc))\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gains / Lift Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-plot\n",
    "\n",
    "# Ref: https://www.listendata.com/2014/08/excel-template-gain-and-lift-charts.html\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "y_pred_probas = logreg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_cumulative_gain(y_test, y_pred_probas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_lift_curve(y_test, y_pred_probas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a7081050c51df07b8af1cd18c9be61f041a97fb8"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "test_scores = []\n",
    "train_scores = []\n",
    "\n",
    "for i in range(1,15):\n",
    "\n",
    "    knn = KNeighborsClassifier(i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    \n",
    "    train_scores.append(knn.score(X_train,y_train))\n",
    "    test_scores.append(knn.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ee126a72ca24e54ee78bfac94a21dfac1a3edee1"
   },
   "outputs": [],
   "source": [
    "## score that comes from testing on the same datapoints that were used for training\n",
    "max_train_score = max(train_scores)\n",
    "train_scores_ind = [i for i, v in enumerate(train_scores) if v == max_train_score]\n",
    "print('Max train score {} % and k = {}'.format(max_train_score*100,list(map(lambda x: x+1, train_scores_ind))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8bbfda9d066c354f974dcb1180c3348aaa915c4e"
   },
   "outputs": [],
   "source": [
    "## score that comes from testing on the datapoints that were split in the beginning to be used for testing solely\n",
    "max_test_score = max(test_scores)\n",
    "test_scores_ind = [i for i, v in enumerate(test_scores) if v == max_test_score]\n",
    "print('Max test score {} % and k = {}'.format(max_test_score*100,list(map(lambda x: x+1, test_scores_ind))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fe08768381ea8011d90ae58149c8e41b0a707da2"
   },
   "source": [
    "### K-NN Result Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2a5c0b4fde15148a049fa340a58f5b4fa421e614"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(range(1,15),train_scores,marker='*',label='Train Score')\n",
    "plt.plot(range(1,15),test_scores,marker='o',label='Test Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one compares..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1db31455aba31edc524091fa0914743a284034c5"
   },
   "source": [
    "#### The best result is captured at k = 11 hence 11 is used for the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "277c1bb9c48cca13536ac8ba71604818d323fae0"
   },
   "outputs": [],
   "source": [
    "#Setup a knn classifier with k neighbors\n",
    "knn = KNeighborsClassifier(11)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "knn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ab1e49d83f39a6ddc780c394d3a052b49508c6ac"
   },
   "source": [
    "## Model Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d09044f60af8405e7334c2062404336d0849e871"
   },
   "outputs": [],
   "source": [
    "#import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#let us get the predictions using the classifier we had fit above\n",
    "y_pred = knn.predict(X_test)\n",
    "#confusion_matrix(y_test,y_pred)\n",
    "pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "\n",
    "# Better ways to display Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6ac998149c1f0dd304b807707f0dc44dd2b2ffb3"
   },
   "outputs": [],
   "source": [
    "#import classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "20b2083d2eaf2fca599eb6f2ef8803be0b1ac5d7"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "y_pred_proba = knn.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "379eefad0181f1f57ffbb3634ab6d132af17464f"
   },
   "outputs": [],
   "source": [
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr,tpr, label='Knn')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('Knn(n_neighbors=11) ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6c92773e49532f6133b23d511058202bb77ff2cd"
   },
   "outputs": [],
   "source": [
    "#Area under ROC curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test,y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e369c794253b71d3daa1444fb7d11872fb8a110c"
   },
   "outputs": [],
   "source": [
    "#import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#In case of classifier like knn the parameter to be tuned is n_neighbors\n",
    "param_grid = {'n_neighbors':np.arange(1,50)}\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv= GridSearchCV(knn,param_grid,cv=5)\n",
    "knn_cv.fit(X_train,y_train)\n",
    "\n",
    "print(\"Best Score:\" + str(knn_cv.best_score_))\n",
    "print(\"Best Parameters: \" + str(knn_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naiive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating the Gaussian Classifier\n",
    "mod = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training your model \n",
    "mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting Outcome \n",
    "predicted = mod.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "y_pred = mod.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can compare the performance of multiple models in one ROC chart. Wrtie your own codes in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Logreg\n",
    "logreg_y_pred_proba = logreg.predict_proba(X_test)[::,1]\n",
    "logreg_fpr, logreg_tpr, _ = metrics.roc_curve(y_test,  logreg_y_pred_proba)\n",
    "plt.plot(logreg_fpr,logreg_tpr,label=\"logreg\")\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "\n",
    "\n",
    "# KNN\n",
    "knn = KNeighborsClassifier(19)\n",
    "knn.fit(X_train,y_train)\n",
    "knn_y_pred_proba = knn.predict_proba(X_test)[:,1]\n",
    "knn_fpr, knn_tpr, _ = roc_curve(y_test, knn_y_pred_proba)\n",
    "plt.plot(knn_fpr,knn_tpr,label='Knn')\n",
    "plt.legend(loc=4)\n",
    "plt.title('Different ROC curves')\n",
    "\n",
    "\n",
    "# Naive Bayes\n",
    "mod_y_pred = mod.predict(X_test)\n",
    "mod_fpr, mod_tpr, _ = roc_curve(y_test, mod_y_pred)\n",
    "plt.plot(mod_fpr,mod_tpr,label='Naive Bayes')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.3",
    "jupytext_version": "1.5.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
