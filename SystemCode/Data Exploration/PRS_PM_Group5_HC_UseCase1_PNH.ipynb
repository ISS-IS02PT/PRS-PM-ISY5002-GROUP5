{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parkway Project Use Case 1: Write Off Cases Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', 500)\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "import pickle\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/temp25Oct-Mok-cfc9083c3125ca7ce3bf62e5/PRS-PM-ISY5002-GROUP5/SystemCode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from datapipeline import Datapipeline\n",
    "dpl = Datapipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = './Data Exploration/data/uc1/'\n",
    "dict_X_train_file_paths = {\n",
    "#    'GHL' : [file_dir + 'GHL_new_train_X_uc1.pkl'],\n",
    "#    'MEH' : [file_dir + 'MEH_new_train_X_uc1.pkl'],\n",
    "#    'PEH' : [file_dir + 'PEH_new_train_X_uc1.pkl'],\n",
    "    'PNH' : [file_dir + 'PNH_new_train_X_uc1.pkl']\n",
    "}\n",
    "dict_y_train_file_paths = {\n",
    "    'GHL' : file_dir + 'GHL_data_y_train.pkl',\n",
    "    'MEH' : file_dir + 'MEH_data_y_train.pkl',\n",
    "    'PEH' : file_dir + 'PEH_data_y_train.pkl',\n",
    "    'PNH' : file_dir + 'PNH_data_y_train.pkl'\n",
    "}\n",
    "dict_X_test_file_paths = {\n",
    "    'GHL' : [file_dir + 'GHL_new_test_X_uc1.pkl'],\n",
    "    'MEH' : [file_dir + 'MEH_new_test_X_uc1.pkl'],\n",
    "    'PEH' : [file_dir + 'PEH_new_test_X_uc1.pkl'],\n",
    "    'PNH' : [file_dir + 'PNH_new_test_X_uc1.pkl']\n",
    "}\n",
    "dict_y_test_file_paths = {\n",
    "    'GHL' : file_dir + 'GHL_data_y_test.pkl',\n",
    "    'MEH' : file_dir + 'MEH_data_y_test.pkl',\n",
    "    'PEH' : file_dir + 'PEH_data_y_test.pkl',\n",
    "    'PNH' : file_dir + 'PNH_data_y_test.pkl'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train PNH (79336, 3223)\n",
      "y_train PNH (79336,)\n",
      "X_test PNH (26445, 3223)\n",
      "y_test PNH (26445,)\n"
     ]
    }
   ],
   "source": [
    "dict_df_X_train = {}\n",
    "dict_df_y_train = {}\n",
    "dict_df_X_test = {}\n",
    "dict_df_y_test = {}\n",
    "\n",
    "for hosp in dict_X_train_file_paths:\n",
    "    dict_df_X_train[hosp] = pd.concat([pd.read_pickle(file_path)\n",
    "                                       for file_path in dict_X_train_file_paths[hosp]])\n",
    "    print(f'X_train {hosp} {dict_df_X_train[hosp].shape}')\n",
    "    \n",
    "    dict_df_y_train[hosp] = pd.read_pickle(dict_y_train_file_paths[hosp])\n",
    "    print(f'y_train {hosp} {dict_df_y_train[hosp].shape}')\n",
    "\n",
    "    dict_df_X_test[hosp] = pd.concat([pd.read_pickle(file_path)\n",
    "                                      for file_path in dict_X_test_file_paths[hosp]])\n",
    "    print(f'X_test {hosp} {dict_df_X_test[hosp].shape}')\n",
    "\n",
    "    dict_df_y_test[hosp] = pd.read_pickle(dict_y_test_file_paths[hosp])\n",
    "    print(f'y_test {hosp} {dict_df_y_test[hosp].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def convert_y(df):\n",
    "    df1 = dpl.bin_column(df.to_frame(), col='WRITE_OFF', bin_thresh = [500])\n",
    "    df1 = pd.get_dummies(df1['bin_WRITE_OFF'])\n",
    "    df1 = df1.drop(0, axis=1)\n",
    "    df1.columns = ['WRITE_OFF_LABEL']\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hosp in dict_df_y_train:\n",
    "    dict_df_y_train[hosp] = convert_y(dict_df_y_train[hosp])\n",
    "    dict_df_y_test[hosp] = convert_y(dict_df_y_test[hosp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECISION TREE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree WITHOUT SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "from sklearn.tree import export_graphviz\n",
    "from subprocess import call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = 'entropy'\n",
    "rand_seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
      "Accuracy on PNH training set without SMOTE decision tree: 1.0\n",
      "Accuracy on PNH test set without SMOTE decision tree: 0.9984117980714691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_no_smote_dt_model.pkl'>\n",
      "  if __name__ == '__main__':\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH decision tree\n",
      " [[26382    16]\n",
      " [   26    21]]\n",
      "PNH decision tree\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.57      0.45      0.50        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.78      0.72      0.75     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for hosp in dict_df_X_train:\n",
    "    model = DecisionTreeClassifier(criterion=criterion,random_state=rand_seed)\n",
    "    model.fit(dict_df_X_train[hosp], dict_df_y_train[hosp])\n",
    "    print(model)\n",
    "    print(f\"Accuracy on {hosp} training set without SMOTE decision tree: {model.score(dict_df_X_train[hosp], dict_df_y_train[hosp])}\")\n",
    "    print(f\"Accuracy on {hosp} test set without SMOTE decision tree: {model.score(dict_df_X_test[hosp], dict_df_y_test[hosp])}\")\n",
    "    \n",
    "    filename = file_dir + f'{hosp}_uc1_no_smote_dt_model.pkl'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    \n",
    "    y_pred = model.predict(dict_df_X_test[hosp])\n",
    "    print(hosp, 'decision tree\\n', confusion_matrix(dict_df_y_test[hosp], y_pred))  \n",
    "    print(hosp, 'decision tree\\n', classification_report(dict_df_y_test[hosp], y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree WITH SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree WITH SMOTE SS = 0.1 ~ 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
      "Accuracy on PNH training set with 0.1 SMOTE decision tree: 1.0\n",
      "Accuracy on PNH test set with 0.1 SMOTE decision tree: 0.9974664397806768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.1_smote_dt_model.pkl'>\n",
      "  del sys.path[0]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH decision tree \n",
      " [[26362    36]\n",
      " [   31    16]]\n",
      "PNH decision tree \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.31      0.34      0.32        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.65      0.67      0.66     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n",
      "DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
      "Accuracy on PNH training set with 0.2 SMOTE decision tree: 1.0\n",
      "Accuracy on PNH test set with 0.2 SMOTE decision tree: 0.997693325770467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.2_smote_dt_model.pkl'>\n",
      "  del sys.path[0]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH decision tree \n",
      " [[26368    30]\n",
      " [   31    16]]\n",
      "PNH decision tree \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.35      0.34      0.34        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.67      0.67      0.67     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n",
      "DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
      "Accuracy on PNH training set with 0.30000000000000004 SMOTE decision tree: 1.0\n",
      "Accuracy on PNH test set with 0.30000000000000004 SMOTE decision tree: 0.997579882775572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.30000000000000004_smote_dt_model.pkl'>\n",
      "  del sys.path[0]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH decision tree \n",
      " [[26363    35]\n",
      " [   29    18]]\n",
      "PNH decision tree \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.34      0.38      0.36        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.67      0.69      0.68     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n",
      "DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
      "Accuracy on PNH training set with 0.4 SMOTE decision tree: 1.0\n",
      "Accuracy on PNH test set with 0.4 SMOTE decision tree: 0.9978823974286255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.4_smote_dt_model.pkl'>\n",
      "  del sys.path[0]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH decision tree \n",
      " [[26371    27]\n",
      " [   29    18]]\n",
      "PNH decision tree \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.40      0.38      0.39        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.70      0.69      0.70     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n",
      "DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
      "Accuracy on PNH training set with 0.5 SMOTE decision tree: 1.0\n",
      "Accuracy on PNH test set with 0.5 SMOTE decision tree: 0.9976176971072036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.5_smote_dt_model.pkl'>\n",
      "  del sys.path[0]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH decision tree \n",
      " [[26366    32]\n",
      " [   31    16]]\n",
      "PNH decision tree \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.33      0.34      0.34        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.67      0.67      0.67     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n",
      "DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
      "Accuracy on PNH training set with 0.6 SMOTE decision tree: 1.0\n",
      "Accuracy on PNH test set with 0.6 SMOTE decision tree: 0.9973908111174135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.6_smote_dt_model.pkl'>\n",
      "  del sys.path[0]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH decision tree \n",
      " [[26357    41]\n",
      " [   28    19]]\n",
      "PNH decision tree \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.32      0.40      0.36        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.66      0.70      0.68     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n",
      "DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
      "Accuracy on PNH training set with 0.7000000000000001 SMOTE decision tree: 1.0\n",
      "Accuracy on PNH test set with 0.7000000000000001 SMOTE decision tree: 0.9974664397806768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.7000000000000001_smote_dt_model.pkl'>\n",
      "  del sys.path[0]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH decision tree \n",
      " [[26358    40]\n",
      " [   27    20]]\n",
      "PNH decision tree \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.33      0.43      0.37        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.67      0.71      0.69     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n",
      "DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
      "Accuracy on PNH training set with 0.8 SMOTE decision tree: 1.0\n",
      "Accuracy on PNH test set with 0.8 SMOTE decision tree: 0.9977311401020987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.8_smote_dt_model.pkl'>\n",
      "  del sys.path[0]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH decision tree \n",
      " [[26365    33]\n",
      " [   27    20]]\n",
      "PNH decision tree \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.38      0.43      0.40        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.69      0.71      0.70     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n",
      "DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
      "Accuracy on PNH training set with 0.9 SMOTE decision tree: 1.0\n",
      "Accuracy on PNH test set with 0.9 SMOTE decision tree: 0.997579882775572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.9_smote_dt_model.pkl'>\n",
      "  del sys.path[0]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH decision tree \n",
      " [[26364    34]\n",
      " [   30    17]]\n",
      "PNH decision tree \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.33      0.36      0.35        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.67      0.68      0.67     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n",
      "DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
      "Accuracy on PNH training set with 1.0 SMOTE decision tree: 1.0\n",
      "Accuracy on PNH test set with 1.0 SMOTE decision tree: 0.9974286254490452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_1.0_smote_dt_model.pkl'>\n",
      "  del sys.path[0]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH decision tree \n",
      " [[26357    41]\n",
      " [   27    20]]\n",
      "PNH decision tree \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.33      0.43      0.37        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.66      0.71      0.68     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for hosp in dict_df_X_train:\n",
    "    for sample in np.arange(0.1, 1.1, 0.1):\n",
    "        sm_ss = SMOTE(random_state=55,sampling_strategy=sample)\n",
    "        X_train_ss, y_train_ss = sm_ss.fit_sample(dict_df_X_train[hosp], dict_df_y_train[hosp])\n",
    "        \n",
    "        model = DecisionTreeClassifier(criterion=criterion,random_state=rand_seed)\n",
    "        model.fit(X_train_ss, y_train_ss)\n",
    "        print(model)\n",
    "        print(f\"Accuracy on {hosp} training set with {sample} SMOTE decision tree: {model.score(X_train_ss, y_train_ss)}\")\n",
    "        print(f\"Accuracy on {hosp} test set with {sample} SMOTE decision tree: {model.score(dict_df_X_test[hosp], dict_df_y_test[hosp])}\")\n",
    "    \n",
    "        filename = file_dir + f'{hosp}_uc1_{sample}_smote_dt_model.pkl'\n",
    "        pickle.dump(model, open(filename, 'wb'))\n",
    "        \n",
    "        y_pred = model.predict(dict_df_X_test[hosp])\n",
    "        print(hosp, 'decision tree \\n', confusion_matrix(dict_df_y_test[hosp], y_pred))  \n",
    "        print(hosp, 'decision tree \\n', classification_report(dict_df_y_test[hosp], y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_strength = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01)\n",
      "PNH Training set without SMOTE log reg score: 0.9983109811434909\n",
      "PNH Test set without SMOTE log reg score: 0.9981849120816789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_no_smote_logreg_model.pkl'>\n",
      "  \n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH log reg \n",
      " [[26397     1]\n",
      " [   47     0]]\n",
      "PNH log reg \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.50      0.50      0.50     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for hosp in dict_df_X_train:\n",
    "    model = LogisticRegression(C=reg_strength).fit(dict_df_X_train[hosp], dict_df_y_train[hosp])\n",
    "    print(model)\n",
    "    print(f\"{hosp} Training set without SMOTE log reg score: {model.score(dict_df_X_train[hosp], dict_df_y_train[hosp])}\")\n",
    "    print(f\"{hosp} Test set without SMOTE log reg score: {model.score(dict_df_X_test[hosp], dict_df_y_test[hosp])}\")\n",
    "    \n",
    "    filename = file_dir + f'{hosp}_uc1_no_smote_logreg_model.pkl'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    \n",
    "    y_pred = model.predict(dict_df_X_test[hosp])\n",
    "    print(hosp, 'log reg \\n', confusion_matrix(dict_df_y_test[hosp], y_pred))  \n",
    "    print(hosp, 'log reg \\n', classification_report(dict_df_y_test[hosp], y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression With SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression With SMOTE ss=0.1 ~ 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01)\n",
      "PNH Training set with 0.1 SMOTE log reg score: 0.9679526176237646\n",
      "PNH Test set with 0.1 SMOTE log reg score: 0.9951975798827756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.1_smote_logreg_model.pkl'>\n",
      "  if sys.path[0] == '':\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH log reg \n",
      " [[26288   110]\n",
      " [   17    30]]\n",
      "PNH log reg \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.21      0.64      0.32        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.61      0.82      0.66     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01)\n",
      "PNH Training set with 0.2 SMOTE log reg score: 0.9658568407318947\n",
      "PNH Test set with 0.2 SMOTE log reg score: 0.9934581206277179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.2_smote_logreg_model.pkl'>\n",
      "  if sys.path[0] == '':\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH log reg \n",
      " [[26242   156]\n",
      " [   17    30]]\n",
      "PNH log reg \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     26398\n",
      "           1       0.16      0.64      0.26        47\n",
      "\n",
      "    accuracy                           0.99     26445\n",
      "   macro avg       0.58      0.82      0.63     26445\n",
      "weighted avg       1.00      0.99      1.00     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01)\n",
      "PNH Training set with 0.30000000000000004 SMOTE log reg score: 0.975291615271802\n",
      "PNH Test set with 0.30000000000000004 SMOTE log reg score: 0.9916430327093969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.30000000000000004_smote_logreg_model.pkl'>\n",
      "  if sys.path[0] == '':\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH log reg \n",
      " [[26194   204]\n",
      " [   17    30]]\n",
      "PNH log reg \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     26398\n",
      "           1       0.13      0.64      0.21        47\n",
      "\n",
      "    accuracy                           0.99     26445\n",
      "   macro avg       0.56      0.82      0.60     26445\n",
      "weighted avg       1.00      0.99      0.99     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01)\n",
      "PNH Training set with 0.4 SMOTE log reg score: 0.9790766677789703\n",
      "PNH Test set with 0.4 SMOTE log reg score: 0.9897523161278124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.4_smote_logreg_model.pkl'>\n",
      "  if sys.path[0] == '':\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH log reg \n",
      " [[26144   254]\n",
      " [   17    30]]\n",
      "PNH log reg \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     26398\n",
      "           1       0.11      0.64      0.18        47\n",
      "\n",
      "    accuracy                           0.99     26445\n",
      "   macro avg       0.55      0.81      0.59     26445\n",
      "weighted avg       1.00      0.99      0.99     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01)\n",
      "PNH Training set with 0.5 SMOTE log reg score: 0.9816163163609734\n",
      "PNH Test set with 0.5 SMOTE log reg score: 0.9877859708829646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.5_smote_logreg_model.pkl'>\n",
      "  if sys.path[0] == '':\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH log reg \n",
      " [[26092   306]\n",
      " [   17    30]]\n",
      "PNH log reg \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     26398\n",
      "           1       0.09      0.64      0.16        47\n",
      "\n",
      "    accuracy                           0.99     26445\n",
      "   macro avg       0.54      0.81      0.58     26445\n",
      "weighted avg       1.00      0.99      0.99     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01)\n",
      "PNH Training set with 0.6 SMOTE log reg score: 0.9849196265812297\n",
      "PNH Test set with 0.6 SMOTE log reg score: 0.9867271695972774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.6_smote_logreg_model.pkl'>\n",
      "  if sys.path[0] == '':\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH log reg \n",
      " [[26064   334]\n",
      " [   17    30]]\n",
      "PNH log reg \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     26398\n",
      "           1       0.08      0.64      0.15        47\n",
      "\n",
      "    accuracy                           0.99     26445\n",
      "   macro avg       0.54      0.81      0.57     26445\n",
      "weighted avg       1.00      0.99      0.99     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01)\n",
      "PNH Training set with 0.7000000000000001 SMOTE log reg score: 0.9867945128155614\n",
      "PNH Test set with 0.7000000000000001 SMOTE log reg score: 0.9849877103422197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.7000000000000001_smote_logreg_model.pkl'>\n",
      "  if sys.path[0] == '':\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH log reg \n",
      " [[26018   380]\n",
      " [   17    30]]\n",
      "PNH log reg \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     26398\n",
      "           1       0.07      0.64      0.13        47\n",
      "\n",
      "    accuracy                           0.98     26445\n",
      "   macro avg       0.54      0.81      0.56     26445\n",
      "weighted avg       1.00      0.98      0.99     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01)\n",
      "PNH Training set with 0.8 SMOTE log reg score: 0.9889029959105226\n",
      "PNH Test set with 0.8 SMOTE log reg score: 0.9831726224238987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.8_smote_logreg_model.pkl'>\n",
      "  if sys.path[0] == '':\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH log reg \n",
      " [[25970   428]\n",
      " [   17    30]]\n",
      "PNH log reg \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     26398\n",
      "           1       0.07      0.64      0.12        47\n",
      "\n",
      "    accuracy                           0.98     26445\n",
      "   macro avg       0.53      0.81      0.56     26445\n",
      "weighted avg       1.00      0.98      0.99     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01)\n",
      "PNH Training set with 0.9 SMOTE log reg score: 0.9895202716622032\n",
      "PNH Test set with 0.9 SMOTE log reg score: 0.9819625638116847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.9_smote_logreg_model.pkl'>\n",
      "  if sys.path[0] == '':\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH log reg \n",
      " [[25938   460]\n",
      " [   17    30]]\n",
      "PNH log reg \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     26398\n",
      "           1       0.06      0.64      0.11        47\n",
      "\n",
      "    accuracy                           0.98     26445\n",
      "   macro avg       0.53      0.81      0.55     26445\n",
      "weighted avg       1.00      0.98      0.99     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01)\n",
      "PNH Training set with 1.0 SMOTE log reg score: 0.989892804383783\n",
      "PNH Test set with 1.0 SMOTE log reg score: 0.9809415768576291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_1.0_smote_logreg_model.pkl'>\n",
      "  if sys.path[0] == '':\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH log reg \n",
      " [[25911   487]\n",
      " [   17    30]]\n",
      "PNH log reg \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     26398\n",
      "           1       0.06      0.64      0.11        47\n",
      "\n",
      "    accuracy                           0.98     26445\n",
      "   macro avg       0.53      0.81      0.55     26445\n",
      "weighted avg       1.00      0.98      0.99     26445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for hosp in dict_df_X_train:\n",
    "    for sample in np.arange(0.1, 1.1, 0.1):\n",
    "        sm_ss = SMOTE(random_state=55,sampling_strategy=sample)\n",
    "        X_train_ss, y_train_ss = sm_ss.fit_sample(dict_df_X_train[hosp], dict_df_y_train[hosp])\n",
    "        \n",
    "        model = LogisticRegression(C=reg_strength).fit(X_train_ss, y_train_ss)\n",
    "        print(model)\n",
    "        print(f\"{hosp} Training set with {sample} SMOTE log reg score: {model.score(X_train_ss, y_train_ss)}\")\n",
    "        print(f\"{hosp} Test set with {sample} SMOTE log reg score: {model.score(dict_df_X_test[hosp], dict_df_y_test[hosp])}\")\n",
    "\n",
    "        filename = file_dir + f'{hosp}_uc1_{sample}_smote_logreg_model.pkl'\n",
    "        pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "        y_pred = model.predict(dict_df_X_test[hosp])\n",
    "        print(hosp, 'log reg \\n', confusion_matrix(dict_df_y_test[hosp], y_pred))  \n",
    "        print(hosp, 'log reg \\n', classification_report(dict_df_y_test[hosp], y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAIVE BAYES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_no_smote_nb_model.pkl'>\n",
      "  if __name__ == '__main__':\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set without SMOTE Naive Bayes score: 0.9658162750831905\n",
      "PNH Test set without SMOTE Naive Bayes score: 0.9656267725467952\n",
      "PNH Naive Bayes \n",
      " [[25526   872]\n",
      " [   37    10]]\n",
      "PNH Naive Bayes \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     26398\n",
      "           1       0.01      0.21      0.02        47\n",
      "\n",
      "    accuracy                           0.97     26445\n",
      "   macro avg       0.50      0.59      0.50     26445\n",
      "weighted avg       1.00      0.97      0.98     26445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for hosp in dict_df_X_train:\n",
    "    # Initiating the Gaussian Classifier\n",
    "    model = GaussianNB()\n",
    "\n",
    "    # Training your model \n",
    "    model.fit(dict_df_X_train[hosp], dict_df_y_train[hosp])\n",
    "    print(model)\n",
    "    filename = file_dir + f'{hosp}_uc1_no_smote_nb_model.pkl'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "    # Score\n",
    "    print(f\"{hosp} Training set without SMOTE Naive Bayes score: {model.score(dict_df_X_train[hosp], dict_df_y_train[hosp])}\")\n",
    "    print(f\"{hosp} Test set without SMOTE Naive Bayes score: {model.score(dict_df_X_test[hosp], dict_df_y_test[hosp])}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    y_pred = model.predict(dict_df_X_test[hosp])\n",
    "    print(hosp, 'Naive Bayes \\n', confusion_matrix(dict_df_y_test[hosp], y_pred))  \n",
    "    print(hosp, 'Naive Bayes \\n', classification_report(dict_df_y_test[hosp], y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes With SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Without SMOTE ss=0.1 ~ 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.1_smote_nb_model.pkl'>\n",
      "  del sys.path[0]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set with 0.1 SMOTE Naive Bayes score: 0.9688708807291009\n",
      "PNH Test set with 0.1 SMOTE Naive Bayes score: 0.9656267725467952\n",
      "PNH Naive Bayes\n",
      " [[25526   872]\n",
      " [   37    10]]\n",
      "PNH Naive Bayes\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     26398\n",
      "           1       0.01      0.21      0.02        47\n",
      "\n",
      "    accuracy                           0.97     26445\n",
      "   macro avg       0.50      0.59      0.50     26445\n",
      "weighted avg       1.00      0.97      0.98     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.2_smote_nb_model.pkl'>\n",
      "  del sys.path[0]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set with 0.2 SMOTE Naive Bayes score: 0.9714649467072106\n",
      "PNH Test set with 0.2 SMOTE Naive Bayes score: 0.9656267725467952\n",
      "PNH Naive Bayes\n",
      " [[25526   872]\n",
      " [   37    10]]\n",
      "PNH Naive Bayes\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     26398\n",
      "           1       0.01      0.21      0.02        47\n",
      "\n",
      "    accuracy                           0.97     26445\n",
      "   macro avg       0.50      0.59      0.50     26445\n",
      "weighted avg       1.00      0.97      0.98     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.30000000000000004_smote_nb_model.pkl'>\n",
      "  del sys.path[0]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set with 0.30000000000000004 SMOTE Naive Bayes score: 0.9736599294878643\n",
      "PNH Test set with 0.30000000000000004 SMOTE Naive Bayes score: 0.9656267725467952\n",
      "PNH Naive Bayes\n",
      " [[25526   872]\n",
      " [   37    10]]\n",
      "PNH Naive Bayes\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     26398\n",
      "           1       0.01      0.21      0.02        47\n",
      "\n",
      "    accuracy                           0.97     26445\n",
      "   macro avg       0.50      0.59      0.50     26445\n",
      "weighted avg       1.00      0.97      0.98     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.4_smote_nb_model.pkl'>\n",
      "  del sys.path[0]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set with 0.4 SMOTE Naive Bayes score: 0.9755413461278307\n",
      "PNH Test set with 0.4 SMOTE Naive Bayes score: 0.9656267725467952\n",
      "PNH Naive Bayes\n",
      " [[25526   872]\n",
      " [   37    10]]\n",
      "PNH Naive Bayes\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     26398\n",
      "           1       0.01      0.21      0.02        47\n",
      "\n",
      "    accuracy                           0.97     26445\n",
      "   macro avg       0.50      0.59      0.50     26445\n",
      "weighted avg       1.00      0.97      0.98     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.5_smote_nb_model.pkl'>\n",
      "  del sys.path[0]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set with 0.5 SMOTE Naive Bayes score: 0.9771719093273625\n",
      "PNH Test set with 0.5 SMOTE Naive Bayes score: 0.9656267725467952\n",
      "PNH Naive Bayes\n",
      " [[25526   872]\n",
      " [   37    10]]\n",
      "PNH Naive Bayes\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     26398\n",
      "           1       0.01      0.21      0.02        47\n",
      "\n",
      "    accuracy                           0.97     26445\n",
      "   macro avg       0.50      0.59      0.50     26445\n",
      "weighted avg       1.00      0.97      0.98     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.6_smote_nb_model.pkl'>\n",
      "  del sys.path[0]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set with 0.6 SMOTE Naive Bayes score: 0.9785986537353714\n",
      "PNH Test set with 0.6 SMOTE Naive Bayes score: 0.9656267725467952\n",
      "PNH Naive Bayes\n",
      " [[25526   872]\n",
      " [   37    10]]\n",
      "PNH Naive Bayes\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     26398\n",
      "           1       0.01      0.21      0.02        47\n",
      "\n",
      "    accuracy                           0.97     26445\n",
      "   macro avg       0.50      0.59      0.50     26445\n",
      "weighted avg       1.00      0.97      0.98     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.7000000000000001_smote_nb_model.pkl'>\n",
      "  del sys.path[0]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set with 0.7000000000000001 SMOTE Naive Bayes score: 0.9798575471067505\n",
      "PNH Test set with 0.7000000000000001 SMOTE Naive Bayes score: 0.9656267725467952\n",
      "PNH Naive Bayes\n",
      " [[25526   872]\n",
      " [   37    10]]\n",
      "PNH Naive Bayes\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     26398\n",
      "           1       0.01      0.21      0.02        47\n",
      "\n",
      "    accuracy                           0.97     26445\n",
      "   macro avg       0.50      0.59      0.50     26445\n",
      "weighted avg       1.00      0.97      0.98     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.8_smote_nb_model.pkl'>\n",
      "  del sys.path[0]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set with 0.8 SMOTE Naive Bayes score: 0.9809765644180386\n",
      "PNH Test set with 0.8 SMOTE Naive Bayes score: 0.9656267725467952\n",
      "PNH Naive Bayes\n",
      " [[25526   872]\n",
      " [   37    10]]\n",
      "PNH Naive Bayes\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     26398\n",
      "           1       0.01      0.21      0.02        47\n",
      "\n",
      "    accuracy                           0.97     26445\n",
      "   macro avg       0.50      0.59      0.50     26445\n",
      "weighted avg       1.00      0.97      0.98     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.9_smote_nb_model.pkl'>\n",
      "  del sys.path[0]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set with 0.9 SMOTE Naive Bayes score: 0.9819777912161668\n",
      "PNH Test set with 0.9 SMOTE Naive Bayes score: 0.9656267725467952\n",
      "PNH Naive Bayes\n",
      " [[25526   872]\n",
      " [   37    10]]\n",
      "PNH Naive Bayes\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     26398\n",
      "           1       0.01      0.21      0.02        47\n",
      "\n",
      "    accuracy                           0.97     26445\n",
      "   macro avg       0.50      0.59      0.50     26445\n",
      "weighted avg       1.00      0.97      0.98     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_1.0_smote_nb_model.pkl'>\n",
      "  del sys.path[0]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set with 1.0 SMOTE Naive Bayes score: 0.9828790040529791\n",
      "PNH Test set with 1.0 SMOTE Naive Bayes score: 0.9656267725467952\n",
      "PNH Naive Bayes\n",
      " [[25526   872]\n",
      " [   37    10]]\n",
      "PNH Naive Bayes\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     26398\n",
      "           1       0.01      0.21      0.02        47\n",
      "\n",
      "    accuracy                           0.97     26445\n",
      "   macro avg       0.50      0.59      0.50     26445\n",
      "weighted avg       1.00      0.97      0.98     26445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for hosp in dict_df_X_train:\n",
    "    for sample in np.arange(0.1, 1.1, 0.1):\n",
    "        sm_ss = SMOTE(random_state=55,sampling_strategy=sample)\n",
    "        X_train_ss, y_train_ss = sm_ss.fit_sample(dict_df_X_train[hosp], dict_df_y_train[hosp])\n",
    "        \n",
    "        # Initiating the Gaussian Classifier\n",
    "        model = GaussianNB()\n",
    "        \n",
    "        # Training your model \n",
    "        model.fit(X_train_ss, y_train_ss)\n",
    "        print(model)\n",
    "        filename = file_dir + f'{hosp}_uc1_{sample}_smote_nb_model.pkl'\n",
    "        pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "        # Score\n",
    "        print(f\"{hosp} Training set with {sample} SMOTE Naive Bayes score: {model.score(X_train_ss, y_train_ss)}\")\n",
    "        print(f\"{hosp} Test set with {sample} SMOTE Naive Bayes score: {model.score(dict_df_X_test[hosp], dict_df_y_test[hosp])}\")\n",
    "\n",
    "        # Confusion Matrix\n",
    "        y_pred = model.predict(dict_df_X_test[hosp])\n",
    "        print(hosp, 'Naive Bayes\\n', confusion_matrix(dict_df_y_test[hosp], y_pred))  \n",
    "        print(hosp, 'Naive Bayes\\n', classification_report(dict_df_y_test[hosp], y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## NEURAL NET MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net MLP Without SMOTE, 2 Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier  \n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_hid_layers = [(128,128), (16,16,16), (32,32,32), (16,16,16,16), (32,32,32,32)]\n",
    "max_iter = 1000\n",
    "list_smote_sampling = [0.1, 0.2, 0.3, 0.5, 1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net MLPClassifier without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.02369188\n",
      "Iteration 2, loss = 0.00664379\n",
      "Iteration 3, loss = 0.00498875\n",
      "Iteration 4, loss = 0.00366666\n",
      "Iteration 5, loss = 0.00275576\n",
      "Iteration 6, loss = 0.00217786\n",
      "Iteration 7, loss = 0.00232103\n",
      "Iteration 8, loss = 0.00137605\n",
      "Iteration 9, loss = 0.00117535\n",
      "Iteration 10, loss = 0.00080757\n",
      "Iteration 11, loss = 0.00058167\n",
      "Iteration 12, loss = 0.00084741\n",
      "Iteration 13, loss = 0.00056601\n",
      "Iteration 14, loss = 0.00046697\n",
      "Iteration 15, loss = 0.00081881\n",
      "Iteration 16, loss = 0.00040922\n",
      "Iteration 17, loss = 0.00033487\n",
      "Iteration 18, loss = 0.00039387\n",
      "Iteration 19, loss = 0.00036052\n",
      "Iteration 20, loss = 0.00036214\n",
      "Iteration 21, loss = 0.00035305\n",
      "Iteration 22, loss = 0.00112150\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "MLPClassifier(hidden_layer_sizes=(128, 128), max_iter=1000, verbose=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_no_smote_mlp_(128, 128)_model.pkl'>\n",
      "  import sys\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set without SMOTE mlp (128, 128) score: 0.9997857214883533\n",
      "PNH Test set without SMOTE mlp (128, 128) score: 0.9984117980714691\n",
      "PNH Accuracy without SMOTE mlp (128, 128):  0.9984117980714691\n",
      "PNH mlp (128, 128)\n",
      " [[26391     7]\n",
      " [   35    12]]\n",
      "PNH mlp (128, 128)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.63      0.26      0.36        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.82      0.63      0.68     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.05109059\n",
      "Iteration 2, loss = 0.00725010\n",
      "Iteration 3, loss = 0.00602842\n",
      "Iteration 4, loss = 0.00509317\n",
      "Iteration 5, loss = 0.00424239\n",
      "Iteration 6, loss = 0.00355333\n",
      "Iteration 7, loss = 0.00307851\n",
      "Iteration 8, loss = 0.00266303\n",
      "Iteration 9, loss = 0.00219980\n",
      "Iteration 10, loss = 0.00192851\n",
      "Iteration 11, loss = 0.00161106\n",
      "Iteration 12, loss = 0.00135239\n",
      "Iteration 13, loss = 0.00111942\n",
      "Iteration 14, loss = 0.00109358\n",
      "Iteration 15, loss = 0.00081793\n",
      "Iteration 16, loss = 0.00101612\n",
      "Iteration 17, loss = 0.00045356\n",
      "Iteration 18, loss = 0.00042350\n",
      "Iteration 19, loss = 0.00039109\n",
      "Iteration 20, loss = 0.00043874\n",
      "Iteration 21, loss = 0.00050547\n",
      "Iteration 22, loss = 0.00037064\n",
      "Iteration 23, loss = 0.00040339\n",
      "Iteration 24, loss = 0.00058352\n",
      "Iteration 25, loss = 0.00040187\n",
      "Iteration 26, loss = 0.00030070\n",
      "Iteration 27, loss = 0.00025138\n",
      "Iteration 28, loss = 0.00025708\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "MLPClassifier(hidden_layer_sizes=(16, 16, 16), max_iter=1000, verbose=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_no_smote_mlp_(16, 16, 16)_model.pkl'>\n",
      "  import sys\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set without SMOTE mlp (16, 16, 16) score: 0.9999369769083393\n",
      "PNH Test set without SMOTE mlp (16, 16, 16) score: 0.9982227264133107\n",
      "PNH Accuracy without SMOTE mlp (16, 16, 16):  0.9982227264133107\n",
      "PNH mlp (16, 16, 16)\n",
      " [[26381    17]\n",
      " [   30    17]]\n",
      "PNH mlp (16, 16, 16)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.50      0.36      0.42        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.75      0.68      0.71     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.06717221\n",
      "Iteration 2, loss = 0.00724820\n",
      "Iteration 3, loss = 0.00576207\n",
      "Iteration 4, loss = 0.00455513\n",
      "Iteration 5, loss = 0.00347153\n",
      "Iteration 6, loss = 0.00292290\n",
      "Iteration 7, loss = 0.00199152\n",
      "Iteration 8, loss = 0.00167774\n",
      "Iteration 9, loss = 0.00131542\n",
      "Iteration 10, loss = 0.00098891\n",
      "Iteration 11, loss = 0.00111659\n",
      "Iteration 12, loss = 0.00075074\n",
      "Iteration 13, loss = 0.00092687\n",
      "Iteration 14, loss = 0.00052950\n",
      "Iteration 15, loss = 0.00053690\n",
      "Iteration 16, loss = 0.00034217\n",
      "Iteration 17, loss = 0.00037948\n",
      "Iteration 18, loss = 0.00036652\n",
      "Iteration 19, loss = 0.00036555\n",
      "Iteration 20, loss = 0.00070785\n",
      "Iteration 21, loss = 0.00054721\n",
      "Iteration 22, loss = 0.00053896\n",
      "Iteration 23, loss = 0.00022628\n",
      "Iteration 24, loss = 0.00017919\n",
      "Iteration 25, loss = 0.00025731\n",
      "Iteration 26, loss = 0.00088166\n",
      "Iteration 27, loss = 0.00024045\n",
      "Iteration 28, loss = 0.00022129\n",
      "Iteration 29, loss = 0.00019081\n",
      "Iteration 30, loss = 0.00015865\n",
      "Iteration 31, loss = 0.00064548\n",
      "Iteration 32, loss = 0.00058195\n",
      "Iteration 33, loss = 0.00029204\n",
      "Iteration 34, loss = 0.00013759\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "MLPClassifier(hidden_layer_sizes=(32, 32, 32), max_iter=1000, verbose=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_no_smote_mlp_(32, 32, 32)_model.pkl'>\n",
      "  import sys\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set without SMOTE mlp (32, 32, 32) score: 0.9999747907633357\n",
      "PNH Test set without SMOTE mlp (32, 32, 32) score: 0.9983361694082057\n",
      "PNH Accuracy without SMOTE mlp (32, 32, 32):  0.9983361694082057\n",
      "PNH mlp (32, 32, 32)\n",
      " [[26382    16]\n",
      " [   28    19]]\n",
      "PNH mlp (32, 32, 32)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.54      0.40      0.46        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.77      0.70      0.73     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.05809656\n",
      "Iteration 2, loss = 0.00771041\n",
      "Iteration 3, loss = 0.00649975\n",
      "Iteration 4, loss = 0.00543666\n",
      "Iteration 5, loss = 0.00459593\n",
      "Iteration 6, loss = 0.00357642\n",
      "Iteration 7, loss = 0.00278899\n",
      "Iteration 8, loss = 0.00219075\n",
      "Iteration 9, loss = 0.00207529\n",
      "Iteration 10, loss = 0.00130553\n",
      "Iteration 11, loss = 0.00102010\n",
      "Iteration 12, loss = 0.00092473\n",
      "Iteration 13, loss = 0.00123128\n",
      "Iteration 14, loss = 0.00060406\n",
      "Iteration 15, loss = 0.00059035\n",
      "Iteration 16, loss = 0.00074491\n",
      "Iteration 17, loss = 0.00061163\n",
      "Iteration 18, loss = 0.00053008\n",
      "Iteration 19, loss = 0.00039305\n",
      "Iteration 20, loss = 0.00033718\n",
      "Iteration 21, loss = 0.00030737\n",
      "Iteration 22, loss = 0.00081947\n",
      "Iteration 23, loss = 0.00068797\n",
      "Iteration 24, loss = 0.00041764\n",
      "Iteration 25, loss = 0.00026378\n",
      "Iteration 26, loss = 0.00017497\n",
      "Iteration 27, loss = 0.00029823\n",
      "Iteration 28, loss = 0.00020179\n",
      "Iteration 29, loss = 0.00017434\n",
      "Iteration 30, loss = 0.00019846\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "MLPClassifier(hidden_layer_sizes=(16, 16, 16, 16), max_iter=1000, verbose=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_no_smote_mlp_(16, 16, 16, 16)_model.pkl'>\n",
      "  import sys\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set without SMOTE mlp (16, 16, 16, 16) score: 0.9998739538166784\n",
      "PNH Test set without SMOTE mlp (16, 16, 16, 16) score: 0.9984117980714691\n",
      "PNH Accuracy without SMOTE mlp (16, 16, 16, 16):  0.9984117980714691\n",
      "PNH mlp (16, 16, 16, 16)\n",
      " [[26388    10]\n",
      " [   32    15]]\n",
      "PNH mlp (16, 16, 16, 16)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.60      0.32      0.42        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.80      0.66      0.71     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.04257434\n",
      "Iteration 2, loss = 0.00701941\n",
      "Iteration 3, loss = 0.00551708\n",
      "Iteration 4, loss = 0.00433360\n",
      "Iteration 5, loss = 0.00315531\n",
      "Iteration 6, loss = 0.00211594\n",
      "Iteration 7, loss = 0.00187811\n",
      "Iteration 8, loss = 0.00136336\n",
      "Iteration 9, loss = 0.00099859\n",
      "Iteration 10, loss = 0.00104321\n",
      "Iteration 11, loss = 0.00069684\n",
      "Iteration 12, loss = 0.00102306\n",
      "Iteration 13, loss = 0.00063844\n",
      "Iteration 14, loss = 0.00038129\n",
      "Iteration 15, loss = 0.00039224\n",
      "Iteration 16, loss = 0.00061034\n",
      "Iteration 17, loss = 0.00040583\n",
      "Iteration 18, loss = 0.00041016\n",
      "Iteration 19, loss = 0.00073994\n",
      "Iteration 20, loss = 0.00019964\n",
      "Iteration 21, loss = 0.00029067\n",
      "Iteration 22, loss = 0.00022844\n",
      "Iteration 23, loss = 0.00051644\n",
      "Iteration 24, loss = 0.00118663\n",
      "Iteration 25, loss = 0.00022511\n",
      "Iteration 26, loss = 0.00020899\n",
      "Iteration 27, loss = 0.00018479\n",
      "Iteration 28, loss = 0.00017268\n",
      "Iteration 29, loss = 0.00014489\n",
      "Iteration 30, loss = 0.00130290\n",
      "Iteration 31, loss = 0.00054703\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "MLPClassifier(hidden_layer_sizes=(32, 32, 32, 32), max_iter=1000, verbose=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_no_smote_mlp_(32, 32, 32, 32)_model.pkl'>\n",
      "  import sys\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set without SMOTE mlp (32, 32, 32, 32) score: 0.9999495815266713\n",
      "PNH Test set without SMOTE mlp (32, 32, 32, 32) score: 0.9984874267347325\n",
      "PNH Accuracy without SMOTE mlp (32, 32, 32, 32):  0.9984874267347325\n",
      "PNH mlp (32, 32, 32, 32)\n",
      " [[26385    13]\n",
      " [   27    20]]\n",
      "PNH mlp (32, 32, 32, 32)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.61      0.43      0.50        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.80      0.71      0.75     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for hosp in dict_df_X_train:\n",
    "    for hid_layers in list_hid_layers:\n",
    "        model = MLPClassifier(hidden_layer_sizes=hid_layers, max_iter=max_iter,verbose=1)  \n",
    "        model.fit(dict_df_X_train[hosp], dict_df_y_train[hosp])\n",
    "        print(model)\n",
    "        filename = file_dir + f'{hosp}_uc1_no_smote_mlp_{hid_layers}_model.pkl'\n",
    "        pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "        predictions = model.predict(dict_df_X_test[hosp]) \n",
    "\n",
    "        # Score\n",
    "        print(f\"{hosp} Training set without SMOTE mlp {hid_layers} score: {model.score(dict_df_X_train[hosp], dict_df_y_train[hosp])}\")\n",
    "        print(f\"{hosp} Test set without SMOTE mlp {hid_layers} score: {model.score(dict_df_X_test[hosp], dict_df_y_test[hosp])}\")\n",
    "\n",
    "        print(f\"{hosp} Accuracy without SMOTE mlp {hid_layers}: \", metrics.accuracy_score(dict_df_y_test[hosp], predictions))\n",
    "        print(hosp, f'mlp {hid_layers}\\n', confusion_matrix(dict_df_y_test[hosp],predictions))  \n",
    "        print(hosp, f'mlp {hid_layers}\\n', classification_report(dict_df_y_test[hosp],predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net With SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "list_hid_layers = [(16,16), (32,32), (64,64), (128,128), (256,256),\n",
    "                   (16,16,16), (32,32,32), (64,64,64),\n",
    "                   (16,16,16,16), (32,32,32,32)]\n",
    "max_iter = 1000\n",
    "list_smote_sampling = [0.1, 0.2, 0.3, 0.5, 1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net Layers With SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.19823630\n",
      "Iteration 2, loss = 0.01140996\n",
      "Iteration 3, loss = 0.00496564\n",
      "Iteration 4, loss = 0.00302236\n",
      "Iteration 5, loss = 0.00214177\n",
      "Iteration 6, loss = 0.00164094\n",
      "Iteration 7, loss = 0.00208556\n",
      "Iteration 8, loss = 0.00109772\n",
      "Iteration 9, loss = 0.00097542\n",
      "Iteration 10, loss = 0.00136329\n",
      "Iteration 11, loss = 0.00080532\n",
      "Iteration 12, loss = 0.00061287\n",
      "Iteration 13, loss = 0.00062073\n",
      "Iteration 14, loss = 0.00048507\n",
      "Iteration 15, loss = 0.00089327\n",
      "Iteration 16, loss = 0.00047039\n",
      "Iteration 17, loss = 0.00058500\n",
      "Iteration 18, loss = 0.00058301\n",
      "Iteration 19, loss = 0.00050527\n",
      "Iteration 20, loss = 0.00061565\n",
      "Iteration 21, loss = 0.00036779\n",
      "Iteration 22, loss = 0.00055779\n",
      "Iteration 23, loss = 0.00035657\n",
      "Iteration 24, loss = 0.00029523\n",
      "Iteration 25, loss = 0.00045916\n",
      "Iteration 26, loss = 0.00097147\n",
      "Iteration 27, loss = 0.00030684\n",
      "Iteration 28, loss = 0.00023922\n",
      "Iteration 29, loss = 0.00051327\n",
      "Iteration 30, loss = 0.00054974\n",
      "Iteration 31, loss = 0.00027049\n",
      "Iteration 32, loss = 0.00026170\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "MLPClassifier(hidden_layer_sizes=(16, 16), max_iter=1000, verbose=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.1_smote_mlp_(16, 16)_model.pkl'>\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set 0.1 SMOTE mlp (16, 16) score: 0.9999655651335498\n",
      "PNH Test set 0.1 SMOTE mlp (16, 16) score: 0.997579882775572\n",
      "PNH Accuracy:  0.997579882775572\n",
      "PNH mlp (16, 16)\n",
      " [[26366    32]\n",
      " [   32    15]]\n",
      "PNH mlp (16, 16)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.32      0.32      0.32        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.66      0.66      0.66     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.11488017\n",
      "Iteration 2, loss = 0.00744179\n",
      "Iteration 3, loss = 0.00340427\n",
      "Iteration 4, loss = 0.00216191\n",
      "Iteration 5, loss = 0.00105930\n",
      "Iteration 6, loss = 0.00077802\n",
      "Iteration 7, loss = 0.00064845\n",
      "Iteration 8, loss = 0.00056401\n",
      "Iteration 9, loss = 0.00071795\n",
      "Iteration 10, loss = 0.00041655\n",
      "Iteration 11, loss = 0.00039646\n",
      "Iteration 12, loss = 0.00039006\n",
      "Iteration 13, loss = 0.00045095\n",
      "Iteration 14, loss = 0.00083326\n",
      "Iteration 15, loss = 0.00036170\n",
      "Iteration 16, loss = 0.00031872\n",
      "Iteration 17, loss = 0.00033716\n",
      "Iteration 18, loss = 0.00053899\n",
      "Iteration 19, loss = 0.00033001\n",
      "Iteration 20, loss = 0.00024713\n",
      "Iteration 21, loss = 0.00028177\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "MLPClassifier(hidden_layer_sizes=(16, 16), max_iter=1000, verbose=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.2_smote_mlp_(16, 16)_model.pkl'>\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set 0.2 SMOTE mlp (16, 16) score: 0.9999684346755611\n",
      "PNH Test set 0.2 SMOTE mlp (16, 16) score: 0.9974664397806768\n",
      "PNH Accuracy:  0.9974664397806768\n",
      "PNH mlp (16, 16)\n",
      " [[26363    35]\n",
      " [   32    15]]\n",
      "PNH mlp (16, 16)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.30      0.32      0.31        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.65      0.66      0.65     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.11744873\n",
      "Iteration 2, loss = 0.00650142\n",
      "Iteration 3, loss = 0.00308663\n",
      "Iteration 4, loss = 0.00181265\n",
      "Iteration 5, loss = 0.00125670\n",
      "Iteration 6, loss = 0.00110509\n",
      "Iteration 7, loss = 0.00075670\n",
      "Iteration 8, loss = 0.00055035\n",
      "Iteration 9, loss = 0.00070216\n",
      "Iteration 10, loss = 0.00045704\n",
      "Iteration 11, loss = 0.00040232\n",
      "Iteration 12, loss = 0.00054020\n",
      "Iteration 13, loss = 0.00063907\n",
      "Iteration 14, loss = 0.00038488\n",
      "Iteration 15, loss = 0.00031442\n",
      "Iteration 16, loss = 0.00058610\n",
      "Iteration 17, loss = 0.00033815\n",
      "Iteration 18, loss = 0.00040560\n",
      "Iteration 19, loss = 0.00024067\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "MLPClassifier(hidden_layer_sizes=(16, 16), max_iter=1000, verbose=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.3_smote_mlp_(16, 16)_model.pkl'>\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set 0.3 SMOTE mlp (16, 16) score: 0.9999708627538583\n",
      "PNH Test set 0.3 SMOTE mlp (16, 16) score: 0.9973151824541501\n",
      "PNH Accuracy:  0.9973151824541501\n",
      "PNH mlp (16, 16)\n",
      " [[26358    40]\n",
      " [   31    16]]\n",
      "PNH mlp (16, 16)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.29      0.34      0.31        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.64      0.67      0.65     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.09460377\n",
      "Iteration 2, loss = 0.00404033\n",
      "Iteration 3, loss = 0.00171402\n",
      "Iteration 4, loss = 0.00086608\n",
      "Iteration 5, loss = 0.00058303\n",
      "Iteration 6, loss = 0.00057735\n",
      "Iteration 7, loss = 0.00039557\n",
      "Iteration 8, loss = 0.00063410\n",
      "Iteration 9, loss = 0.00050097\n",
      "Iteration 10, loss = 0.00032954\n",
      "Iteration 11, loss = 0.00030340\n",
      "Iteration 12, loss = 0.00030511\n",
      "Iteration 13, loss = 0.00046792\n",
      "Iteration 14, loss = 0.00035920\n",
      "Iteration 15, loss = 0.00028919\n",
      "Iteration 16, loss = 0.00025577\n",
      "Iteration 17, loss = 0.00022960\n",
      "Iteration 18, loss = 0.00025186\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "MLPClassifier(hidden_layer_sizes=(16, 16), max_iter=1000, verbose=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.5_smote_mlp_(16, 16)_model.pkl'>\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set 0.5 SMOTE mlp (16, 16) score: 0.999974747687309\n",
      "PNH Test set 0.5 SMOTE mlp (16, 16) score: 0.997693325770467\n",
      "PNH Accuracy:  0.997693325770467\n",
      "PNH mlp (16, 16)\n",
      " [[26369    29]\n",
      " [   32    15]]\n",
      "PNH mlp (16, 16)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.34      0.32      0.33        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.67      0.66      0.66     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.06592007\n",
      "Iteration 2, loss = 0.00390707\n",
      "Iteration 3, loss = 0.00192582\n",
      "Iteration 4, loss = 0.00097868\n",
      "Iteration 5, loss = 0.00081107\n",
      "Iteration 6, loss = 0.00097751\n",
      "Iteration 7, loss = 0.00056414\n",
      "Iteration 8, loss = 0.00039761\n",
      "Iteration 9, loss = 0.00036473\n",
      "Iteration 10, loss = 0.00032125\n",
      "Iteration 11, loss = 0.00029451\n",
      "Iteration 12, loss = 0.00030192\n",
      "Iteration 13, loss = 0.00104728\n",
      "Iteration 14, loss = 0.00034732\n",
      "Iteration 15, loss = 0.00026610\n",
      "Iteration 16, loss = 0.00022512\n",
      "Iteration 17, loss = 0.00024306\n",
      "Iteration 18, loss = 0.00024544\n",
      "Iteration 19, loss = 0.00025088\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "MLPClassifier(hidden_layer_sizes=(16, 16), max_iter=1000, verbose=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_1.0_smote_mlp_(16, 16)_model.pkl'>\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set 1.0 SMOTE mlp (16, 16) score: 0.9999873738967943\n",
      "PNH Test set 1.0 SMOTE mlp (16, 16) score: 0.9978823974286255\n",
      "PNH Accuracy:  0.9978823974286255\n",
      "PNH mlp (16, 16)\n",
      " [[26375    23]\n",
      " [   33    14]]\n",
      "PNH mlp (16, 16)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.38      0.30      0.33        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.69      0.65      0.67     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.08795576\n",
      "Iteration 2, loss = 0.00627178\n",
      "Iteration 3, loss = 0.00254460\n",
      "Iteration 4, loss = 0.00163482\n",
      "Iteration 5, loss = 0.00087694\n",
      "Iteration 6, loss = 0.00082028\n",
      "Iteration 7, loss = 0.00168885\n",
      "Iteration 8, loss = 0.00050529\n",
      "Iteration 9, loss = 0.00051989\n",
      "Iteration 10, loss = 0.00087628\n",
      "Iteration 11, loss = 0.00040577\n",
      "Iteration 12, loss = 0.00039230\n",
      "Iteration 13, loss = 0.00067830\n",
      "Iteration 14, loss = 0.00036219\n",
      "Iteration 15, loss = 0.00039586\n",
      "Iteration 16, loss = 0.00036834\n",
      "Iteration 17, loss = 0.00030638\n",
      "Iteration 18, loss = 0.00032878\n",
      "Iteration 19, loss = 0.00117691\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "MLPClassifier(hidden_layer_sizes=(32, 32), max_iter=1000, verbose=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.1_smote_mlp_(32, 32)_model.pkl'>\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set 0.1 SMOTE mlp (32, 32) score: 0.9999655651335498\n",
      "PNH Test set 0.1 SMOTE mlp (32, 32) score: 0.9978823974286255\n",
      "PNH Accuracy:  0.9978823974286255\n",
      "PNH mlp (32, 32)\n",
      " [[26372    26]\n",
      " [   30    17]]\n",
      "PNH mlp (32, 32)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.40      0.36      0.38        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.70      0.68      0.69     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.07212226\n",
      "Iteration 2, loss = 0.00420507\n",
      "Iteration 3, loss = 0.00198931\n",
      "Iteration 4, loss = 0.00161886\n",
      "Iteration 5, loss = 0.00078736\n",
      "Iteration 6, loss = 0.00053135\n",
      "Iteration 7, loss = 0.00056585\n",
      "Iteration 8, loss = 0.00045303\n",
      "Iteration 9, loss = 0.00044928\n",
      "Iteration 10, loss = 0.00071750\n",
      "Iteration 11, loss = 0.00033342\n",
      "Iteration 12, loss = 0.00033385\n",
      "Iteration 13, loss = 0.00148455\n",
      "Iteration 14, loss = 0.00031891\n",
      "Iteration 15, loss = 0.00025855\n",
      "Iteration 16, loss = 0.00095481\n",
      "Iteration 17, loss = 0.00028812\n",
      "Iteration 18, loss = 0.00051565\n",
      "Iteration 19, loss = 0.00025950\n",
      "Iteration 20, loss = 0.00024369\n",
      "Iteration 21, loss = 0.00020975\n",
      "Iteration 22, loss = 0.00022393\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "MLPClassifier(hidden_layer_sizes=(32, 32), max_iter=1000, verbose=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.2_smote_mlp_(32, 32)_model.pkl'>\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set 0.2 SMOTE mlp (32, 32) score: 0.999989478225187\n",
      "PNH Test set 0.2 SMOTE mlp (32, 32) score: 0.9977689544337304\n",
      "PNH Accuracy:  0.9977689544337304\n",
      "PNH mlp (32, 32)\n",
      " [[26370    28]\n",
      " [   31    16]]\n",
      "PNH mlp (32, 32)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.36      0.34      0.35        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.68      0.67      0.68     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.08350649\n",
      "Iteration 2, loss = 0.00407696\n",
      "Iteration 3, loss = 0.00198548\n",
      "Iteration 4, loss = 0.00102446\n",
      "Iteration 5, loss = 0.00068018\n",
      "Iteration 6, loss = 0.00085468\n",
      "Iteration 7, loss = 0.00048912\n",
      "Iteration 8, loss = 0.00063547\n",
      "Iteration 9, loss = 0.00088231\n",
      "Iteration 10, loss = 0.00039292\n",
      "Iteration 11, loss = 0.00041932\n",
      "Iteration 12, loss = 0.00031299\n",
      "Iteration 13, loss = 0.00036706\n",
      "Iteration 14, loss = 0.00058889\n",
      "Iteration 15, loss = 0.00034146\n",
      "Iteration 16, loss = 0.00030721\n",
      "Iteration 17, loss = 0.00110943\n",
      "Iteration 18, loss = 0.00067965\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "MLPClassifier(hidden_layer_sizes=(32, 32), max_iter=1000, verbose=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.3_smote_mlp_(32, 32)_model.pkl'>\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set 0.3 SMOTE mlp (32, 32) score: 0.9999417255077165\n",
      "PNH Test set 0.3 SMOTE mlp (32, 32) score: 0.9978445830969938\n",
      "PNH Accuracy:  0.9978445830969938\n",
      "PNH mlp (32, 32)\n",
      " [[26372    26]\n",
      " [   31    16]]\n",
      "PNH mlp (32, 32)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.38      0.34      0.36        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.69      0.67      0.68     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.06673720\n",
      "Iteration 2, loss = 0.00410172\n",
      "Iteration 3, loss = 0.00186738\n",
      "Iteration 4, loss = 0.00106813\n",
      "Iteration 5, loss = 0.00074229\n",
      "Iteration 6, loss = 0.00049529\n",
      "Iteration 7, loss = 0.00045949\n",
      "Iteration 8, loss = 0.00038067\n",
      "Iteration 9, loss = 0.00045163\n",
      "Iteration 10, loss = 0.00166039\n",
      "Iteration 11, loss = 0.00070031\n",
      "Iteration 12, loss = 0.00059818\n",
      "Iteration 13, loss = 0.00030929\n",
      "Iteration 14, loss = 0.00032626\n",
      "Iteration 15, loss = 0.00085037\n",
      "Iteration 16, loss = 0.00035165\n",
      "Iteration 17, loss = 0.00032562\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "MLPClassifier(hidden_layer_sizes=(32, 32), max_iter=1000, verbose=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.5_smote_mlp_(32, 32)_model.pkl'>\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set 0.5 SMOTE mlp (32, 32) score: 0.9999831651248727\n",
      "PNH Test set 0.5 SMOTE mlp (32, 32) score: 0.9976176971072036\n",
      "PNH Accuracy:  0.9976176971072036\n",
      "PNH mlp (32, 32)\n",
      " [[26366    32]\n",
      " [   31    16]]\n",
      "PNH mlp (32, 32)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.33      0.34      0.34        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.67      0.67      0.67     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.04810159\n",
      "Iteration 2, loss = 0.00326951\n",
      "Iteration 3, loss = 0.00116675\n",
      "Iteration 4, loss = 0.00067066\n",
      "Iteration 5, loss = 0.00093579\n",
      "Iteration 6, loss = 0.00039560\n",
      "Iteration 7, loss = 0.00038844\n",
      "Iteration 8, loss = 0.00034448\n",
      "Iteration 9, loss = 0.00038731\n",
      "Iteration 10, loss = 0.00035838\n",
      "Iteration 11, loss = 0.00099450\n",
      "Iteration 12, loss = 0.00039915\n",
      "Iteration 13, loss = 0.00034719\n",
      "Iteration 14, loss = 0.00026121\n",
      "Iteration 15, loss = 0.00024826\n",
      "Iteration 16, loss = 0.00028366\n",
      "Iteration 17, loss = 0.00049613\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "MLPClassifier(hidden_layer_sizes=(32, 32), max_iter=1000, verbose=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_1.0_smote_mlp_(32, 32)_model.pkl'>\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set 1.0 SMOTE mlp (32, 32) score: 0.9999810608451913\n",
      "PNH Test set 1.0 SMOTE mlp (32, 32) score: 0.9979958404235205\n",
      "PNH Accuracy:  0.9979958404235205\n",
      "PNH mlp (32, 32)\n",
      " [[26376    22]\n",
      " [   31    16]]\n",
      "PNH mlp (32, 32)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.42      0.34      0.38        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.71      0.67      0.69     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.05627601\n",
      "Iteration 2, loss = 0.00353351\n",
      "Iteration 3, loss = 0.00153705\n",
      "Iteration 4, loss = 0.00079495\n",
      "Iteration 5, loss = 0.00144061\n",
      "Iteration 6, loss = 0.00044101\n",
      "Iteration 7, loss = 0.00035370\n",
      "Iteration 8, loss = 0.00161750\n",
      "Iteration 9, loss = 0.00035189\n",
      "Iteration 10, loss = 0.00036976\n",
      "Iteration 11, loss = 0.00046724\n",
      "Iteration 12, loss = 0.00044938\n",
      "Iteration 13, loss = 0.00068175\n",
      "Iteration 14, loss = 0.00028356\n",
      "Iteration 15, loss = 0.00086023\n",
      "Iteration 16, loss = 0.00027573\n",
      "Iteration 17, loss = 0.00065019\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "MLPClassifier(hidden_layer_sizes=(64, 64), max_iter=1000, verbose=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.1_smote_mlp_(64, 64)_model.pkl'>\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set 0.1 SMOTE mlp (64, 64) score: 0.9998737388230162\n",
      "PNH Test set 0.1 SMOTE mlp (64, 64) score: 0.9981849120816789\n",
      "PNH Accuracy:  0.9981849120816789\n",
      "PNH mlp (64, 64)\n",
      " [[26379    19]\n",
      " [   29    18]]\n",
      "PNH mlp (64, 64)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.49      0.38      0.43        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.74      0.69      0.71     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.05792979\n",
      "Iteration 2, loss = 0.00345138\n",
      "Iteration 3, loss = 0.00114436\n",
      "Iteration 4, loss = 0.00075535\n",
      "Iteration 5, loss = 0.00073732\n",
      "Iteration 6, loss = 0.00054604\n",
      "Iteration 7, loss = 0.00053123\n",
      "Iteration 8, loss = 0.00153349\n",
      "Iteration 9, loss = 0.00070767\n",
      "Iteration 10, loss = 0.00036306\n",
      "Iteration 11, loss = 0.00035960\n",
      "Iteration 12, loss = 0.00032639\n",
      "Iteration 13, loss = 0.00038664\n",
      "Iteration 14, loss = 0.00051852\n",
      "Iteration 15, loss = 0.00060493\n",
      "Iteration 16, loss = 0.00034724\n",
      "Iteration 17, loss = 0.00029196\n",
      "Iteration 18, loss = 0.00022418\n",
      "Iteration 19, loss = 0.00020339\n",
      "Iteration 20, loss = 0.00055889\n",
      "Iteration 21, loss = 0.00077473\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "MLPClassifier(hidden_layer_sizes=(64, 64), max_iter=1000, verbose=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.2_smote_mlp_(64, 64)_model.pkl'>\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set 0.2 SMOTE mlp (64, 64) score: 0.999989478225187\n",
      "PNH Test set 0.2 SMOTE mlp (64, 64) score: 0.998298355076574\n",
      "PNH Accuracy:  0.998298355076574\n",
      "PNH mlp (64, 64)\n",
      " [[26386    12]\n",
      " [   33    14]]\n",
      "PNH mlp (64, 64)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.54      0.30      0.38        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.77      0.65      0.69     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.05430336\n",
      "Iteration 2, loss = 0.00280441\n",
      "Iteration 3, loss = 0.00216407\n",
      "Iteration 4, loss = 0.00067768\n",
      "Iteration 5, loss = 0.00052838\n",
      "Iteration 6, loss = 0.00059990\n",
      "Iteration 7, loss = 0.00094968\n",
      "Iteration 8, loss = 0.00044136\n",
      "Iteration 9, loss = 0.00035122\n",
      "Iteration 10, loss = 0.00036307\n",
      "Iteration 11, loss = 0.00110331\n",
      "Iteration 12, loss = 0.00039536\n",
      "Iteration 13, loss = 0.00032684\n",
      "Iteration 14, loss = 0.00032857\n",
      "Iteration 15, loss = 0.00027237\n",
      "Iteration 16, loss = 0.00029442\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "MLPClassifier(hidden_layer_sizes=(64, 64), max_iter=1000, verbose=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: ResourceWarning: unclosed file <_io.BufferedWriter name='./Data Exploration/data/uc1/PNH_uc1_0.3_smote_mlp_(64, 64)_model.pkl'>\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNH Training set 0.3 SMOTE mlp (64, 64) score: 0.9999708627538583\n",
      "PNH Test set 0.3 SMOTE mlp (64, 64) score: 0.9981470977500473\n",
      "PNH Accuracy:  0.9981470977500473\n",
      "PNH mlp (64, 64)\n",
      " [[26385    13]\n",
      " [   36    11]]\n",
      "PNH mlp (64, 64)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26398\n",
      "           1       0.46      0.23      0.31        47\n",
      "\n",
      "    accuracy                           1.00     26445\n",
      "   macro avg       0.73      0.62      0.65     26445\n",
      "weighted avg       1.00      1.00      1.00     26445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.05027976\n",
      "Iteration 2, loss = 0.00217943\n",
      "Iteration 3, loss = 0.00099615\n",
      "Iteration 4, loss = 0.00082900\n",
      "Iteration 5, loss = 0.00072407\n",
      "Iteration 6, loss = 0.00063415\n",
      "Iteration 7, loss = 0.00050784\n",
      "Iteration 8, loss = 0.00041847\n",
      "Iteration 9, loss = 0.00047651\n",
      "Iteration 10, loss = 0.00081472\n",
      "Iteration 11, loss = 0.00035107\n",
      "Iteration 12, loss = 0.00058820\n",
      "Iteration 13, loss = 0.00035129\n",
      "Iteration 14, loss = 0.00040140\n",
      "Iteration 15, loss = 0.00029341\n",
      "Iteration 17, loss = 0.00111806\n"
     ]
    }
   ],
   "source": [
    "for hosp in dict_df_X_train:\n",
    "    for hid_layers in list_hid_layers:\n",
    "        for sample in list_smote_sampling:\n",
    "            sm_ss = SMOTE(random_state=55,sampling_strategy=sample)\n",
    "            X_train_ss, y_train_ss = sm_ss.fit_sample(dict_df_X_train[hosp], dict_df_y_train[hosp])\n",
    "        \n",
    "            model = MLPClassifier(hidden_layer_sizes=hid_layers, max_iter=max_iter,verbose=1)  \n",
    "            model.fit(X_train_ss, y_train_ss)  \n",
    "            print(model)\n",
    "            filename = file_dir + f'{hosp}_uc1_{sample}_smote_mlp_{hid_layers}_model.pkl'\n",
    "            pickle.dump(model, open(filename, 'wb'))\n",
    "            \n",
    "            predictions = model.predict(dict_df_X_test[hosp]) \n",
    "\n",
    "            # Score\n",
    "            print(f\"{hosp} Training set {sample} SMOTE mlp {hid_layers} score: {model.score(X_train_ss, y_train_ss)}\")\n",
    "            print(f\"{hosp} Test set {sample} SMOTE mlp {hid_layers} score: {model.score(dict_df_X_test[hosp], dict_df_y_test[hosp])}\")\n",
    "\n",
    "            print(f\"{hosp} Accuracy: \", metrics.accuracy_score(dict_df_y_test[hosp], predictions))\n",
    "            print(hosp, f'mlp {hid_layers}\\n', confusion_matrix(dict_df_y_test[hosp],predictions))  \n",
    "            print(hosp, f'mlp {hid_layers}\\n', classification_report(dict_df_y_test[hosp],predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful when running this, about 2 full days are needed to run this!!!\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hosp in dict_df_X_train:\n",
    "    test_scores = []\n",
    "    train_scores = []\n",
    "\n",
    "    for i in range(1,15):\n",
    "\n",
    "        knn = KNeighborsClassifier(i)\n",
    "        knn.fit(dict_df_X_train[hosp],dict_df_y_train[hosp])\n",
    "\n",
    "        train_scores.append(knn.score(dict_df_X_train[hosp],dict_df_y_train[hosp]))\n",
    "        test_scores.append(knn.score(dict_df_X_test[hosp],dict_df_y_test[hosp]))\n",
    "\n",
    "    ## score that comes from testing on the same datapoints that were used for training\n",
    "    max_train_score = max(train_scores)\n",
    "    train_scores_ind = [i for i, v in enumerate(train_scores) if v == max_train_score]\n",
    "    print(f'{hosp} Max train score {max_train_score*100} % and k = {list(map(lambda x: x+1, train_scores_ind))}')\n",
    "\n",
    "    ## score that comes from testing on the datapoints that were split in the beginning to be used for testing solely\n",
    "    max_test_score = max(test_scores)\n",
    "    test_scores_ind = [i for i, v in enumerate(test_scores) if v == max_test_score]\n",
    "    print(f'{hosp} Max test score {max_test_score*100} % and k = {list(map(lambda x: x+1, test_scores_ind))}')\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.plot(range(1,15),train_scores,marker='*',label='Train Score')\n",
    "    plt.plot(range(1,15),test_scores,marker='o',label='Test Score')\n",
    "    plt.title(f'{hosp} KNN')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# From the above, the best KNN is at k=8\n",
    "#Setup a knn classifier with k neighbors\n",
    "best_knn = KNeighborsClassifier(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbours = 8\n",
    "for hosp in dict_df_X_train:\n",
    "    # Fit the KNN model with training data and score the test data\n",
    "    best_knn = KNeighborsClassifier(n_neighbours)\n",
    "    \n",
    "    best_knn.fit(dict_df_X_train[hosp],dict_df_y_train[hosp])\n",
    "    best_knn.score(dict_df_X_test[hosp],dict_df_y_test[hosp])\n",
    "    \n",
    "    # save the model to disk\n",
    "    filename = f'{hosp}_best_knn_without_smote.pkl'\n",
    "    pickle.dump(best_knn, open(filename, 'wb'))\n",
    "    \n",
    "    y_pred = best_knn.predict(dict_df_X_test[hosp])\n",
    "    # Score for Best KNN, No SMOTE\n",
    "    print(f\"{hosp} Training set without SMOTE KNN({n_neighbours}) score: {best_knn.score(dict_df_X_train[hosp], dict_df_y_train[hosp])}\")\n",
    "    print(f\"{hosp} Test set without SMOTE KNN({n_neighbours}) score: {best_knn.score(dict_df_X_test[hosp], dict_df_y_test[hosp])}\")\n",
    "\n",
    "    print(f\"{hosp} Accuracy without SMOTE KNN({n_neighbours}): {metrics.accuracy_score(dict_df_y_test[hosp], y_pred)}\")\n",
    "    print(hosp, f'KNN({n_neighbours})\\n', confusion_matrix(dict_df_y_test[hosp],y_pred))  \n",
    "    print(hosp, f'KNN({n_neighbours})\\n', classification_report(dict_df_y_test[hosp],y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN With SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN With SMOTE ss=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbours = 8\n",
    "list_smote_sampling = [0.1, 0.5, 1.0]\n",
    "for hosp in dict_df_X_train:\n",
    "    for sample in list_smote_sampling:\n",
    "        sm_ss = SMOTE(random_state=55,sampling_strategy=sample)\n",
    "        X_train_ss, y_train_ss = sm_ss.fit_sample(dict_df_X_train[hosp], dict_df_y_train[hosp])\n",
    "        \n",
    "        # Fit the KNN model with training data and score the test data\n",
    "        best_knn = KNeighborsClassifier(n_neighbours)    \n",
    "        best_knn.fit(X_train_ss,y_train_ss)\n",
    "        #best_knn.score(dict_df_X_test[hosp],dict_df_y_test[hosp])\n",
    "        \n",
    "        # save the model to disk\n",
    "        filename = f'{hosp}_best_knn_{sample}_smote.pkl'\n",
    "        pickle.dump(best_knn, open(filename, 'wb'))\n",
    "        \n",
    "        y_pred = best_knn.predict(dict_df_X_test[hosp])\n",
    "        # Score for Best KNN, with SMOTE\n",
    "        print(f\"{hosp} Training set {sample} SMOTE KNN({n_neighbours}) score: {best_knn.score(X_train_ss, y_train_ss)}\")\n",
    "        print(f\"{hosp} Test set {sample} SMOTE KNN({n_neighbours}) score: {best_knn.score(dict_df_X_test[hosp], dict_df_y_test[hosp])}\")\n",
    "\n",
    "        print(f\"{hosp} Accuracy {sample} SMOTE KNN({n_neighbours}): \", metrics.accuracy_score(dict_df_y_test[hosp], y_pred))\n",
    "        print(confusion_matrix(dict_df_y_test[hosp],y_pred))  \n",
    "        print(classification_report(dict_df_y_test[hosp],y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m56"
  },
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
