{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mokky\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\mokky\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\mokky\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\mokky\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\mokky\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\mokky\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\mokky\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\mokky\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\mokky\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\mokky\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\mokky\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\mokky\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x26918e7e708>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show various error measurement\n",
    "def forecast_accuracy(forecast, actual):\n",
    "    mape = np.mean(np.abs(forecast - actual)/np.abs(actual))  # MAPE\n",
    "    me = np.mean(forecast - actual)             # ME\n",
    "    mae = np.mean(np.abs(forecast - actual))    # MAE\n",
    "    mpe = np.mean((forecast - actual)/actual)   # MPE\n",
    "    mse = np.mean((forecast - actual)**2)  # MSE\n",
    "    rmse = np.mean((forecast - actual)**2)**.5  # RMSE\n",
    "    #corr = np.corrcoef(forecast, actual)[0,1]   # corr\n",
    "    #mins = np.amin(np.hstack([forecast[:,None], \n",
    "    #                          actual[:,None]]), axis=1)\n",
    "    #maxs = np.amax(np.hstack([forecast[:,None], \n",
    "    #                          actual[:,None]]), axis=1)\n",
    "    #minmax = 1 - np.mean(mins/maxs)             # minmax\n",
    "    #acf1 = acf(fc-test)[1]                      # ACF1\n",
    "    #return({'mape':mape, 'me':me, 'mae': mae, \n",
    "    #        'mpe': mpe, 'rmse':rmse, 'acf1':acf1, \n",
    "    #        'corr':corr, 'minmax':minmax})\n",
    "    return({'mape':mape, 'me':me, 'mae': mae, \n",
    "            'mpe': mpe, 'mse':mse, 'rmse':rmse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Users\\mokky\\Documents\\GitHub\\nus-iss\\PRS-PM-ISY5002-GROUP5\\SystemCode\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('d:/Users/mokky/Documents/GitHub/nus-iss/PRS-PM-ISY5002-GROUP5/SystemCode')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = './Data Exploration/data/uc3/'\n",
    "X_train_file_path = 'all_hosp_new_train_X_uc3.pkl'\n",
    "y_train_file_path = 'all_hosp_data_uc3_y_train_uc3.pkl'\n",
    "X_test_file_path = 'all_hosp_new_test_X_uc3.pkl'\n",
    "y_test_file_path = 'all_hosp_data_uc3_y_test_uc3.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46888, 14313) (46888,) (15629, 14313) (15629,)\n"
     ]
    }
   ],
   "source": [
    "df_X_train = pd.read_pickle(file_dir + X_train_file_path)\n",
    "df_y_train = pd.read_pickle(file_dir + y_train_file_path)\n",
    "df_X_test = pd.read_pickle(file_dir + X_test_file_path)\n",
    "df_y_test = pd.read_pickle(file_dir + y_test_file_path)\n",
    "print(df_X_train.shape, df_y_train.shape, df_X_test.shape, df_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15629,)\n"
     ]
    }
   ],
   "source": [
    "print(df_y_test.values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks ( Sequential )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model = Sequential()\n",
    "n_hid_nodes = 4096\n",
    "dropout_rate = 0.2\n",
    "rand_seed = 42\n",
    "kernel_init = 'he_normal'\n",
    "hid_act = 'relu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model.add(Dense(n_hid_nodes, kernel_initializer=kernel_init,input_dim = df_X_train.shape[1], activation=hid_act))\n",
    "NN_model.add(Dropout(dropout_rate, seed=rand_seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN_model.add(GaussianNoise(0.01,input_shape = (df_X_train.shape[1],)))\n",
    "#NN_model.add(Dense(n_hid_nodes, kernel_initializer=kernel_init,activation='relu'))\n",
    "#NN_model.add(Dropout(dropout_rate, seed=rand_seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    NN_model.add(Dense(n_hid_nodes, kernel_initializer=kernel_init))#,activation=hid_act))\n",
    "    NN_model.add(BatchNormalization())\n",
    "    NN_model.add(Activation(hid_act))\n",
    "    NN_model.add(Dropout(dropout_rate, seed=rand_seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model.add(Dense(1, kernel_initializer=kernel_init,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 4096)              58630144  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 176,218,113\n",
      "Trainable params: 176,160,769\n",
      "Non-trainable params: 57,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'NN2_Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37510 samples, validate on 9378 samples\n",
      "Epoch 1/100\n",
      "37504/37510 [============================>.] - ETA: 0s - loss: 4258.3989 - mean_absolute_error: 4258.3970\n",
      "Epoch 00001: val_loss improved from inf to 2315.75026, saving model to NN2_Weights-001--2315.75026.hdf5\n",
      "37510/37510 [==============================] - 159s 4ms/sample - loss: 4257.9636 - mean_absolute_error: 4257.9619 - val_loss: 2315.7503 - val_mean_absolute_error: 2315.7510\n",
      "Epoch 2/100\n",
      "37504/37510 [============================>.] - ETA: 0s - loss: 2558.1660 - mean_absolute_error: 2558.1665\n",
      "Epoch 00002: val_loss improved from 2315.75026 to 2039.10448, saving model to NN2_Weights-002--2039.10448.hdf5\n",
      "37510/37510 [==============================] - 158s 4ms/sample - loss: 2558.1961 - mean_absolute_error: 2558.1968 - val_loss: 2039.1045 - val_mean_absolute_error: 2039.1045\n",
      "Epoch 3/100\n",
      "37504/37510 [============================>.] - ETA: 0s - loss: 2373.9062 - mean_absolute_error: 2373.9077\n",
      "Epoch 00003: val_loss improved from 2039.10448 to 2009.84729, saving model to NN2_Weights-003--2009.84729.hdf5\n",
      "37510/37510 [==============================] - 164s 4ms/sample - loss: 2375.4315 - mean_absolute_error: 2375.4329 - val_loss: 2009.8473 - val_mean_absolute_error: 2009.8470\n",
      "Epoch 4/100\n",
      "37504/37510 [============================>.] - ETA: 0s - loss: 2252.5049 - mean_absolute_error: 2252.5037\n",
      "Epoch 00004: val_loss improved from 2009.84729 to 1949.04054, saving model to NN2_Weights-004--1949.04054.hdf5\n",
      "37510/37510 [==============================] - 192s 5ms/sample - loss: 2252.4615 - mean_absolute_error: 2252.4602 - val_loss: 1949.0405 - val_mean_absolute_error: 1949.0405\n",
      "Epoch 5/100\n",
      "37504/37510 [============================>.] - ETA: 0s - loss: 2174.3493 - mean_absolute_error: 2174.3499\n",
      "Epoch 00005: val_loss did not improve from 1949.04054\n",
      "37510/37510 [==============================] - 237s 6ms/sample - loss: 2174.3518 - mean_absolute_error: 2174.3523 - val_loss: 1953.0394 - val_mean_absolute_error: 1953.0399\n",
      "Epoch 6/100\n",
      "37504/37510 [============================>.] - ETA: 0s - loss: 2097.7453 - mean_absolute_error: 2097.7451\n",
      "Epoch 00006: val_loss did not improve from 1949.04054\n",
      "37510/37510 [==============================] - 174s 5ms/sample - loss: 2097.4973 - mean_absolute_error: 2097.4971 - val_loss: 1977.9647 - val_mean_absolute_error: 1977.9655\n",
      "Epoch 7/100\n",
      "37504/37510 [============================>.] - ETA: 0s - loss: 1979.0820 - mean_absolute_error: 1979.0833\n",
      "Epoch 00007: val_loss improved from 1949.04054 to 1912.28364, saving model to NN2_Weights-007--1912.28364.hdf5\n",
      "37510/37510 [==============================] - 159s 4ms/sample - loss: 1979.5050 - mean_absolute_error: 1979.5062 - val_loss: 1912.2836 - val_mean_absolute_error: 1912.2832\n",
      "Epoch 8/100\n",
      "37504/37510 [============================>.] - ETA: 0s - loss: 1853.2579 - mean_absolute_error: 1853.2574\n",
      "Epoch 00008: val_loss did not improve from 1912.28364\n",
      "37510/37510 [==============================] - 153s 4ms/sample - loss: 1853.4056 - mean_absolute_error: 1853.4053 - val_loss: 2163.7359 - val_mean_absolute_error: 2163.7361\n",
      "Epoch 9/100\n",
      "37504/37510 [============================>.] - ETA: 0s - loss: 1762.0448 - mean_absolute_error: 1762.0449\n",
      "Epoch 00009: val_loss did not improve from 1912.28364\n",
      "37510/37510 [==============================] - 155s 4ms/sample - loss: 1762.9988 - mean_absolute_error: 1762.9989 - val_loss: 1927.9351 - val_mean_absolute_error: 1927.9354\n",
      "Epoch 10/100\n",
      "37504/37510 [============================>.] - ETA: 0s - loss: 1667.6665 - mean_absolute_error: 1667.6685\n",
      "Epoch 00010: val_loss did not improve from 1912.28364\n",
      "37510/37510 [==============================] - 154s 4ms/sample - loss: 1667.6676 - mean_absolute_error: 1667.6696 - val_loss: 1957.2341 - val_mean_absolute_error: 1957.2341\n",
      "Epoch 11/100\n",
      "37504/37510 [============================>.] - ETA: 0s - loss: 1557.9594 - mean_absolute_error: 1557.9590\n",
      "Epoch 00011: val_loss did not improve from 1912.28364\n",
      "37510/37510 [==============================] - 156s 4ms/sample - loss: 1558.1572 - mean_absolute_error: 1558.1566 - val_loss: 1948.2110 - val_mean_absolute_error: 1948.2113\n",
      "Epoch 12/100\n",
      "37504/37510 [============================>.] - ETA: 0s - loss: 1505.2921 - mean_absolute_error: 1505.2919\n",
      "Epoch 00012: val_loss did not improve from 1912.28364\n",
      "37510/37510 [==============================] - 156s 4ms/sample - loss: 1505.7680 - mean_absolute_error: 1505.7677 - val_loss: 1968.9610 - val_mean_absolute_error: 1968.9609\n",
      "Epoch 13/100\n",
      "37504/37510 [============================>.] - ETA: 0s - loss: 1419.1901 - mean_absolute_error: 1419.1908\n",
      "Epoch 00013: val_loss did not improve from 1912.28364\n",
      "37510/37510 [==============================] - 156s 4ms/sample - loss: 1419.2134 - mean_absolute_error: 1419.2141 - val_loss: 1930.2001 - val_mean_absolute_error: 1930.1998\n",
      "Epoch 14/100\n",
      "37504/37510 [============================>.] - ETA: 0s - loss: 1383.6451 - mean_absolute_error: 1383.6449\n",
      "Epoch 00014: val_loss improved from 1912.28364 to 1907.32689, saving model to NN2_Weights-014--1907.32689.hdf5\n",
      "37510/37510 [==============================] - 164s 4ms/sample - loss: 1384.0024 - mean_absolute_error: 1384.0022 - val_loss: 1907.3269 - val_mean_absolute_error: 1907.3268\n",
      "Epoch 15/100\n",
      "37504/37510 [============================>.] - ETA: 0s - loss: 1320.0509 - mean_absolute_error: 1320.0524\n",
      "Epoch 00015: val_loss did not improve from 1907.32689\n",
      "37510/37510 [==============================] - 156s 4ms/sample - loss: 1320.3656 - mean_absolute_error: 1320.3671 - val_loss: 1965.6053 - val_mean_absolute_error: 1965.6055\n",
      "Epoch 16/100\n",
      "37504/37510 [============================>.] - ETA: 0s - loss: 1261.3709 - mean_absolute_error: 1261.3705\n",
      "Epoch 00016: val_loss did not improve from 1907.32689\n",
      "37510/37510 [==============================] - 154s 4ms/sample - loss: 1263.6923 - mean_absolute_error: 1263.6919 - val_loss: 1952.0900 - val_mean_absolute_error: 1952.0908\n",
      "Epoch 17/100\n",
      "37504/37510 [============================>.] - ETA: 0s - loss: 1239.9247 - mean_absolute_error: 1239.9230\n",
      "Epoch 00017: val_loss did not improve from 1907.32689\n",
      "37510/37510 [==============================] - 156s 4ms/sample - loss: 1240.1203 - mean_absolute_error: 1240.1185 - val_loss: 1946.8062 - val_mean_absolute_error: 1946.8065\n",
      "Epoch 18/100\n",
      "37504/37510 [============================>.] - ETA: 0s - loss: 1190.0630 - mean_absolute_error: 1190.0637\n",
      "Epoch 00018: val_loss did not improve from 1907.32689\n",
      "37510/37510 [==============================] - 161s 4ms/sample - loss: 1190.2835 - mean_absolute_error: 1190.2841 - val_loss: 1960.3198 - val_mean_absolute_error: 1960.3203\n",
      "Epoch 19/100\n",
      "37504/37510 [============================>.] - ETA: 0s - loss: 1146.8990 - mean_absolute_error: 1146.8993"
     ]
    }
   ],
   "source": [
    "NN_model.fit(df_X_train, df_y_train, epochs=100, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)\n",
    "\n",
    "# save model to file\n",
    "NN_model.save(file_dir + \"uc3_NN2_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = NN_model.predict(df_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=df_y_test, y=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(df_y_test,predictions, squared=True))\n",
    "\n",
    "# RMSE\n",
    "print('Root Mean squared error: %.2f'\n",
    "      % mean_squared_error(df_y_test,predictions, squared=False))\n",
    "\n",
    "# MAE\n",
    "print('Mean absolute error: %.2f'\n",
    "      % mean_absolute_error(df_y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_accuracy(predictions.reshape((-1,)), df_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
