{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parkway Project Use Case 1: Write Off Cases Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', 500)\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: DeprecationWarning: invalid escape sequence \\P\n",
      "C:\\Users\\HCAND\\anaconda3\\envs\\psupr\\lib\\site-packages\\xlrd\\xlsx.py:266: PendingDeprecationWarning: This method will be removed in future versions.  Use 'tree.iter()' or 'list(tree.iter())' instead.\n",
      "  for elem in self.tree.iter() if Element_has_iter else self.tree.getiterator():\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(381210, 85)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filePath = '.\\ParkwaySampleDataForProject_12_WithLabelNoFormula.xlsx'\n",
    "df = pd.read_excel(filePath)\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colName</th>\n",
       "      <th>non-null values</th>\n",
       "      <th>unique</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INSTITUTION</td>\n",
       "      <td>381210</td>\n",
       "      <td>4</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CASE_NUMBER</td>\n",
       "      <td>381210</td>\n",
       "      <td>381210</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TOTAL_PAID_AMT</td>\n",
       "      <td>381210</td>\n",
       "      <td>326907</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PAYER_CODE_1</td>\n",
       "      <td>381210</td>\n",
       "      <td>482</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PAYER_NAME_1</td>\n",
       "      <td>381210</td>\n",
       "      <td>425</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PAYER_1_PAID_AMT</td>\n",
       "      <td>381210</td>\n",
       "      <td>308341</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PAYER_CODE_2</td>\n",
       "      <td>149318</td>\n",
       "      <td>378</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PAYER_NAME_2</td>\n",
       "      <td>149318</td>\n",
       "      <td>329</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PAYER_2_PAID_AMT</td>\n",
       "      <td>381210</td>\n",
       "      <td>117053</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PAYER_CODE_3</td>\n",
       "      <td>53205</td>\n",
       "      <td>230</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PAYER_NAME_3</td>\n",
       "      <td>53205</td>\n",
       "      <td>201</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PAYER_3_PAID_AMT</td>\n",
       "      <td>381210</td>\n",
       "      <td>42878</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PAYER_CODE_4</td>\n",
       "      <td>2373</td>\n",
       "      <td>89</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PAYER_NAME_4</td>\n",
       "      <td>2373</td>\n",
       "      <td>78</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PAYER_4_PAID_AMT</td>\n",
       "      <td>381210</td>\n",
       "      <td>2198</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PAYER_CODE_5</td>\n",
       "      <td>52</td>\n",
       "      <td>21</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PAYER_NAME_5</td>\n",
       "      <td>52</td>\n",
       "      <td>18</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PAYER_5_PAID_AMT</td>\n",
       "      <td>381210</td>\n",
       "      <td>41</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CASE_TYPE</td>\n",
       "      <td>381210</td>\n",
       "      <td>1</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BED_TYPE</td>\n",
       "      <td>381210</td>\n",
       "      <td>10</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>REFERRAL_TYPE</td>\n",
       "      <td>381206</td>\n",
       "      <td>50</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TREATMENT_CATEGORY</td>\n",
       "      <td>381210</td>\n",
       "      <td>60</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ADMISSION_DTE</td>\n",
       "      <td>381210</td>\n",
       "      <td>1095</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ADMISSION_TYPE</td>\n",
       "      <td>381210</td>\n",
       "      <td>8</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DISCHARGE_DTE</td>\n",
       "      <td>381210</td>\n",
       "      <td>1128</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DISCHARGE_TYPE</td>\n",
       "      <td>381210</td>\n",
       "      <td>9</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DISCHARGE_TYPE_DESC</td>\n",
       "      <td>381210</td>\n",
       "      <td>9</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LOS_DAYS</td>\n",
       "      <td>381210</td>\n",
       "      <td>147</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DOCTOR_CODE</td>\n",
       "      <td>381209</td>\n",
       "      <td>1247</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DOCTOR_NAME</td>\n",
       "      <td>381210</td>\n",
       "      <td>1247</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SPECIALTY_CODE</td>\n",
       "      <td>381173</td>\n",
       "      <td>36</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SPECIALTY_DESC</td>\n",
       "      <td>381173</td>\n",
       "      <td>36</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SPECIALTY_GRP</td>\n",
       "      <td>372891</td>\n",
       "      <td>5</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>TOSP_COUNT</td>\n",
       "      <td>381210</td>\n",
       "      <td>12</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>TOSP_STRING</td>\n",
       "      <td>267026</td>\n",
       "      <td>17489</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>TOSP_CODE1</td>\n",
       "      <td>267026</td>\n",
       "      <td>2114</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>TOSP_CODE2</td>\n",
       "      <td>85649</td>\n",
       "      <td>1571</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TOSP_CODE3</td>\n",
       "      <td>12950</td>\n",
       "      <td>965</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>TOSP_CODE4</td>\n",
       "      <td>3265</td>\n",
       "      <td>491</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>TOSP_DESC1</td>\n",
       "      <td>381210</td>\n",
       "      <td>1807</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>TOSP_DESC2</td>\n",
       "      <td>85649</td>\n",
       "      <td>1358</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TOSP_DESC3</td>\n",
       "      <td>12950</td>\n",
       "      <td>852</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>TOSP_DESC4</td>\n",
       "      <td>3265</td>\n",
       "      <td>442</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NATIONALITY</td>\n",
       "      <td>381210</td>\n",
       "      <td>163</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>RESID_CTY</td>\n",
       "      <td>381205</td>\n",
       "      <td>132</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>RESID_POSTALCODE</td>\n",
       "      <td>381198</td>\n",
       "      <td>41533</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>DOB</td>\n",
       "      <td>381210</td>\n",
       "      <td>31946</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NONRESID_FLAG</td>\n",
       "      <td>381210</td>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>PATIENT_SID</td>\n",
       "      <td>381210</td>\n",
       "      <td>266574</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>PATIENT_NUMBER</td>\n",
       "      <td>381210</td>\n",
       "      <td>266574</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>GENDER</td>\n",
       "      <td>381210</td>\n",
       "      <td>3</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>DECEASED_FLAG</td>\n",
       "      <td>381210</td>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>MARITAL_STATUS</td>\n",
       "      <td>363544</td>\n",
       "      <td>8</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>RELIGION</td>\n",
       "      <td>172705</td>\n",
       "      <td>17</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>LANGUAGE</td>\n",
       "      <td>381210</td>\n",
       "      <td>1</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>VIP_FLAG</td>\n",
       "      <td>381210</td>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>RACE</td>\n",
       "      <td>380824</td>\n",
       "      <td>8</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>DRG_CODE</td>\n",
       "      <td>372890</td>\n",
       "      <td>682</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>DRG_DESC</td>\n",
       "      <td>381210</td>\n",
       "      <td>681</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>PAYER_CODE1_V</td>\n",
       "      <td>381210</td>\n",
       "      <td>482</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>PAYER_NAME1_V</td>\n",
       "      <td>381210</td>\n",
       "      <td>425</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>PAYER_CODE2_V</td>\n",
       "      <td>149363</td>\n",
       "      <td>378</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>PAYER_NAME2_V</td>\n",
       "      <td>149363</td>\n",
       "      <td>330</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>PAYER_CODE3_V</td>\n",
       "      <td>53232</td>\n",
       "      <td>231</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>PAYER_NAME3_V</td>\n",
       "      <td>53232</td>\n",
       "      <td>203</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>PAYER_CODE4_V</td>\n",
       "      <td>2380</td>\n",
       "      <td>89</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>PAYER_NAME4_V</td>\n",
       "      <td>2380</td>\n",
       "      <td>78</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>PACKAGE_CODE</td>\n",
       "      <td>91099</td>\n",
       "      <td>185</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>PACKAGE_PRICE</td>\n",
       "      <td>91099</td>\n",
       "      <td>473</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>PACKAGE_EXCL</td>\n",
       "      <td>91099</td>\n",
       "      <td>51908</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>PACKAGE_ADJ</td>\n",
       "      <td>91099</td>\n",
       "      <td>46968</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>PACKAGE_DESC</td>\n",
       "      <td>91099</td>\n",
       "      <td>187</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>PACKAGE_CODE1</td>\n",
       "      <td>91099</td>\n",
       "      <td>185</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>PACKAGE_CODE2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>PACKAGE_DESC1</td>\n",
       "      <td>91099</td>\n",
       "      <td>187</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>PACKAGE_DESC2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>ICD_CODE1</td>\n",
       "      <td>377241</td>\n",
       "      <td>7143</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>ICD_CODE2</td>\n",
       "      <td>166166</td>\n",
       "      <td>5699</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>ICD_CODE3</td>\n",
       "      <td>68949</td>\n",
       "      <td>3411</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>ICDCODE_STRING</td>\n",
       "      <td>377241</td>\n",
       "      <td>72388</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>PROF_FEE</td>\n",
       "      <td>381210</td>\n",
       "      <td>77917</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>TOTAL_FEES</td>\n",
       "      <td>381210</td>\n",
       "      <td>326929</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>WRITE_OFF</td>\n",
       "      <td>381210</td>\n",
       "      <td>2452</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>PCT_WRITE_OFF</td>\n",
       "      <td>381210</td>\n",
       "      <td>15983</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>WRITE_OFF_LABEL</td>\n",
       "      <td>381210</td>\n",
       "      <td>2</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                colName  non-null values  unique           dtype\n",
       "0           INSTITUTION           381210       4          object\n",
       "1           CASE_NUMBER           381210  381210           int64\n",
       "2        TOTAL_PAID_AMT           381210  326907         float64\n",
       "3          PAYER_CODE_1           381210     482          object\n",
       "4          PAYER_NAME_1           381210     425          object\n",
       "5      PAYER_1_PAID_AMT           381210  308341         float64\n",
       "6          PAYER_CODE_2           149318     378          object\n",
       "7          PAYER_NAME_2           149318     329          object\n",
       "8      PAYER_2_PAID_AMT           381210  117053         float64\n",
       "9          PAYER_CODE_3            53205     230          object\n",
       "10         PAYER_NAME_3            53205     201          object\n",
       "11     PAYER_3_PAID_AMT           381210   42878         float64\n",
       "12         PAYER_CODE_4             2373      89          object\n",
       "13         PAYER_NAME_4             2373      78          object\n",
       "14     PAYER_4_PAID_AMT           381210    2198         float64\n",
       "15         PAYER_CODE_5               52      21          object\n",
       "16         PAYER_NAME_5               52      18          object\n",
       "17     PAYER_5_PAID_AMT           381210      41         float64\n",
       "18            CASE_TYPE           381210       1          object\n",
       "19             BED_TYPE           381210      10          object\n",
       "20        REFERRAL_TYPE           381206      50          object\n",
       "21   TREATMENT_CATEGORY           381210      60          object\n",
       "22        ADMISSION_DTE           381210    1095  datetime64[ns]\n",
       "23       ADMISSION_TYPE           381210       8          object\n",
       "24        DISCHARGE_DTE           381210    1128  datetime64[ns]\n",
       "25       DISCHARGE_TYPE           381210       9           int64\n",
       "26  DISCHARGE_TYPE_DESC           381210       9          object\n",
       "27             LOS_DAYS           381210     147           int64\n",
       "28          DOCTOR_CODE           381209    1247          object\n",
       "29          DOCTOR_NAME           381210    1247          object\n",
       "30       SPECIALTY_CODE           381173      36         float64\n",
       "31       SPECIALTY_DESC           381173      36          object\n",
       "32        SPECIALTY_GRP           372891       5         float64\n",
       "33           TOSP_COUNT           381210      12           int64\n",
       "34          TOSP_STRING           267026   17489          object\n",
       "35           TOSP_CODE1           267026    2114          object\n",
       "36           TOSP_CODE2            85649    1571          object\n",
       "37           TOSP_CODE3            12950     965          object\n",
       "38           TOSP_CODE4             3265     491          object\n",
       "39           TOSP_DESC1           381210    1807          object\n",
       "40           TOSP_DESC2            85649    1358          object\n",
       "41           TOSP_DESC3            12950     852          object\n",
       "42           TOSP_DESC4             3265     442          object\n",
       "43          NATIONALITY           381210     163          object\n",
       "44            RESID_CTY           381205     132          object\n",
       "45     RESID_POSTALCODE           381198   41533          object\n",
       "46                  DOB           381210   31946  datetime64[ns]\n",
       "47        NONRESID_FLAG           381210       2          object\n",
       "48          PATIENT_SID           381210  266574           int64\n",
       "49       PATIENT_NUMBER           381210  266574           int64\n",
       "50               GENDER           381210       3          object\n",
       "51        DECEASED_FLAG           381210       2          object\n",
       "52       MARITAL_STATUS           363544       8          object\n",
       "53             RELIGION           172705      17          object\n",
       "54             LANGUAGE           381210       1          object\n",
       "55             VIP_FLAG           381210       2          object\n",
       "56                 RACE           380824       8          object\n",
       "57             DRG_CODE           372890     682          object\n",
       "58             DRG_DESC           381210     681          object\n",
       "59        PAYER_CODE1_V           381210     482          object\n",
       "60        PAYER_NAME1_V           381210     425          object\n",
       "61        PAYER_CODE2_V           149363     378          object\n",
       "62        PAYER_NAME2_V           149363     330          object\n",
       "63        PAYER_CODE3_V            53232     231          object\n",
       "64        PAYER_NAME3_V            53232     203          object\n",
       "65        PAYER_CODE4_V             2380      89          object\n",
       "66        PAYER_NAME4_V             2380      78          object\n",
       "67         PACKAGE_CODE            91099     185         float64\n",
       "68        PACKAGE_PRICE            91099     473         float64\n",
       "69         PACKAGE_EXCL            91099   51908         float64\n",
       "70          PACKAGE_ADJ            91099   46968         float64\n",
       "71         PACKAGE_DESC            91099     187          object\n",
       "72        PACKAGE_CODE1            91099     185         float64\n",
       "73        PACKAGE_CODE2                1       1         float64\n",
       "74        PACKAGE_DESC1            91099     187          object\n",
       "75        PACKAGE_DESC2                1       1          object\n",
       "76            ICD_CODE1           377241    7143          object\n",
       "77            ICD_CODE2           166166    5699          object\n",
       "78            ICD_CODE3            68949    3411          object\n",
       "79       ICDCODE_STRING           377241   72388          object\n",
       "80             PROF_FEE           381210   77917         float64\n",
       "81           TOTAL_FEES           381210  326929         float64\n",
       "82            WRITE_OFF           381210    2452         float64\n",
       "83        PCT_WRITE_OFF           381210   15983         float64\n",
       "84      WRITE_OFF_LABEL           381210       2           int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "info = []\n",
    "for col in df.columns:\n",
    "    non_null  = len(df) - np.sum(pd.isna(df[col]))\n",
    "    num_unique = df[col].nunique()\n",
    "    col_type = str(df[col].dtype)\n",
    "\n",
    "    info.append([col, non_null, num_unique, col_type])\n",
    "\n",
    "features_info = pd.DataFrame(info, columns = ['colName','non-null values', 'unique', 'dtype'])\n",
    "\n",
    "display(features_info)\n",
    "#features_info.to_csv('Info_List.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 381210 entries, 0 to 381209\n",
      "Data columns (total 44 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   INSTITUTION          381210 non-null  int64  \n",
      " 1   CASE_NUMBER          381210 non-null  int64  \n",
      " 2   PAYER_CODE_1         381210 non-null  int64  \n",
      " 3   PAYER_CODE_2         381210 non-null  int64  \n",
      " 4   PAYER_CODE_3         381210 non-null  int64  \n",
      " 5   PAYER_CODE_4         381210 non-null  int64  \n",
      " 6   PAYER_CODE_5         381210 non-null  int64  \n",
      " 7   BED_TYPE             381210 non-null  int64  \n",
      " 8   REFERRAL_TYPE        381210 non-null  int64  \n",
      " 9   TREATMENT_CATEGORY   381210 non-null  int64  \n",
      " 10  ADMISSION_TYPE       381210 non-null  int64  \n",
      " 11  DISCHARGE_TYPE       381210 non-null  int64  \n",
      " 12  LOS_DAYS             381210 non-null  int64  \n",
      " 13  DOCTOR_CODE          381210 non-null  int64  \n",
      " 14  SPECIALTY_CODE       381173 non-null  float64\n",
      " 15  SPECIALTY_GRP        372891 non-null  float64\n",
      " 16  TOSP_COUNT           381210 non-null  int64  \n",
      " 17  TOSP_CODE1           381210 non-null  int64  \n",
      " 18  TOSP_CODE2           381210 non-null  int64  \n",
      " 19  TOSP_CODE3           381210 non-null  int64  \n",
      " 20  TOSP_CODE4           381210 non-null  int64  \n",
      " 21  NATIONALITY          381210 non-null  int64  \n",
      " 22  RESID_CTY            381210 non-null  int64  \n",
      " 23  RESID_POSTALCODE     381210 non-null  int64  \n",
      " 24  NONRESID_FLAG        381210 non-null  int64  \n",
      " 25  GENDER               381210 non-null  int64  \n",
      " 26  DECEASED_FLAG        381210 non-null  int64  \n",
      " 27  MARITAL_STATUS       381210 non-null  int64  \n",
      " 28  RELIGION             381210 non-null  int64  \n",
      " 29  VIP_FLAG             381210 non-null  int64  \n",
      " 30  RACE                 381210 non-null  int64  \n",
      " 31  ICD_CODE1            381210 non-null  int64  \n",
      " 32  ICD_CODE2            381210 non-null  int64  \n",
      " 33  ICD_CODE3            381210 non-null  int64  \n",
      " 34  WRITE_OFF_LABEL      381210 non-null  int64  \n",
      " 35  ADMISSION_DTE_year   381210 non-null  int64  \n",
      " 36  ADMISSION_DTE_month  381210 non-null  int64  \n",
      " 37  ADMISSION_DTE_day    381210 non-null  int64  \n",
      " 38  DISCHARGE_DTE_year   381210 non-null  int64  \n",
      " 39  DISCHARGE_DTE_month  381210 non-null  int64  \n",
      " 40  DISCHARGE_DTE_day    381210 non-null  int64  \n",
      " 41  DOB_year             381210 non-null  int64  \n",
      " 42  DOB_month            381210 non-null  int64  \n",
      " 43  DOB_day              381210 non-null  int64  \n",
      "dtypes: float64(2), int64(42)\n",
      "memory usage: 128.0 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colName</th>\n",
       "      <th>non-null values</th>\n",
       "      <th>unique</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INSTITUTION</td>\n",
       "      <td>381210</td>\n",
       "      <td>4</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CASE_NUMBER</td>\n",
       "      <td>381210</td>\n",
       "      <td>381210</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PAYER_CODE_1</td>\n",
       "      <td>381210</td>\n",
       "      <td>482</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PAYER_CODE_2</td>\n",
       "      <td>381210</td>\n",
       "      <td>379</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PAYER_CODE_3</td>\n",
       "      <td>381210</td>\n",
       "      <td>231</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PAYER_CODE_4</td>\n",
       "      <td>381210</td>\n",
       "      <td>90</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PAYER_CODE_5</td>\n",
       "      <td>381210</td>\n",
       "      <td>22</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BED_TYPE</td>\n",
       "      <td>381210</td>\n",
       "      <td>10</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>REFERRAL_TYPE</td>\n",
       "      <td>381210</td>\n",
       "      <td>51</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TREATMENT_CATEGORY</td>\n",
       "      <td>381210</td>\n",
       "      <td>60</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ADMISSION_TYPE</td>\n",
       "      <td>381210</td>\n",
       "      <td>8</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DISCHARGE_TYPE</td>\n",
       "      <td>381210</td>\n",
       "      <td>9</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LOS_DAYS</td>\n",
       "      <td>381210</td>\n",
       "      <td>147</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DOCTOR_CODE</td>\n",
       "      <td>381210</td>\n",
       "      <td>1248</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SPECIALTY_CODE</td>\n",
       "      <td>381173</td>\n",
       "      <td>36</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SPECIALTY_GRP</td>\n",
       "      <td>372891</td>\n",
       "      <td>5</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TOSP_COUNT</td>\n",
       "      <td>381210</td>\n",
       "      <td>12</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TOSP_CODE1</td>\n",
       "      <td>381210</td>\n",
       "      <td>2115</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TOSP_CODE2</td>\n",
       "      <td>381210</td>\n",
       "      <td>1572</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TOSP_CODE3</td>\n",
       "      <td>381210</td>\n",
       "      <td>966</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TOSP_CODE4</td>\n",
       "      <td>381210</td>\n",
       "      <td>492</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NATIONALITY</td>\n",
       "      <td>381210</td>\n",
       "      <td>163</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RESID_CTY</td>\n",
       "      <td>381210</td>\n",
       "      <td>133</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RESID_POSTALCODE</td>\n",
       "      <td>381210</td>\n",
       "      <td>41534</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NONRESID_FLAG</td>\n",
       "      <td>381210</td>\n",
       "      <td>2</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>GENDER</td>\n",
       "      <td>381210</td>\n",
       "      <td>3</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DECEASED_FLAG</td>\n",
       "      <td>381210</td>\n",
       "      <td>2</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MARITAL_STATUS</td>\n",
       "      <td>381210</td>\n",
       "      <td>9</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RELIGION</td>\n",
       "      <td>381210</td>\n",
       "      <td>18</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>VIP_FLAG</td>\n",
       "      <td>381210</td>\n",
       "      <td>2</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RACE</td>\n",
       "      <td>381210</td>\n",
       "      <td>9</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ICD_CODE1</td>\n",
       "      <td>381210</td>\n",
       "      <td>7144</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ICD_CODE2</td>\n",
       "      <td>381210</td>\n",
       "      <td>5700</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ICD_CODE3</td>\n",
       "      <td>381210</td>\n",
       "      <td>3412</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>WRITE_OFF_LABEL</td>\n",
       "      <td>381210</td>\n",
       "      <td>2</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ADMISSION_DTE_year</td>\n",
       "      <td>381210</td>\n",
       "      <td>3</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ADMISSION_DTE_month</td>\n",
       "      <td>381210</td>\n",
       "      <td>12</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ADMISSION_DTE_day</td>\n",
       "      <td>381210</td>\n",
       "      <td>31</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>DISCHARGE_DTE_year</td>\n",
       "      <td>381210</td>\n",
       "      <td>4</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>DISCHARGE_DTE_month</td>\n",
       "      <td>381210</td>\n",
       "      <td>12</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>DISCHARGE_DTE_day</td>\n",
       "      <td>381210</td>\n",
       "      <td>31</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>DOB_year</td>\n",
       "      <td>381210</td>\n",
       "      <td>110</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>DOB_month</td>\n",
       "      <td>381210</td>\n",
       "      <td>12</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>DOB_day</td>\n",
       "      <td>381210</td>\n",
       "      <td>31</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                colName  non-null values  unique    dtype\n",
       "0           INSTITUTION           381210       4    int64\n",
       "1           CASE_NUMBER           381210  381210    int64\n",
       "2          PAYER_CODE_1           381210     482    int64\n",
       "3          PAYER_CODE_2           381210     379    int64\n",
       "4          PAYER_CODE_3           381210     231    int64\n",
       "5          PAYER_CODE_4           381210      90    int64\n",
       "6          PAYER_CODE_5           381210      22    int64\n",
       "7              BED_TYPE           381210      10    int64\n",
       "8         REFERRAL_TYPE           381210      51    int64\n",
       "9    TREATMENT_CATEGORY           381210      60    int64\n",
       "10       ADMISSION_TYPE           381210       8    int64\n",
       "11       DISCHARGE_TYPE           381210       9    int64\n",
       "12             LOS_DAYS           381210     147    int64\n",
       "13          DOCTOR_CODE           381210    1248    int64\n",
       "14       SPECIALTY_CODE           381173      36  float64\n",
       "15        SPECIALTY_GRP           372891       5  float64\n",
       "16           TOSP_COUNT           381210      12    int64\n",
       "17           TOSP_CODE1           381210    2115    int64\n",
       "18           TOSP_CODE2           381210    1572    int64\n",
       "19           TOSP_CODE3           381210     966    int64\n",
       "20           TOSP_CODE4           381210     492    int64\n",
       "21          NATIONALITY           381210     163    int64\n",
       "22            RESID_CTY           381210     133    int64\n",
       "23     RESID_POSTALCODE           381210   41534    int64\n",
       "24        NONRESID_FLAG           381210       2    int64\n",
       "25               GENDER           381210       3    int64\n",
       "26        DECEASED_FLAG           381210       2    int64\n",
       "27       MARITAL_STATUS           381210       9    int64\n",
       "28             RELIGION           381210      18    int64\n",
       "29             VIP_FLAG           381210       2    int64\n",
       "30                 RACE           381210       9    int64\n",
       "31            ICD_CODE1           381210    7144    int64\n",
       "32            ICD_CODE2           381210    5700    int64\n",
       "33            ICD_CODE3           381210    3412    int64\n",
       "34      WRITE_OFF_LABEL           381210       2    int64\n",
       "35   ADMISSION_DTE_year           381210       3    int64\n",
       "36  ADMISSION_DTE_month           381210      12    int64\n",
       "37    ADMISSION_DTE_day           381210      31    int64\n",
       "38   DISCHARGE_DTE_year           381210       4    int64\n",
       "39  DISCHARGE_DTE_month           381210      12    int64\n",
       "40    DISCHARGE_DTE_day           381210      31    int64\n",
       "41             DOB_year           381210     110    int64\n",
       "42            DOB_month           381210      12    int64\n",
       "43              DOB_day           381210      31    int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# drop unnecessary columns\n",
    "col_drop = ['PAYER_NAME_1', 'PAYER_NAME_2', 'PAYER_NAME_3', 'PAYER_NAME_4', 'PAYER_NAME_5', 'CASE_TYPE',\n",
    "            'DISCHARGE_TYPE_DESC', 'DOCTOR_NAME', 'SPECIALTY_DESC','TOSP_STRING', 'TOSP_DESC1', 'TOSP_DESC2',\n",
    "            'TOSP_DESC3', 'TOSP_DESC4', 'DRG_DESC', 'PAYER_CODE1_V', 'PAYER_NAME1_V', 'PAYER_CODE2_V',\n",
    "            'PAYER_NAME2_V', 'PAYER_CODE3_V', 'PAYER_NAME3_V', 'PAYER_CODE4_V', 'PAYER_NAME4_V',\n",
    "            'PACKAGE_DESC', 'PACKAGE_DESC1', 'PACKAGE_DESC2','ICDCODE_STRING', 'PACKAGE_CODE',\n",
    "            'PACKAGE_PRICE', 'PACKAGE_EXCL', 'PACKAGE_ADJ', 'PACKAGE_CODE1', 'PACKAGE_CODE2','WRITE_OFF',\n",
    "            'PCT_WRITE_OFF','PROF_FEE','TOTAL_FEES','TOTAL_PAID_AMT','PAYER_1_PAID_AMT','PAYER_2_PAID_AMT',\n",
    "            'PAYER_3_PAID_AMT','PAYER_4_PAID_AMT','PAYER_5_PAID_AMT','PATIENT_SID','PATIENT_NUMBER','LANGUAGE','DRG_CODE']\n",
    "df1 =  df.drop(col_drop, axis=1)\n",
    "\n",
    "# convert dates\n",
    "col_dt = df1.select_dtypes(include=np.datetime64).columns\n",
    "for col in col_dt:\n",
    "    df1[col+'_year'] = df1[col].dt.year\n",
    "    df1[col+'_month'] = df1[col].dt.month\n",
    "    df1[col+'_day'] = df1[col].dt.day\n",
    "df1 =  df1.drop(col_dt, axis=1)\n",
    "\n",
    "# convert objects to factors\n",
    "col_obj = df1.select_dtypes(include=np.object).columns\n",
    "for col in col_obj:\n",
    "    df1[col] = pd.factorize(df1[col])[0] +1\n",
    "\n",
    "print(df1.info())\n",
    "\n",
    "\n",
    "# Checking df1 columns\n",
    "info = []\n",
    "for col in df1.columns:\n",
    "    non_null  = len(df1) - np.sum(pd.isna(df1[col]))\n",
    "    num_unique = df1[col].nunique()\n",
    "    col_type = str(df1[col].dtype)\n",
    "\n",
    "    info.append([col, non_null, num_unique, col_type])\n",
    "\n",
    "features_info = pd.DataFrame(info, columns = ['colName','non-null values', 'unique', 'dtype'])\n",
    "\n",
    "display(features_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381210\n"
     ]
    }
   ],
   "source": [
    "print(df['CASE_NUMBER'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [INSTITUTION, CASE_NUMBER, TOTAL_PAID_AMT, PAYER_CODE_1, PAYER_NAME_1, PAYER_1_PAID_AMT, PAYER_CODE_2, PAYER_NAME_2, PAYER_2_PAID_AMT, PAYER_CODE_3, PAYER_NAME_3, PAYER_3_PAID_AMT, PAYER_CODE_4, PAYER_NAME_4, PAYER_4_PAID_AMT, PAYER_CODE_5, PAYER_NAME_5, PAYER_5_PAID_AMT, CASE_TYPE, BED_TYPE, REFERRAL_TYPE, TREATMENT_CATEGORY, ADMISSION_DTE, ADMISSION_TYPE, DISCHARGE_DTE, DISCHARGE_TYPE, DISCHARGE_TYPE_DESC, LOS_DAYS, DOCTOR_CODE, DOCTOR_NAME, SPECIALTY_CODE, SPECIALTY_DESC, SPECIALTY_GRP, TOSP_COUNT, TOSP_STRING, TOSP_CODE1, TOSP_CODE2, TOSP_CODE3, TOSP_CODE4, TOSP_DESC1, TOSP_DESC2, TOSP_DESC3, TOSP_DESC4, NATIONALITY, RESID_CTY, RESID_POSTALCODE, DOB, NONRESID_FLAG, PATIENT_SID, PATIENT_NUMBER, GENDER, DECEASED_FLAG, MARITAL_STATUS, RELIGION, LANGUAGE, VIP_FLAG, RACE, DRG_CODE, DRG_DESC, PAYER_CODE1_V, PAYER_NAME1_V, PAYER_CODE2_V, PAYER_NAME2_V, PAYER_CODE3_V, PAYER_NAME3_V, PAYER_CODE4_V, PAYER_NAME4_V, PACKAGE_CODE, PACKAGE_PRICE, PACKAGE_EXCL, PACKAGE_ADJ, PACKAGE_DESC, PACKAGE_CODE1, PACKAGE_CODE2, PACKAGE_DESC1, PACKAGE_DESC2, ICD_CODE1, ICD_CODE2, ICD_CODE3, ICDCODE_STRING, PROF_FEE, TOTAL_FEES, WRITE_OFF, PCT_WRITE_OFF, WRITE_OFF_LABEL]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 85 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[df.duplicated(subset=['CASE_NUMBER'], keep=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1440 with 45 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1.hist(figsize=(15,20), layout=(-1,5))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        INSTITUTION  CASE_NUMBER  PAYER_CODE_1  PAYER_CODE_2  PAYER_CODE_3  \\\n",
      "0                 1   1014019571             1             1             1   \n",
      "1                 1   1014022893             1             0             0   \n",
      "2                 1   1014060798             2             2             0   \n",
      "3                 1   1015067071             1             1             0   \n",
      "4                 1   1015073219             1             0             0   \n",
      "...             ...          ...           ...           ...           ...   \n",
      "381205            4   4019117108            16             0             0   \n",
      "381206            4   4019117110             4             0             0   \n",
      "381207            4   4019117113             1             1             8   \n",
      "381208            4   4019117132             8             0             0   \n",
      "381209            4   4019117134             4             0             0   \n",
      "\n",
      "        PAYER_CODE_4  PAYER_CODE_5  BED_TYPE  REFERRAL_TYPE  \\\n",
      "0                  0             0         1              1   \n",
      "1                  0             0         2              1   \n",
      "2                  0             0         1              1   \n",
      "3                  0             0         3              1   \n",
      "4                  0             0         2              1   \n",
      "...              ...           ...       ...            ...   \n",
      "381205             0             0        10              1   \n",
      "381206             0             0        10              3   \n",
      "381207             0             0         1              3   \n",
      "381208             0             0        10              3   \n",
      "381209             0             0         1              3   \n",
      "\n",
      "        TREATMENT_CATEGORY  ...  WRITE_OFF_LABEL  ADMISSION_DTE_year  \\\n",
      "0                        1  ...                0                2018   \n",
      "1                        2  ...                0                2018   \n",
      "2                        1  ...                0                2018   \n",
      "3                        3  ...                0                2017   \n",
      "4                        4  ...                0                2019   \n",
      "...                    ...  ...              ...                 ...   \n",
      "381205                  52  ...                0                2019   \n",
      "381206                  52  ...                0                2019   \n",
      "381207                   1  ...                0                2019   \n",
      "381208                  52  ...                0                2019   \n",
      "381209                   1  ...                0                2019   \n",
      "\n",
      "        ADMISSION_DTE_month  ADMISSION_DTE_day  DISCHARGE_DTE_year  \\\n",
      "0                         5                  1                2018   \n",
      "1                         4                 24                2018   \n",
      "2                         4                 11                2018   \n",
      "3                         1                 26                2017   \n",
      "4                         9                 26                2019   \n",
      "...                     ...                ...                 ...   \n",
      "381205                   12                 31                2020   \n",
      "381206                   12                 31                2020   \n",
      "381207                   12                 31                2020   \n",
      "381208                   12                 31                2020   \n",
      "381209                   12                 31                2020   \n",
      "\n",
      "        DISCHARGE_DTE_month  DISCHARGE_DTE_day  DOB_year  DOB_month  DOB_day  \n",
      "0                         5                  4      1980         12       25  \n",
      "1                         4                 24      1951         10       26  \n",
      "2                         4                 12      1948          6        6  \n",
      "3                         1                 27      1980          1       23  \n",
      "4                         9                 26      1972          5       25  \n",
      "...                     ...                ...       ...        ...      ...  \n",
      "381205                    1                  3      1964         10       29  \n",
      "381206                    1                  4      1982          7       28  \n",
      "381207                    1                  6      1937          7       16  \n",
      "381208                    1                  1      1964          6       13  \n",
      "381209                    1                  1      2015         12       23  \n",
      "\n",
      "[381210 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1980\n",
      "1    1951\n",
      "2    1948\n",
      "3    1980\n",
      "4    1972\n",
      "Name: DOB_year, dtype: int64\n",
      "        ADMISSION_DTE_year  DOB_year  Admission_Age\n",
      "0                     2018      1980             38\n",
      "1                     2018      1951             67\n",
      "2                     2018      1948             70\n",
      "3                     2017      1980             37\n",
      "4                     2019      1972             47\n",
      "...                    ...       ...            ...\n",
      "381205                2019      1964             55\n",
      "381206                2019      1982             37\n",
      "381207                2019      1937             82\n",
      "381208                2019      1964             55\n",
      "381209                2019      2015              4\n",
      "\n",
      "[381210 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Aggregate 'Admission_Age' using 'ADMISSION_DTE', 'DOB'\n",
    "print(df1['DOB_year'].head())\n",
    "df1['Admission_Age'] = df1['ADMISSION_DTE_year']-df1['DOB_year']\n",
    "print(df1[['ADMISSION_DTE_year', 'DOB_year','Admission_Age']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data to Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(381210, 45)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.index = df1.CASE_NUMBER\n",
    "df1 =  df1.drop(['CASE_NUMBER'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NAN with zeros\n",
    "df1 = df1.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             INSTITUTION  PAYER_CODE_1  PAYER_CODE_2  PAYER_CODE_3  \\\n",
      "CASE_NUMBER                                                          \n",
      "1014019571             1             1             1             1   \n",
      "1014022893             1             1             0             0   \n",
      "1014060798             1             2             2             0   \n",
      "1015067071             1             1             1             0   \n",
      "1015073219             1             1             0             0   \n",
      "...                  ...           ...           ...           ...   \n",
      "4019117108             4            16             0             0   \n",
      "4019117110             4             4             0             0   \n",
      "4019117113             4             1             1             8   \n",
      "4019117132             4             8             0             0   \n",
      "4019117134             4             4             0             0   \n",
      "\n",
      "             PAYER_CODE_4  PAYER_CODE_5  BED_TYPE  REFERRAL_TYPE  \\\n",
      "CASE_NUMBER                                                        \n",
      "1014019571              0             0         1              1   \n",
      "1014022893              0             0         2              1   \n",
      "1014060798              0             0         1              1   \n",
      "1015067071              0             0         3              1   \n",
      "1015073219              0             0         2              1   \n",
      "...                   ...           ...       ...            ...   \n",
      "4019117108              0             0        10              1   \n",
      "4019117110              0             0        10              3   \n",
      "4019117113              0             0         1              3   \n",
      "4019117132              0             0        10              3   \n",
      "4019117134              0             0         1              3   \n",
      "\n",
      "             TREATMENT_CATEGORY  ADMISSION_TYPE  ...  ADMISSION_DTE_year  \\\n",
      "CASE_NUMBER                                      ...                       \n",
      "1014019571                    1               1  ...                2018   \n",
      "1014022893                    2               2  ...                2018   \n",
      "1014060798                    1               3  ...                2018   \n",
      "1015067071                    3               4  ...                2017   \n",
      "1015073219                    4               2  ...                2019   \n",
      "...                         ...             ...  ...                 ...   \n",
      "4019117108                   52               4  ...                2019   \n",
      "4019117110                   52               4  ...                2019   \n",
      "4019117113                    1               3  ...                2019   \n",
      "4019117132                   52               4  ...                2019   \n",
      "4019117134                    1               3  ...                2019   \n",
      "\n",
      "             ADMISSION_DTE_month  ADMISSION_DTE_day  DISCHARGE_DTE_year  \\\n",
      "CASE_NUMBER                                                               \n",
      "1014019571                     5                  1                2018   \n",
      "1014022893                     4                 24                2018   \n",
      "1014060798                     4                 11                2018   \n",
      "1015067071                     1                 26                2017   \n",
      "1015073219                     9                 26                2019   \n",
      "...                          ...                ...                 ...   \n",
      "4019117108                    12                 31                2020   \n",
      "4019117110                    12                 31                2020   \n",
      "4019117113                    12                 31                2020   \n",
      "4019117132                    12                 31                2020   \n",
      "4019117134                    12                 31                2020   \n",
      "\n",
      "             DISCHARGE_DTE_month  DISCHARGE_DTE_day  DOB_year  DOB_month  \\\n",
      "CASE_NUMBER                                                                \n",
      "1014019571                     5                  4      1980         12   \n",
      "1014022893                     4                 24      1951         10   \n",
      "1014060798                     4                 12      1948          6   \n",
      "1015067071                     1                 27      1980          1   \n",
      "1015073219                     9                 26      1972          5   \n",
      "...                          ...                ...       ...        ...   \n",
      "4019117108                     1                  3      1964         10   \n",
      "4019117110                     1                  4      1982          7   \n",
      "4019117113                     1                  6      1937          7   \n",
      "4019117132                     1                  1      1964          6   \n",
      "4019117134                     1                  1      2015         12   \n",
      "\n",
      "             DOB_day  Admission_Age  \n",
      "CASE_NUMBER                          \n",
      "1014019571        25             38  \n",
      "1014022893        26             67  \n",
      "1014060798         6             70  \n",
      "1015067071        23             37  \n",
      "1015073219        25             47  \n",
      "...              ...            ...  \n",
      "4019117108        29             55  \n",
      "4019117110        28             37  \n",
      "4019117113        16             82  \n",
      "4019117132        13             55  \n",
      "4019117134        23              4  \n",
      "\n",
      "[381210 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('PARKWAY_PROCESSED_4_NAN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop(\"WRITE_OFF_LABEL\",axis = 1)\n",
    "y = df1.WRITE_OFF_LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "#importing train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=1/3,random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INSTITUTION</th>\n",
       "      <th>PAYER_CODE_1</th>\n",
       "      <th>PAYER_CODE_2</th>\n",
       "      <th>PAYER_CODE_3</th>\n",
       "      <th>PAYER_CODE_4</th>\n",
       "      <th>PAYER_CODE_5</th>\n",
       "      <th>BED_TYPE</th>\n",
       "      <th>REFERRAL_TYPE</th>\n",
       "      <th>TREATMENT_CATEGORY</th>\n",
       "      <th>ADMISSION_TYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>ADMISSION_DTE_year</th>\n",
       "      <th>ADMISSION_DTE_month</th>\n",
       "      <th>ADMISSION_DTE_day</th>\n",
       "      <th>DISCHARGE_DTE_year</th>\n",
       "      <th>DISCHARGE_DTE_month</th>\n",
       "      <th>DISCHARGE_DTE_day</th>\n",
       "      <th>DOB_year</th>\n",
       "      <th>DOB_month</th>\n",
       "      <th>DOB_day</th>\n",
       "      <th>Admission_Age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CASE_NUMBER</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1014019571</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1980</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014022893</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>1951</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014060798</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1948</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015067071</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015073219</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>1972</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             INSTITUTION  PAYER_CODE_1  PAYER_CODE_2  PAYER_CODE_3  \\\n",
       "CASE_NUMBER                                                          \n",
       "1014019571             1             1             1             1   \n",
       "1014022893             1             1             0             0   \n",
       "1014060798             1             2             2             0   \n",
       "1015067071             1             1             1             0   \n",
       "1015073219             1             1             0             0   \n",
       "\n",
       "             PAYER_CODE_4  PAYER_CODE_5  BED_TYPE  REFERRAL_TYPE  \\\n",
       "CASE_NUMBER                                                        \n",
       "1014019571              0             0         1              1   \n",
       "1014022893              0             0         2              1   \n",
       "1014060798              0             0         1              1   \n",
       "1015067071              0             0         3              1   \n",
       "1015073219              0             0         2              1   \n",
       "\n",
       "             TREATMENT_CATEGORY  ADMISSION_TYPE  ...  ADMISSION_DTE_year  \\\n",
       "CASE_NUMBER                                      ...                       \n",
       "1014019571                    1               1  ...                2018   \n",
       "1014022893                    2               2  ...                2018   \n",
       "1014060798                    1               3  ...                2018   \n",
       "1015067071                    3               4  ...                2017   \n",
       "1015073219                    4               2  ...                2019   \n",
       "\n",
       "             ADMISSION_DTE_month  ADMISSION_DTE_day  DISCHARGE_DTE_year  \\\n",
       "CASE_NUMBER                                                               \n",
       "1014019571                     5                  1                2018   \n",
       "1014022893                     4                 24                2018   \n",
       "1014060798                     4                 11                2018   \n",
       "1015067071                     1                 26                2017   \n",
       "1015073219                     9                 26                2019   \n",
       "\n",
       "             DISCHARGE_DTE_month  DISCHARGE_DTE_day  DOB_year  DOB_month  \\\n",
       "CASE_NUMBER                                                                \n",
       "1014019571                     5                  4      1980         12   \n",
       "1014022893                     4                 24      1951         10   \n",
       "1014060798                     4                 12      1948          6   \n",
       "1015067071                     1                 27      1980          1   \n",
       "1015073219                     9                 26      1972          5   \n",
       "\n",
       "             DOB_day  Admission_Age  \n",
       "CASE_NUMBER                          \n",
       "1014019571        25             38  \n",
       "1014022893        26             67  \n",
       "1014060798         6             70  \n",
       "1015067071        23             37  \n",
       "1015073219        25             47  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CASE_NUMBER\n",
       "1014019571    0\n",
       "1014022893    0\n",
       "1014060798    0\n",
       "1015067071    0\n",
       "1015073219    0\n",
       "Name: WRITE_OFF_LABEL, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CASE_NUMBER\n",
       "4017062839    0\n",
       "1019051639    0\n",
       "4018041857    0\n",
       "1017016510    0\n",
       "2019044524    0\n",
       "Name: WRITE_OFF_LABEL, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape is  (254140, 43)\n",
      "X_test.shape is  (127070, 43)\n",
      "y_train.shape is  (254140,)\n",
      "y_test.shape is  (127070,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train.shape is ', X_train.shape)\n",
    "print('X_test.shape is ', X_test.shape)\n",
    "print('y_train.shape is ', y_train.shape)\n",
    "print('y_test.shape is ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)  \n",
    "X_test_scaled = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(X_train)\n",
    "np.where(np.isnan(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPARATION WITH SMOTE (Synthetic Minority Over Sampling Technique)\n",
    "## UNSCALED FOR DECISION TREE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7.0\n",
      "X_train.shape is  (254140, 43)\n",
      "X_train_unscaled_ss_01.shape is  (279121, 43)\n",
      "y_train_unscaled_ss_01.shape is  (279121,)\n",
      "X_train_unscaled_ss_02.shape is  (304496, 43)\n",
      "y_train_unscaled_ss_02.shape is  (304496,)\n",
      "X_train_unscaled_ss_03.shape is  (329871, 43)\n",
      "y_train_unscaled_ss_03.shape is  (329871,)\n",
      "X_train_unscaled_ss_04.shape is  (355245, 43)\n",
      "y_train_unscaled_ss_04.shape is  (355245,)\n",
      "X_train_unscaled_ss_05.shape is  (380620, 43)\n",
      "y_train_unscaled_ss_05.shape is  (380620,)\n",
      "X_train_unscaled_ss_06.shape is  (405995, 43)\n",
      "y_train_unscaled_ss_06.shape is  (405995,)\n",
      "X_train_unscaled_ss_07.shape is  (431369, 43)\n",
      "y_train_unscaled_ss_07.shape is  (431369,)\n",
      "X_train_unscaled_ss_08.shape is  (456744, 43)\n",
      "y_train_unscaled_ss_08.shape is  (456744,)\n",
      "X_train_unscaled_ss_09.shape is  (482119, 43)\n",
      "y_train_unscaled_ss_09.shape is  (482119,)\n",
      "X_train_unscaled_ss_10.shape is  (507494, 43)\n",
      "y_train_unscaled_ss_10.shape is  (507494,)\n",
      "X_test.shape is  (127070, 43)\n",
      "y_test.shape is  (127070,)\n"
     ]
    }
   ],
   "source": [
    "# Created few instances of smote here\n",
    "# sm_ss_10 = normal smote with default sampling strategy = 1.0 -> this will create synthetic data for minority class such that the\n",
    "#   number of samples for minority class equals with samples for majority class\n",
    "# sm_ss_01 = smote with sampling strategy = 0.1\n",
    "# sm_ss_02 = smote with sampling strategy = 0.2\n",
    "# sm_ss_03 = smote with sampling strategy = 0.3 etc\n",
    "# this will create synthetic data for minority class such that the number of samples for minority class = 0.1,0.2, 0.3 or 10%,20%,30% of the number of samples from majority class\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "print(imblearn.__version__)\n",
    "\n",
    "sm_ss_01 = SMOTE(random_state=55,sampling_strategy=0.1)\n",
    "sm_ss_02 = SMOTE(random_state=55,sampling_strategy=0.2)\n",
    "sm_ss_03 = SMOTE(random_state=55,sampling_strategy=0.3)\n",
    "sm_ss_04 = SMOTE(random_state=55,sampling_strategy=0.4)\n",
    "sm_ss_05 = SMOTE(random_state=55,sampling_strategy=0.5)\n",
    "sm_ss_06 = SMOTE(random_state=55,sampling_strategy=0.6)\n",
    "sm_ss_07 = SMOTE(random_state=55,sampling_strategy=0.7)\n",
    "sm_ss_08 = SMOTE(random_state=55,sampling_strategy=0.8)\n",
    "sm_ss_09 = SMOTE(random_state=55,sampling_strategy=0.9)\n",
    "sm_ss_10 = SMOTE(random_state=55) # default sampling strategy is 1.0\n",
    "\n",
    "\n",
    "# Preparing Unscaled Training Data with Smote\n",
    "X_train_unscaled_ss_01, y_train_unscaled_ss_01 = sm_ss_01.fit_sample(X_train,y_train)\n",
    "X_train_unscaled_ss_02, y_train_unscaled_ss_02 = sm_ss_02.fit_sample(X_train,y_train)\n",
    "X_train_unscaled_ss_03, y_train_unscaled_ss_03 = sm_ss_03.fit_sample(X_train,y_train)\n",
    "X_train_unscaled_ss_04, y_train_unscaled_ss_04 = sm_ss_04.fit_sample(X_train,y_train)\n",
    "X_train_unscaled_ss_05, y_train_unscaled_ss_05 = sm_ss_05.fit_sample(X_train,y_train)\n",
    "X_train_unscaled_ss_06, y_train_unscaled_ss_06 = sm_ss_06.fit_sample(X_train,y_train)\n",
    "X_train_unscaled_ss_07, y_train_unscaled_ss_07 = sm_ss_07.fit_sample(X_train,y_train)\n",
    "X_train_unscaled_ss_08, y_train_unscaled_ss_08 = sm_ss_08.fit_sample(X_train,y_train)\n",
    "X_train_unscaled_ss_09, y_train_unscaled_ss_09 = sm_ss_09.fit_sample(X_train,y_train)\n",
    "X_train_unscaled_ss_10, y_train_unscaled_ss_10 = sm_ss_10.fit_sample(X_train,y_train)\n",
    "\n",
    "# Checking Data Shape\n",
    "print('X_train.shape is ', X_train.shape)\n",
    "print('X_train_unscaled_ss_01.shape is ', X_train_unscaled_ss_01.shape)\n",
    "print('y_train_unscaled_ss_01.shape is ', y_train_unscaled_ss_01.shape)\n",
    "print('X_train_unscaled_ss_02.shape is ', X_train_unscaled_ss_02.shape)\n",
    "print('y_train_unscaled_ss_02.shape is ', y_train_unscaled_ss_02.shape)\n",
    "print('X_train_unscaled_ss_03.shape is ', X_train_unscaled_ss_03.shape)\n",
    "print('y_train_unscaled_ss_03.shape is ', y_train_unscaled_ss_03.shape)\n",
    "print('X_train_unscaled_ss_04.shape is ', X_train_unscaled_ss_04.shape)\n",
    "print('y_train_unscaled_ss_04.shape is ', y_train_unscaled_ss_04.shape)\n",
    "print('X_train_unscaled_ss_05.shape is ', X_train_unscaled_ss_05.shape)\n",
    "print('y_train_unscaled_ss_05.shape is ', y_train_unscaled_ss_05.shape)\n",
    "print('X_train_unscaled_ss_06.shape is ', X_train_unscaled_ss_06.shape)\n",
    "print('y_train_unscaled_ss_06.shape is ', y_train_unscaled_ss_06.shape)\n",
    "print('X_train_unscaled_ss_07.shape is ', X_train_unscaled_ss_07.shape)\n",
    "print('y_train_unscaled_ss_07.shape is ', y_train_unscaled_ss_07.shape)\n",
    "print('X_train_unscaled_ss_08.shape is ', X_train_unscaled_ss_08.shape)\n",
    "print('y_train_unscaled_ss_08.shape is ', y_train_unscaled_ss_08.shape)\n",
    "print('X_train_unscaled_ss_09.shape is ', X_train_unscaled_ss_09.shape)\n",
    "print('y_train_unscaled_ss_09.shape is ', y_train_unscaled_ss_09.shape)\n",
    "print('X_train_unscaled_ss_10.shape is ', X_train_unscaled_ss_10.shape)\n",
    "print('y_train_unscaled_ss_10.shape is ', y_train_unscaled_ss_10.shape)\n",
    "\n",
    "print('X_test.shape is ', X_test.shape)\n",
    "print('y_test.shape is ', y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train unique values  {0: 253747, 1: 393}\n",
      "y_train_unscaled_ss_01 unique values  {0: 253747, 1: 25374}\n",
      "y_train_unscaled_ss_02 unique values  {0: 253747, 1: 50749}\n",
      "y_train_unscaled_ss_03 unique values  {0: 253747, 1: 76124}\n",
      "y_train_unscaled_ss_04 unique values  {0: 253747, 1: 101498}\n",
      "y_train_unscaled_ss_05 unique values  {0: 253747, 1: 126873}\n",
      "y_train_unscaled_ss_06 unique values  {0: 253747, 1: 152248}\n",
      "y_train_unscaled_ss_07 unique values  {0: 253747, 1: 177622}\n",
      "y_train_unscaled_ss_08 unique values  {0: 253747, 1: 202997}\n",
      "y_train_unscaled_ss_09 unique values  {0: 253747, 1: 228372}\n",
      "y_train_unscaled_ss_10 unique values  {0: 253747, 1: 253747}\n"
     ]
    }
   ],
   "source": [
    "# Checking Unique Values in y_train\n",
    "unique, count = np.unique(y_train, return_counts=True)\n",
    "y_train_dict_value_count = {k:v for (k,v) in zip(unique,count)}\n",
    "print('y_train unique values ',y_train_dict_value_count)\n",
    "\n",
    "unique, count = np.unique(y_train_unscaled_ss_01, return_counts=True)\n",
    "y_train_dict_value_count = {k:v for (k,v) in zip(unique,count)}\n",
    "print('y_train_unscaled_ss_01 unique values ',y_train_dict_value_count)\n",
    "\n",
    "unique, count = np.unique(y_train_unscaled_ss_02, return_counts=True)\n",
    "y_train_dict_value_count = {k:v for (k,v) in zip(unique,count)}\n",
    "print('y_train_unscaled_ss_02 unique values ',y_train_dict_value_count)\n",
    "\n",
    "unique, count = np.unique(y_train_unscaled_ss_03, return_counts=True)\n",
    "y_train_dict_value_count = {k:v for (k,v) in zip(unique,count)}\n",
    "print('y_train_unscaled_ss_03 unique values ',y_train_dict_value_count)\n",
    "\n",
    "unique, count = np.unique(y_train_unscaled_ss_04, return_counts=True)\n",
    "y_train_dict_value_count = {k:v for (k,v) in zip(unique,count)}\n",
    "print('y_train_unscaled_ss_04 unique values ',y_train_dict_value_count)\n",
    "\n",
    "unique, count = np.unique(y_train_unscaled_ss_05, return_counts=True)\n",
    "y_train_dict_value_count = {k:v for (k,v) in zip(unique,count)}\n",
    "print('y_train_unscaled_ss_05 unique values ',y_train_dict_value_count)\n",
    "\n",
    "unique, count = np.unique(y_train_unscaled_ss_06, return_counts=True)\n",
    "y_train_dict_value_count = {k:v for (k,v) in zip(unique,count)}\n",
    "print('y_train_unscaled_ss_06 unique values ',y_train_dict_value_count)\n",
    "\n",
    "unique, count = np.unique(y_train_unscaled_ss_07, return_counts=True)\n",
    "y_train_dict_value_count = {k:v for (k,v) in zip(unique,count)}\n",
    "print('y_train_unscaled_ss_07 unique values ',y_train_dict_value_count)\n",
    "\n",
    "unique, count = np.unique(y_train_unscaled_ss_08, return_counts=True)\n",
    "y_train_dict_value_count = {k:v for (k,v) in zip(unique,count)}\n",
    "print('y_train_unscaled_ss_08 unique values ',y_train_dict_value_count)\n",
    "\n",
    "unique, count = np.unique(y_train_unscaled_ss_09, return_counts=True)\n",
    "y_train_dict_value_count = {k:v for (k,v) in zip(unique,count)}\n",
    "print('y_train_unscaled_ss_09 unique values ',y_train_dict_value_count)\n",
    "\n",
    "unique, count = np.unique(y_train_unscaled_ss_10, return_counts=True)\n",
    "y_train_dict_value_count = {k:v for (k,v) in zip(unique,count)}\n",
    "print('y_train_unscaled_ss_10 unique values ',y_train_dict_value_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECISION TREE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree WITHOUT SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.997\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(criterion='entropy',random_state=0)\n",
    "dt.fit(X_train, y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(dt.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(dt.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[126639    235]\n",
      " [   160     36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.13      0.18      0.15       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.57      0.59      0.58    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DT visualizatin method 1\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "dotfile = open(\"dt_unscaled_NoSMOTE.dot\", 'w')\n",
    "\n",
    "export_graphviz(dt, out_file=dotfile,feature_names = X.columns,class_names=['0','1'])\n",
    "dotfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DT visualizatin method 2\n",
    "# need to install Graphviz first https://graphviz.gitlab.io/_pages/Download/Download_windows.html\n",
    "from sklearn.tree import export_graphviz\n",
    "import os\n",
    "\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "\n",
    "export_graphviz(dt, out_file='tree.dot', feature_names=X.columns,class_names=['0','1'])\n",
    "# Convert to png using system command (requires Graphviz)\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'ParkwayWriteOff_Dectree_Unscaled_NoSmote.png', '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "#from IPython.display import Image\n",
    "#Image(filename = 'ParkwayWriteOff_tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for DT = 0.9968914771385851\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "print(\"Accuracy Score for DT =\", metrics.accuracy_score(y_test, y_pred_dt))\n",
    "fpr_dt, tpr_dt, _ = metrics.roc_curve(y_test,  y_pred_dt)\n",
    "auc_dt = metrics.roc_auc_score(y_test, y_pred_dt)\n",
    "#HC: Plot ROC for Decision Tree dt\n",
    "plt.plot(fpr_dt,tpr_dt,label=\"Decision Tree, auc=\"+str(auc_dt))\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, INSTITUTION, Score: 0.01934\n",
      "Feature: 1, PAYER_CODE_1, Score: 0.03681\n",
      "Feature: 2, PAYER_CODE_2, Score: 0.02216\n",
      "Feature: 3, PAYER_CODE_3, Score: 0.01535\n",
      "Feature: 4, PAYER_CODE_4, Score: 0.00904\n",
      "Feature: 5, PAYER_CODE_5, Score: 0.00111\n",
      "Feature: 6, BED_TYPE, Score: 0.01119\n",
      "Feature: 7, REFERRAL_TYPE, Score: 0.00796\n",
      "Feature: 8, TREATMENT_CATEGORY, Score: 0.01098\n",
      "Feature: 9, ADMISSION_TYPE, Score: 0.00686\n",
      "Feature: 10, DISCHARGE_TYPE, Score: 0.01140\n",
      "Feature: 11, LOS_DAYS, Score: 0.12961\n",
      "Feature: 12, DOCTOR_CODE, Score: 0.05360\n",
      "Feature: 13, SPECIALTY_CODE, Score: 0.02632\n",
      "Feature: 14, SPECIALTY_GRP, Score: 0.00703\n",
      "Feature: 15, TOSP_COUNT, Score: 0.00703\n",
      "Feature: 16, TOSP_CODE1, Score: 0.02049\n",
      "Feature: 17, TOSP_CODE2, Score: 0.00688\n",
      "Feature: 18, TOSP_CODE3, Score: 0.00841\n",
      "Feature: 19, TOSP_CODE4, Score: 0.00265\n",
      "Feature: 20, NATIONALITY, Score: 0.13238\n",
      "Feature: 21, RESID_CTY, Score: 0.00187\n",
      "Feature: 22, RESID_POSTALCODE, Score: 0.04216\n",
      "Feature: 23, NONRESID_FLAG, Score: 0.00065\n",
      "Feature: 24, GENDER, Score: 0.00437\n",
      "Feature: 25, DECEASED_FLAG, Score: 0.00240\n",
      "Feature: 26, MARITAL_STATUS, Score: 0.00985\n",
      "Feature: 27, RELIGION, Score: 0.02610\n",
      "Feature: 28, VIP_FLAG, Score: 0.00170\n",
      "Feature: 29, RACE, Score: 0.01596\n",
      "Feature: 30, ICD_CODE1, Score: 0.04774\n",
      "Feature: 31, ICD_CODE2, Score: 0.02557\n",
      "Feature: 32, ICD_CODE3, Score: 0.01369\n",
      "Feature: 33, WRITE_OFF_LABEL, Score: 0.02559\n",
      "Feature: 34, ADMISSION_DTE_year, Score: 0.01972\n",
      "Feature: 35, ADMISSION_DTE_month, Score: 0.03661\n",
      "Feature: 36, ADMISSION_DTE_day, Score: 0.01120\n",
      "Feature: 37, DISCHARGE_DTE_year, Score: 0.02051\n",
      "Feature: 38, DISCHARGE_DTE_month, Score: 0.03217\n",
      "Feature: 39, DISCHARGE_DTE_day, Score: 0.03302\n",
      "Feature: 40, DOB_year, Score: 0.02575\n",
      "Feature: 41, DOB_month, Score: 0.03296\n",
      "Feature: 42, DOB_day, Score: 0.02384\n",
      "\n",
      "Below is the barchart for each feature's value\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'INSTITUTION': 0.01933654296793789,\n",
       " 'PAYER_CODE_1': 0.036814886884121475,\n",
       " 'PAYER_CODE_2': 0.022159918425252938,\n",
       " 'PAYER_CODE_3': 0.01535438009579856,\n",
       " 'PAYER_CODE_4': 0.009043561558009535,\n",
       " 'PAYER_CODE_5': 0.0011073723244204626,\n",
       " 'BED_TYPE': 0.011186677843464447,\n",
       " 'REFERRAL_TYPE': 0.00796318485209775,\n",
       " 'TREATMENT_CATEGORY': 0.010980409048713727,\n",
       " 'ADMISSION_TYPE': 0.0068584024935060715,\n",
       " 'DISCHARGE_TYPE': 0.011399908654919988,\n",
       " 'LOS_DAYS': 0.12961352537703144,\n",
       " 'DOCTOR_CODE': 0.05359913820407048,\n",
       " 'SPECIALTY_CODE': 0.02631911443613569,\n",
       " 'SPECIALTY_GRP': 0.007026431733646504,\n",
       " 'TOSP_COUNT': 0.0070255766966710095,\n",
       " 'TOSP_CODE1': 0.0204855328935143,\n",
       " 'TOSP_CODE2': 0.0068755142450453305,\n",
       " 'TOSP_CODE3': 0.00840649983265432,\n",
       " 'TOSP_CODE4': 0.0026539920639506616,\n",
       " 'NATIONALITY': 0.1323751781499683,\n",
       " 'RESID_CTY': 0.0018662577832660278,\n",
       " 'RESID_POSTALCODE': 0.042158441532338435,\n",
       " 'NONRESID_FLAG': 0.000650361326532613,\n",
       " 'GENDER': 0.004373843409589594,\n",
       " 'DECEASED_FLAG': 0.002398470568087725,\n",
       " 'MARITAL_STATUS': 0.009845736872417476,\n",
       " 'RELIGION': 0.02609708292688212,\n",
       " 'VIP_FLAG': 0.0017016230009593947,\n",
       " 'RACE': 0.0159590755156103,\n",
       " 'ICD_CODE1': 0.04774064338129034,\n",
       " 'ICD_CODE2': 0.02556966665647704,\n",
       " 'ICD_CODE3': 0.013694048439569647,\n",
       " 'WRITE_OFF_LABEL': 0.025585032854699964,\n",
       " 'ADMISSION_DTE_year': 0.019720733155864183,\n",
       " 'ADMISSION_DTE_month': 0.036613947018954256,\n",
       " 'ADMISSION_DTE_day': 0.01120254261353958,\n",
       " 'DISCHARGE_DTE_year': 0.02050607222396658,\n",
       " 'DISCHARGE_DTE_month': 0.032165010499630685,\n",
       " 'DISCHARGE_DTE_day': 0.03302283070892219,\n",
       " 'DOB_year': 0.025747826375221897,\n",
       " 'DOB_month': 0.032958089883609265,\n",
       " 'DOB_day': 0.02383691447163984}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method 1: with bar chart\n",
    "from matplotlib import pyplot\n",
    "# get importance\n",
    "importance = dt.feature_importances_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, %s, Score: %.5f' % (i,df1.columns[i],v))\n",
    "# plot feature importance\n",
    "print()\n",
    "print('Below is the barchart for each feature\\'s value')\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "#pyplot.bar([diabetes_data.columns[x] for x in range(len(importance))], importance)\n",
    "pyplot.show()\n",
    "\n",
    "#Method 2: Simply showing numbers\n",
    "feature_importances = dict(zip(df1.columns, dt.feature_importances_))\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree WITH SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree WITH SMOTE SS = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.995\n",
      "[[126438    436]\n",
      " [   162     34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.07      0.17      0.10       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.54      0.59      0.55    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt.fit(X_train_unscaled_ss_01, y_train_unscaled_ss_01)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(dt.score(X_train_unscaled_ss_01, y_train_unscaled_ss_01)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(dt.score(X_test, y_test)))\n",
    "y_pred = dt.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree WITH SMOTE SS = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.995\n",
      "[[126425    449]\n",
      " [   157     39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.08      0.20      0.11       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.54      0.60      0.56    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt.fit(X_train_unscaled_ss_02, y_train_unscaled_ss_02)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(dt.score(X_train_unscaled_ss_02, y_train_unscaled_ss_02)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(dt.score(X_test, y_test)))\n",
    "y_pred = dt.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree WITH SMOTE SS = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.995\n",
      "[[126400    474]\n",
      " [   161     35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.07      0.18      0.10       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.53      0.59      0.55    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt.fit(X_train_unscaled_ss_03, y_train_unscaled_ss_03)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(dt.score(X_train_unscaled_ss_03, y_train_unscaled_ss_03)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(dt.score(X_test, y_test)))\n",
    "y_pred = dt.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree WITH SMOTE SS = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.995\n",
      "[[126445    429]\n",
      " [   163     33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.07      0.17      0.10       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.54      0.58      0.55    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt.fit(X_train_unscaled_ss_04, y_train_unscaled_ss_04)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(dt.score(X_train_unscaled_ss_04, y_train_unscaled_ss_04)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(dt.score(X_test, y_test)))\n",
    "y_pred = dt.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree WITH SMOTE SS = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.995\n",
      "[[126388    486]\n",
      " [   168     28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.05      0.14      0.08       196\n",
      "\n",
      "    accuracy                           0.99    127070\n",
      "   macro avg       0.53      0.57      0.54    127070\n",
      "weighted avg       1.00      0.99      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt.fit(X_train_unscaled_ss_05, y_train_unscaled_ss_05)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(dt.score(X_train_unscaled_ss_05, y_train_unscaled_ss_05)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(dt.score(X_test, y_test)))\n",
    "y_pred = dt.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree WITH SMOTE SS = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.995\n",
      "[[126457    417]\n",
      " [   165     31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.07      0.16      0.10       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.53      0.58      0.55    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt.fit(X_train_unscaled_ss_06, y_train_unscaled_ss_06)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(dt.score(X_train_unscaled_ss_06, y_train_unscaled_ss_06)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(dt.score(X_test, y_test)))\n",
    "y_pred = dt.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree WITH SMOTE SS = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.995\n",
      "[[126446    428]\n",
      " [   161     35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.08      0.18      0.11       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.54      0.59      0.55    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt.fit(X_train_unscaled_ss_07, y_train_unscaled_ss_07)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(dt.score(X_train_unscaled_ss_07, y_train_unscaled_ss_07)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(dt.score(X_test, y_test)))\n",
    "y_pred = dt.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree WITH SMOTE SS = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.995\n",
      "[[126433    441]\n",
      " [   165     31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.07      0.16      0.09       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.53      0.58      0.55    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt.fit(X_train_unscaled_ss_08, y_train_unscaled_ss_08)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(dt.score(X_train_unscaled_ss_08, y_train_unscaled_ss_08)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(dt.score(X_test, y_test)))\n",
    "y_pred = dt.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree WITH SMOTE SS = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.995\n",
      "[[126418    456]\n",
      " [   168     28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.06      0.14      0.08       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.53      0.57      0.54    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt.fit(X_train_unscaled_ss_09, y_train_unscaled_ss_09)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(dt.score(X_train_unscaled_ss_09, y_train_unscaled_ss_09)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(dt.score(X_test, y_test)))\n",
    "y_pred = dt.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree WITH SMOTE SS = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.995\n",
      "[[126427    447]\n",
      " [   167     29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.06      0.15      0.09       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.53      0.57      0.54    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt.fit(X_train_unscaled_ss_10, y_train_unscaled_ss_10)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(dt.score(X_train_unscaled_ss_10, y_train_unscaled_ss_10)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(dt.score(X_test, y_test)))\n",
    "y_pred = dt.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPARATION WITH SMOTE (Synthetic Minority Over Sampling Technique)\n",
    "## SCALED FOR OTHER MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape is  (254140, 43)\n",
      "X_train_scaled_ss_01.shape is  (279121, 43)\n",
      "y_train_scaled_ss_01.shape is  (279121,)\n",
      "X_train_scaled_ss_02.shape is  (304496, 43)\n",
      "y_train_scaled_ss_02.shape is  (304496,)\n",
      "X_train_scaled_ss_03.shape is  (329871, 43)\n",
      "y_train_scaled_ss_03.shape is  (329871,)\n",
      "X_train_scaled_ss_04.shape is  (355245, 43)\n",
      "y_train_scaled_ss_04.shape is  (355245,)\n",
      "X_train_scaled_ss_05.shape is  (380620, 43)\n",
      "y_train_scaled_ss_05.shape is  (380620,)\n",
      "X_train_scaled_ss_06.shape is  (405995, 43)\n",
      "y_train_scaled_ss_06.shape is  (405995,)\n",
      "X_train_scaled_ss_07.shape is  (431369, 43)\n",
      "y_train_scaled_ss_07.shape is  (431369,)\n",
      "X_train_scaled_ss_08.shape is  (456744, 43)\n",
      "y_train_scaled_ss_08.shape is  (456744,)\n",
      "X_train_scaled_ss_09.shape is  (482119, 43)\n",
      "y_train_scaled_ss_09.shape is  (482119,)\n",
      "X_train_scaled_ss_10.shape is  (507494, 43)\n",
      "y_train_scaled_ss_10.shape is  (507494,)\n",
      "X_test.shape is  (127070, 43)\n",
      "y_test.shape is  (127070,)\n"
     ]
    }
   ],
   "source": [
    "sm_ss_01 = SMOTE(random_state=55,sampling_strategy=0.1)\n",
    "sm_ss_02 = SMOTE(random_state=55,sampling_strategy=0.2)\n",
    "sm_ss_03 = SMOTE(random_state=55,sampling_strategy=0.3)\n",
    "sm_ss_04 = SMOTE(random_state=55,sampling_strategy=0.4)\n",
    "sm_ss_05 = SMOTE(random_state=55,sampling_strategy=0.5)\n",
    "sm_ss_06 = SMOTE(random_state=55,sampling_strategy=0.6)\n",
    "sm_ss_07 = SMOTE(random_state=55,sampling_strategy=0.7)\n",
    "sm_ss_08 = SMOTE(random_state=55,sampling_strategy=0.8)\n",
    "sm_ss_09 = SMOTE(random_state=55,sampling_strategy=0.9)\n",
    "sm_ss_10 = SMOTE(random_state=55) # default sampling strategy is 1.0\n",
    "\n",
    "\n",
    "# Preparing Scaled Training Data with Smote\n",
    "X_train_scaled_ss_01, y_train_scaled_ss_01 = sm_ss_01.fit_sample(X_train_scaled,y_train)\n",
    "X_train_scaled_ss_02, y_train_scaled_ss_02 = sm_ss_02.fit_sample(X_train_scaled,y_train)\n",
    "X_train_scaled_ss_03, y_train_scaled_ss_03 = sm_ss_03.fit_sample(X_train_scaled,y_train)\n",
    "X_train_scaled_ss_04, y_train_scaled_ss_04 = sm_ss_04.fit_sample(X_train_scaled,y_train)\n",
    "X_train_scaled_ss_05, y_train_scaled_ss_05 = sm_ss_05.fit_sample(X_train_scaled,y_train)\n",
    "X_train_scaled_ss_06, y_train_scaled_ss_06 = sm_ss_06.fit_sample(X_train_scaled,y_train)\n",
    "X_train_scaled_ss_07, y_train_scaled_ss_07 = sm_ss_07.fit_sample(X_train_scaled,y_train)\n",
    "X_train_scaled_ss_08, y_train_scaled_ss_08 = sm_ss_08.fit_sample(X_train_scaled,y_train)\n",
    "X_train_scaled_ss_09, y_train_scaled_ss_09 = sm_ss_09.fit_sample(X_train_scaled,y_train)\n",
    "X_train_scaled_ss_10, y_train_scaled_ss_10 = sm_ss_10.fit_sample(X_train_scaled,y_train)\n",
    "\n",
    "# Checking Data Shape\n",
    "print('X_train.shape is ', X_train.shape)\n",
    "print('X_train_scaled_ss_01.shape is ', X_train_scaled_ss_01.shape)\n",
    "print('y_train_scaled_ss_01.shape is ', y_train_scaled_ss_01.shape)\n",
    "print('X_train_scaled_ss_02.shape is ', X_train_scaled_ss_02.shape)\n",
    "print('y_train_scaled_ss_02.shape is ', y_train_scaled_ss_02.shape)\n",
    "print('X_train_scaled_ss_03.shape is ', X_train_scaled_ss_03.shape)\n",
    "print('y_train_scaled_ss_03.shape is ', y_train_scaled_ss_03.shape)\n",
    "print('X_train_scaled_ss_04.shape is ', X_train_scaled_ss_04.shape)\n",
    "print('y_train_scaled_ss_04.shape is ', y_train_scaled_ss_04.shape)\n",
    "print('X_train_scaled_ss_05.shape is ', X_train_scaled_ss_05.shape)\n",
    "print('y_train_scaled_ss_05.shape is ', y_train_scaled_ss_05.shape)\n",
    "print('X_train_scaled_ss_06.shape is ', X_train_scaled_ss_06.shape)\n",
    "print('y_train_scaled_ss_06.shape is ', y_train_scaled_ss_06.shape)\n",
    "print('X_train_scaled_ss_07.shape is ', X_train_scaled_ss_07.shape)\n",
    "print('y_train_scaled_ss_07.shape is ', y_train_scaled_ss_07.shape)\n",
    "print('X_train_scaled_ss_08.shape is ', X_train_scaled_ss_08.shape)\n",
    "print('y_train_scaled_ss_08.shape is ', y_train_scaled_ss_08.shape)\n",
    "print('X_train_scaled_ss_09.shape is ', X_train_scaled_ss_09.shape)\n",
    "print('y_train_scaled_ss_09.shape is ', y_train_scaled_ss_09.shape)\n",
    "print('X_train_scaled_ss_10.shape is ', X_train_scaled_ss_10.shape)\n",
    "print('y_train_scaled_ss_10.shape is ', y_train_scaled_ss_10.shape)\n",
    "\n",
    "print('X_test.shape is ', X_test.shape)\n",
    "print('y_test.shape is ', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train unique values  {0: 253747, 1: 393}\n",
      "y_train_scaled_ss_01 unique values  {0: 253747, 1: 25374}\n",
      "y_train_scaled_ss_02 unique values  {0: 253747, 1: 50749}\n",
      "y_train_scaled_ss_03 unique values  {0: 253747, 1: 76124}\n",
      "y_train_scaled_ss_04 unique values  {0: 253747, 1: 101498}\n",
      "y_train_scaled_ss_05 unique values  {0: 253747, 1: 126873}\n",
      "y_train_scaled_ss_06 unique values  {0: 253747, 1: 152248}\n",
      "y_train_scaled_ss_07 unique values  {0: 253747, 1: 177622}\n",
      "y_train_scaled_ss_08 unique values  {0: 253747, 1: 202997}\n",
      "y_train_scaled_ss_09 unique values  {0: 253747, 1: 228372}\n",
      "y_train_scaled_ss_10 unique values  {0: 253747, 1: 253747}\n"
     ]
    }
   ],
   "source": [
    "# Checking Unique Values in y_train\n",
    "unique, count = np.unique(y_train, return_counts=True)\n",
    "y_train_dict_value_count = {k:v for (k,v) in zip(unique,count)}\n",
    "print('y_train unique values ',y_train_dict_value_count)\n",
    "\n",
    "unique, count = np.unique(y_train_scaled_ss_01, return_counts=True)\n",
    "y_train_dict_value_count = {k:v for (k,v) in zip(unique,count)}\n",
    "print('y_train_scaled_ss_01 unique values ',y_train_dict_value_count)\n",
    "\n",
    "unique, count = np.unique(y_train_scaled_ss_02, return_counts=True)\n",
    "y_train_dict_value_count = {k:v for (k,v) in zip(unique,count)}\n",
    "print('y_train_scaled_ss_02 unique values ',y_train_dict_value_count)\n",
    "\n",
    "unique, count = np.unique(y_train_scaled_ss_03, return_counts=True)\n",
    "y_train_dict_value_count = {k:v for (k,v) in zip(unique,count)}\n",
    "print('y_train_scaled_ss_03 unique values ',y_train_dict_value_count)\n",
    "\n",
    "unique, count = np.unique(y_train_scaled_ss_04, return_counts=True)\n",
    "y_train_dict_value_count = {k:v for (k,v) in zip(unique,count)}\n",
    "print('y_train_scaled_ss_04 unique values ',y_train_dict_value_count)\n",
    "\n",
    "unique, count = np.unique(y_train_scaled_ss_05, return_counts=True)\n",
    "y_train_dict_value_count = {k:v for (k,v) in zip(unique,count)}\n",
    "print('y_train_scaled_ss_05 unique values ',y_train_dict_value_count)\n",
    "\n",
    "unique, count = np.unique(y_train_scaled_ss_06, return_counts=True)\n",
    "y_train_dict_value_count = {k:v for (k,v) in zip(unique,count)}\n",
    "print('y_train_scaled_ss_06 unique values ',y_train_dict_value_count)\n",
    "\n",
    "unique, count = np.unique(y_train_scaled_ss_07, return_counts=True)\n",
    "y_train_dict_value_count = {k:v for (k,v) in zip(unique,count)}\n",
    "print('y_train_scaled_ss_07 unique values ',y_train_dict_value_count)\n",
    "\n",
    "unique, count = np.unique(y_train_scaled_ss_08, return_counts=True)\n",
    "y_train_dict_value_count = {k:v for (k,v) in zip(unique,count)}\n",
    "print('y_train_scaled_ss_08 unique values ',y_train_dict_value_count)\n",
    "\n",
    "unique, count = np.unique(y_train_scaled_ss_09, return_counts=True)\n",
    "y_train_dict_value_count = {k:v for (k,v) in zip(unique,count)}\n",
    "print('y_train_scaled_ss_09 unique values ',y_train_dict_value_count)\n",
    "\n",
    "unique, count = np.unique(y_train_scaled_ss_10, return_counts=True)\n",
    "y_train_dict_value_count = {k:v for (k,v) in zip(unique,count)}\n",
    "print('y_train_scaled_ss_10 unique values ',y_train_dict_value_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.998\n",
      "Test set score: 0.998\n",
      "[[126872      2]\n",
      " [   193      3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.60      0.02      0.03       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.80      0.51      0.51    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=0.01).fit(X_train_scaled, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test_scaled, y_test)))\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression With SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression With SMOTE ss=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.933\n",
      "Test set score: 0.988\n",
      "[[125541   1333]\n",
      " [   134     62]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    126874\n",
      "           1       0.04      0.32      0.08       196\n",
      "\n",
      "    accuracy                           0.99    127070\n",
      "   macro avg       0.52      0.65      0.54    127070\n",
      "weighted avg       1.00      0.99      0.99    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=0.01).fit(X_train_scaled_ss_01, y_train_scaled_ss_01)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train_scaled_ss_01, y_train_scaled_ss_01)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test_scaled, y_test)))\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression With SMOTE ss=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.888\n",
      "Test set score: 0.977\n",
      "[[124063   2811]\n",
      " [   117     79]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99    126874\n",
      "           1       0.03      0.40      0.05       196\n",
      "\n",
      "    accuracy                           0.98    127070\n",
      "   macro avg       0.51      0.69      0.52    127070\n",
      "weighted avg       1.00      0.98      0.99    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=0.01).fit(X_train_scaled_ss_02, y_train_scaled_ss_02)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train_scaled_ss_02, y_train_scaled_ss_02)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test_scaled, y_test)))\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression With SMOTE ss=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.856\n",
      "Test set score: 0.963\n",
      "[[122267   4607]\n",
      " [   101     95]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98    126874\n",
      "           1       0.02      0.48      0.04       196\n",
      "\n",
      "    accuracy                           0.96    127070\n",
      "   macro avg       0.51      0.72      0.51    127070\n",
      "weighted avg       1.00      0.96      0.98    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=0.01).fit(X_train_scaled_ss_03, y_train_scaled_ss_03)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train_scaled_ss_03, y_train_scaled_ss_03)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test_scaled, y_test)))\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression With SMOTE ss=0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.831\n",
      "Test set score: 0.948\n",
      "[[120416   6458]\n",
      " [    91    105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97    126874\n",
      "           1       0.02      0.54      0.03       196\n",
      "\n",
      "    accuracy                           0.95    127070\n",
      "   macro avg       0.51      0.74      0.50    127070\n",
      "weighted avg       1.00      0.95      0.97    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=0.01).fit(X_train_scaled_ss_04, y_train_scaled_ss_04)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train_scaled_ss_04, y_train_scaled_ss_04)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test_scaled, y_test)))\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression With SMOTE ss=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.810\n",
      "Test set score: 0.932\n",
      "[[118326   8548]\n",
      " [    84    112]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96    126874\n",
      "           1       0.01      0.57      0.03       196\n",
      "\n",
      "    accuracy                           0.93    127070\n",
      "   macro avg       0.51      0.75      0.50    127070\n",
      "weighted avg       1.00      0.93      0.96    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=0.01).fit(X_train_scaled_ss_05, y_train_scaled_ss_05)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train_scaled_ss_05, y_train_scaled_ss_05)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test_scaled, y_test)))\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression With SMOTE ss=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.795\n",
      "Test set score: 0.915\n",
      "[[116167  10707]\n",
      " [    71    125]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96    126874\n",
      "           1       0.01      0.64      0.02       196\n",
      "\n",
      "    accuracy                           0.92    127070\n",
      "   macro avg       0.51      0.78      0.49    127070\n",
      "weighted avg       1.00      0.92      0.95    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=0.01).fit(X_train_scaled_ss_06, y_train_scaled_ss_06)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train_scaled_ss_06, y_train_scaled_ss_06)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test_scaled, y_test)))\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression With SMOTE ss=0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.787\n",
      "Test set score: 0.897\n",
      "[[113840  13034]\n",
      " [    63    133]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95    126874\n",
      "           1       0.01      0.68      0.02       196\n",
      "\n",
      "    accuracy                           0.90    127070\n",
      "   macro avg       0.50      0.79      0.48    127070\n",
      "weighted avg       1.00      0.90      0.94    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=0.01).fit(X_train_scaled_ss_07, y_train_scaled_ss_07)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train_scaled_ss_07, y_train_scaled_ss_07)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test_scaled, y_test)))\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression With SMOTE ss=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.780\n",
      "Test set score: 0.878\n",
      "[[111423  15451]\n",
      " [    56    140]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93    126874\n",
      "           1       0.01      0.71      0.02       196\n",
      "\n",
      "    accuracy                           0.88    127070\n",
      "   macro avg       0.50      0.80      0.48    127070\n",
      "weighted avg       1.00      0.88      0.93    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=0.01).fit(X_train_scaled_ss_08, y_train_scaled_ss_08)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train_scaled_ss_08, y_train_scaled_ss_08)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test_scaled, y_test)))\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression With SMOTE ss=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.778\n",
      "Test set score: 0.859\n",
      "[[108978  17896]\n",
      " [    52    144]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92    126874\n",
      "           1       0.01      0.73      0.02       196\n",
      "\n",
      "    accuracy                           0.86    127070\n",
      "   macro avg       0.50      0.80      0.47    127070\n",
      "weighted avg       1.00      0.86      0.92    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=0.01).fit(X_train_scaled_ss_09, y_train_scaled_ss_09)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train_scaled_ss_09, y_train_scaled_ss_09)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test_scaled, y_test)))\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression With SMOTE ss=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.779\n",
      "Test set score: 0.839\n",
      "[[106529  20345]\n",
      " [    52    144]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91    126874\n",
      "           1       0.01      0.73      0.01       196\n",
      "\n",
      "    accuracy                           0.84    127070\n",
      "   macro avg       0.50      0.79      0.46    127070\n",
      "weighted avg       1.00      0.84      0.91    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=0.01).fit(X_train_scaled_ss_10, y_train_scaled_ss_10)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train_scaled_ss_10, y_train_scaled_ss_10)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test_scaled, y_test)))\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAIVE BAYES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.948\n",
      "Test set score: 0.948\n",
      "[[120337   6537]\n",
      " [   106     90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97    126874\n",
      "           1       0.01      0.46      0.03       196\n",
      "\n",
      "    accuracy                           0.95    127070\n",
      "   macro avg       0.51      0.70      0.50    127070\n",
      "weighted avg       1.00      0.95      0.97    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Initiating the Gaussian Classifier\n",
    "mod = GaussianNB()\n",
    "\n",
    "# Training your model \n",
    "mod.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predicting Outcome \n",
    "predicted = mod.predict(X_test_scaled)\n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mod.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(mod.score(X_test_scaled, y_test)))\n",
    "\n",
    "# Confusion Matrix\n",
    "y_pred = mod.predict(X_test_scaled)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes With SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Without SMOTE ss=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.897\n",
      "Test set score: 0.935\n",
      "[[118664   8210]\n",
      " [    91    105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97    126874\n",
      "           1       0.01      0.54      0.02       196\n",
      "\n",
      "    accuracy                           0.93    127070\n",
      "   macro avg       0.51      0.74      0.50    127070\n",
      "weighted avg       1.00      0.93      0.96    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training your model \n",
    "mod.fit(X_train_scaled_ss_01, y_train_scaled_ss_01)\n",
    "\n",
    "# Predicting Outcome \n",
    "predicted = mod.predict(X_test_scaled)\n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mod.score(X_train_scaled_ss_01, y_train_scaled_ss_01)))\n",
    "print(\"Test set score: {:.3f}\".format(mod.score(X_test_scaled, y_test)))\n",
    "\n",
    "# Confusion Matrix\n",
    "y_pred = mod.predict(X_test_scaled)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Without SMOTE ss=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.865\n",
      "Test set score: 0.931\n",
      "[[118251   8623]\n",
      " [    89    107]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96    126874\n",
      "           1       0.01      0.55      0.02       196\n",
      "\n",
      "    accuracy                           0.93    127070\n",
      "   macro avg       0.51      0.74      0.49    127070\n",
      "weighted avg       1.00      0.93      0.96    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training your model \n",
    "mod.fit(X_train_scaled_ss_02, y_train_scaled_ss_02)\n",
    "\n",
    "# Predicting Outcome \n",
    "predicted = mod.predict(X_test_scaled)\n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mod.score(X_train_scaled_ss_02, y_train_scaled_ss_02)))\n",
    "print(\"Test set score: {:.3f}\".format(mod.score(X_test_scaled, y_test)))\n",
    "\n",
    "# Confusion Matrix\n",
    "y_pred = mod.predict(X_test_scaled)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Without SMOTE ss=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.838\n",
      "Test set score: 0.930\n",
      "[[118055   8819]\n",
      " [    88    108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96    126874\n",
      "           1       0.01      0.55      0.02       196\n",
      "\n",
      "    accuracy                           0.93    127070\n",
      "   macro avg       0.51      0.74      0.49    127070\n",
      "weighted avg       1.00      0.93      0.96    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training your model \n",
    "mod.fit(X_train_scaled_ss_03, y_train_scaled_ss_03)\n",
    "\n",
    "# Predicting Outcome \n",
    "predicted = mod.predict(X_test_scaled)\n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mod.score(X_train_scaled_ss_03, y_train_scaled_ss_03)))\n",
    "print(\"Test set score: {:.3f}\".format(mod.score(X_test_scaled, y_test)))\n",
    "\n",
    "# Confusion Matrix\n",
    "y_pred = mod.predict(X_test_scaled)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Without SMOTE ss=0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.816\n",
      "Test set score: 0.928\n",
      "[[117823   9051]\n",
      " [    87    109]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96    126874\n",
      "           1       0.01      0.56      0.02       196\n",
      "\n",
      "    accuracy                           0.93    127070\n",
      "   macro avg       0.51      0.74      0.49    127070\n",
      "weighted avg       1.00      0.93      0.96    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training your model \n",
    "mod.fit(X_train_scaled_ss_04, y_train_scaled_ss_04)\n",
    "\n",
    "# Predicting Outcome \n",
    "predicted = mod.predict(X_test_scaled)\n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mod.score(X_train_scaled_ss_04, y_train_scaled_ss_04)))\n",
    "print(\"Test set score: {:.3f}\".format(mod.score(X_test_scaled, y_test)))\n",
    "\n",
    "# Confusion Matrix\n",
    "y_pred = mod.predict(X_test_scaled)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Without SMOTE ss=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.797\n",
      "Test set score: 0.926\n",
      "[[117602   9272]\n",
      " [    86    110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96    126874\n",
      "           1       0.01      0.56      0.02       196\n",
      "\n",
      "    accuracy                           0.93    127070\n",
      "   macro avg       0.51      0.74      0.49    127070\n",
      "weighted avg       1.00      0.93      0.96    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training your model \n",
    "mod.fit(X_train_scaled_ss_05, y_train_scaled_ss_05)\n",
    "\n",
    "# Predicting Outcome \n",
    "predicted = mod.predict(X_test_scaled)\n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mod.score(X_train_scaled_ss_05, y_train_scaled_ss_05)))\n",
    "print(\"Test set score: {:.3f}\".format(mod.score(X_test_scaled, y_test)))\n",
    "\n",
    "# Confusion Matrix\n",
    "y_pred = mod.predict(X_test_scaled)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Without SMOTE ss=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.780\n",
      "Test set score: 0.925\n",
      "[[117389   9485]\n",
      " [    86    110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96    126874\n",
      "           1       0.01      0.56      0.02       196\n",
      "\n",
      "    accuracy                           0.92    127070\n",
      "   macro avg       0.51      0.74      0.49    127070\n",
      "weighted avg       1.00      0.92      0.96    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training your model \n",
    "mod.fit(X_train_scaled_ss_06, y_train_scaled_ss_06)\n",
    "\n",
    "# Predicting Outcome \n",
    "predicted = mod.predict(X_test_scaled)\n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mod.score(X_train_scaled_ss_06, y_train_scaled_ss_06)))\n",
    "print(\"Test set score: {:.3f}\".format(mod.score(X_test_scaled, y_test)))\n",
    "\n",
    "# Confusion Matrix\n",
    "y_pred = mod.predict(X_test_scaled)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Without SMOTE ss=0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.766\n",
      "Test set score: 0.924\n",
      "[[117247   9627]\n",
      " [    86    110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96    126874\n",
      "           1       0.01      0.56      0.02       196\n",
      "\n",
      "    accuracy                           0.92    127070\n",
      "   macro avg       0.51      0.74      0.49    127070\n",
      "weighted avg       1.00      0.92      0.96    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training your model \n",
    "mod.fit(X_train_scaled_ss_07, y_train_scaled_ss_07)\n",
    "\n",
    "# Predicting Outcome \n",
    "predicted = mod.predict(X_test_scaled)\n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mod.score(X_train_scaled_ss_07, y_train_scaled_ss_07)))\n",
    "print(\"Test set score: {:.3f}\".format(mod.score(X_test_scaled, y_test)))\n",
    "\n",
    "# Confusion Matrix\n",
    "y_pred = mod.predict(X_test_scaled)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Without SMOTE ss=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.753\n",
      "Test set score: 0.922\n",
      "[[117032   9842]\n",
      " [    86    110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96    126874\n",
      "           1       0.01      0.56      0.02       196\n",
      "\n",
      "    accuracy                           0.92    127070\n",
      "   macro avg       0.51      0.74      0.49    127070\n",
      "weighted avg       1.00      0.92      0.96    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training your model \n",
    "mod.fit(X_train_scaled_ss_08, y_train_scaled_ss_08)\n",
    "\n",
    "# Predicting Outcome \n",
    "predicted = mod.predict(X_test_scaled)\n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mod.score(X_train_scaled_ss_08, y_train_scaled_ss_08)))\n",
    "print(\"Test set score: {:.3f}\".format(mod.score(X_test_scaled, y_test)))\n",
    "\n",
    "# Confusion Matrix\n",
    "y_pred = mod.predict(X_test_scaled)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Without SMOTE ss=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.743\n",
      "Test set score: 0.921\n",
      "[[116878   9996]\n",
      " [    86    110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96    126874\n",
      "           1       0.01      0.56      0.02       196\n",
      "\n",
      "    accuracy                           0.92    127070\n",
      "   macro avg       0.51      0.74      0.49    127070\n",
      "weighted avg       1.00      0.92      0.96    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training your model \n",
    "mod.fit(X_train_scaled_ss_09, y_train_scaled_ss_09)\n",
    "\n",
    "# Predicting Outcome \n",
    "predicted = mod.predict(X_test_scaled)\n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mod.score(X_train_scaled_ss_09, y_train_scaled_ss_09)))\n",
    "print(\"Test set score: {:.3f}\".format(mod.score(X_test_scaled, y_test)))\n",
    "\n",
    "# Confusion Matrix\n",
    "y_pred = mod.predict(X_test_scaled)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Without SMOTE ss=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.733\n",
      "Test set score: 0.920\n",
      "[[116772  10102]\n",
      " [    86    110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96    126874\n",
      "           1       0.01      0.56      0.02       196\n",
      "\n",
      "    accuracy                           0.92    127070\n",
      "   macro avg       0.51      0.74      0.49    127070\n",
      "weighted avg       1.00      0.92      0.96    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training your model \n",
    "mod.fit(X_train_scaled_ss_10, y_train_scaled_ss_10)\n",
    "\n",
    "# Predicting Outcome \n",
    "predicted = mod.predict(X_test_scaled)\n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mod.score(X_train_scaled_ss_10, y_train_scaled_ss_10)))\n",
    "print(\"Test set score: {:.3f}\".format(mod.score(X_test_scaled, y_test)))\n",
    "\n",
    "# Confusion Matrix\n",
    "y_pred = mod.predict(X_test_scaled)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## NEURAL NET MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net MLP Without SMOTE, 2 Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net MLPClassifier without SMOTE, hidden layer (16,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.04653690\n",
      "Iteration 2, loss = 0.01008173\n",
      "Iteration 3, loss = 0.00934238\n",
      "Iteration 4, loss = 0.00890550\n",
      "Iteration 5, loss = 0.00867237\n",
      "Iteration 6, loss = 0.00845301\n",
      "Iteration 7, loss = 0.00829869\n",
      "Iteration 8, loss = 0.00819168\n",
      "Iteration 9, loss = 0.00807960\n",
      "Iteration 10, loss = 0.00792900\n",
      "Iteration 11, loss = 0.00782911\n",
      "Iteration 12, loss = 0.00773284\n",
      "Iteration 13, loss = 0.00763741\n",
      "Iteration 14, loss = 0.00761253\n",
      "Iteration 15, loss = 0.00751725\n",
      "Iteration 16, loss = 0.00747358\n",
      "Iteration 17, loss = 0.00742516\n",
      "Iteration 18, loss = 0.00733818\n",
      "Iteration 19, loss = 0.00724555\n",
      "Iteration 20, loss = 0.00727716\n",
      "Iteration 21, loss = 0.00720115\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(16, 16), max_iter=1000, verbose=2)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier  \n",
    "from sklearn import metrics\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(16,16), max_iter=1000,verbose=2)  \n",
    "mlp.fit(X_train_scaled, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.999\n",
      "Test set score: 0.998\n",
      "Accuracy:  0.9983473675926655\n",
      "[[126832     42]\n",
      " [   168     28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.40      0.14      0.21       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.70      0.57      0.60    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test_scaled) \n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net MLPClassifier without SMOTE, hidden layer (32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.03072718\n",
      "Iteration 2, loss = 0.00945830\n",
      "Iteration 3, loss = 0.00886685\n",
      "Iteration 4, loss = 0.00850062\n",
      "Iteration 5, loss = 0.00829989\n",
      "Iteration 6, loss = 0.00806674\n",
      "Iteration 7, loss = 0.00791253\n",
      "Iteration 8, loss = 0.00769026\n",
      "Iteration 9, loss = 0.00753213\n",
      "Iteration 10, loss = 0.00739460\n",
      "Iteration 11, loss = 0.00724321\n",
      "Iteration 12, loss = 0.00708253\n",
      "Iteration 13, loss = 0.00694710\n",
      "Iteration 14, loss = 0.00685170\n",
      "Iteration 15, loss = 0.00664253\n",
      "Iteration 16, loss = 0.00653519\n",
      "Iteration 17, loss = 0.00631710\n",
      "Iteration 18, loss = 0.00628178\n",
      "Iteration 19, loss = 0.00615745\n",
      "Iteration 20, loss = 0.00600804\n",
      "Iteration 21, loss = 0.00593885\n",
      "Iteration 22, loss = 0.00576949\n",
      "Iteration 23, loss = 0.00563587\n",
      "Iteration 24, loss = 0.00564901\n",
      "Iteration 25, loss = 0.00547951\n",
      "Iteration 26, loss = 0.00544391\n",
      "Iteration 27, loss = 0.00532931\n",
      "Iteration 28, loss = 0.00513743\n",
      "Iteration 29, loss = 0.00511964\n",
      "Iteration 30, loss = 0.00504316\n",
      "Iteration 31, loss = 0.00485363\n",
      "Iteration 32, loss = 0.00496684\n",
      "Iteration 33, loss = 0.00472845\n",
      "Iteration 34, loss = 0.00472245\n",
      "Iteration 35, loss = 0.00468957\n",
      "Iteration 36, loss = 0.00459949\n",
      "Iteration 37, loss = 0.00443505\n",
      "Iteration 38, loss = 0.00440106\n",
      "Iteration 39, loss = 0.00444809\n",
      "Iteration 40, loss = 0.00432510\n",
      "Iteration 41, loss = 0.00427372\n",
      "Iteration 42, loss = 0.00423753\n",
      "Iteration 43, loss = 0.00410758\n",
      "Iteration 44, loss = 0.00407884\n",
      "Iteration 45, loss = 0.00409060\n",
      "Iteration 46, loss = 0.00394759\n",
      "Iteration 47, loss = 0.00397091\n",
      "Iteration 48, loss = 0.00387424\n",
      "Iteration 49, loss = 0.00375058\n",
      "Iteration 50, loss = 0.00378630\n",
      "Iteration 51, loss = 0.00366744\n",
      "Iteration 52, loss = 0.00368424\n",
      "Iteration 53, loss = 0.00365606\n",
      "Iteration 54, loss = 0.00353454\n",
      "Iteration 55, loss = 0.00349457\n",
      "Iteration 56, loss = 0.00345723\n",
      "Iteration 57, loss = 0.00348338\n",
      "Iteration 58, loss = 0.00338329\n",
      "Iteration 59, loss = 0.00334151\n",
      "Iteration 60, loss = 0.00326681\n",
      "Iteration 61, loss = 0.00327468\n",
      "Iteration 62, loss = 0.00323935\n",
      "Iteration 63, loss = 0.00318131\n",
      "Iteration 64, loss = 0.00315063\n",
      "Iteration 65, loss = 0.00312100\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(32, 32), max_iter=1000, verbose=2)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(32,32), max_iter=1000,verbose=2)  \n",
    "mlp.fit(X_train_scaled, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.999\n",
      "Test set score: 0.998\n",
      "Accuracy:  0.9980483198237192\n",
      "[[126798     76]\n",
      " [   172     24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.24      0.12      0.16       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.62      0.56      0.58    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test_scaled) \n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net MLPClassifier without SMOTE, hidden layer (64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.01850770\n",
      "Iteration 2, loss = 0.00911738\n",
      "Iteration 3, loss = 0.00856987\n",
      "Iteration 4, loss = 0.00814619\n",
      "Iteration 5, loss = 0.00785840\n",
      "Iteration 6, loss = 0.00756410\n",
      "Iteration 7, loss = 0.00725918\n",
      "Iteration 8, loss = 0.00695825\n",
      "Iteration 9, loss = 0.00658399\n",
      "Iteration 10, loss = 0.00621677\n",
      "Iteration 11, loss = 0.00590661\n",
      "Iteration 12, loss = 0.00554816\n",
      "Iteration 13, loss = 0.00533353\n",
      "Iteration 14, loss = 0.00500987\n",
      "Iteration 15, loss = 0.00475089\n",
      "Iteration 16, loss = 0.00448428\n",
      "Iteration 17, loss = 0.00421715\n",
      "Iteration 18, loss = 0.00401065\n",
      "Iteration 19, loss = 0.00362673\n",
      "Iteration 20, loss = 0.00349421\n",
      "Iteration 21, loss = 0.00338074\n",
      "Iteration 22, loss = 0.00320054\n",
      "Iteration 23, loss = 0.00291245\n",
      "Iteration 24, loss = 0.00273137\n",
      "Iteration 25, loss = 0.00277677\n",
      "Iteration 26, loss = 0.00238705\n",
      "Iteration 27, loss = 0.00228585\n",
      "Iteration 28, loss = 0.00220277\n",
      "Iteration 29, loss = 0.00205850\n",
      "Iteration 30, loss = 0.00200335\n",
      "Iteration 31, loss = 0.00205027\n",
      "Iteration 32, loss = 0.00168263\n",
      "Iteration 33, loss = 0.00163001\n",
      "Iteration 34, loss = 0.00157654\n",
      "Iteration 35, loss = 0.00149440\n",
      "Iteration 36, loss = 0.00153674\n",
      "Iteration 37, loss = 0.00148216\n",
      "Iteration 38, loss = 0.00133143\n",
      "Iteration 39, loss = 0.00148329\n",
      "Iteration 40, loss = 0.00119925\n",
      "Iteration 41, loss = 0.00124003\n",
      "Iteration 42, loss = 0.00112953\n",
      "Iteration 43, loss = 0.00129799\n",
      "Iteration 44, loss = 0.00098204\n",
      "Iteration 45, loss = 0.00111127\n",
      "Iteration 46, loss = 0.00130227\n",
      "Iteration 47, loss = 0.00089085\n",
      "Iteration 48, loss = 0.00103135\n",
      "Iteration 49, loss = 0.00108503\n",
      "Iteration 50, loss = 0.00122044\n",
      "Iteration 51, loss = 0.00079232\n",
      "Iteration 52, loss = 0.00113485\n",
      "Iteration 53, loss = 0.00098350\n",
      "Iteration 54, loss = 0.00093054\n",
      "Iteration 55, loss = 0.00093374\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(64, 64), max_iter=1000, verbose=2)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(64,64), max_iter=1000,verbose=2)  \n",
    "mlp.fit(X_train_scaled, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.000\n",
      "Test set score: 0.998\n",
      "Accuracy:  0.9982214527425828\n",
      "[[126824     50]\n",
      " [   176     20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.29      0.10      0.15       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.64      0.55      0.57    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test_scaled) \n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net MLPClassifier without SMOTE, hidden layer (128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.01354809\n",
      "Iteration 2, loss = 0.00897308\n",
      "Iteration 3, loss = 0.00840203\n",
      "Iteration 4, loss = 0.00815592\n",
      "Iteration 5, loss = 0.00773303\n",
      "Iteration 6, loss = 0.00732485\n",
      "Iteration 7, loss = 0.00692609\n",
      "Iteration 8, loss = 0.00649118\n",
      "Iteration 9, loss = 0.00599470\n",
      "Iteration 10, loss = 0.00565518\n",
      "Iteration 11, loss = 0.00500086\n",
      "Iteration 12, loss = 0.00454753\n",
      "Iteration 13, loss = 0.00406369\n",
      "Iteration 14, loss = 0.00366366\n",
      "Iteration 15, loss = 0.00327920\n",
      "Iteration 16, loss = 0.00284088\n",
      "Iteration 17, loss = 0.00263607\n",
      "Iteration 18, loss = 0.00224575\n",
      "Iteration 19, loss = 0.00218667\n",
      "Iteration 20, loss = 0.00195845\n",
      "Iteration 21, loss = 0.00174370\n",
      "Iteration 22, loss = 0.00188302\n",
      "Iteration 23, loss = 0.00142852\n",
      "Iteration 24, loss = 0.00129712\n",
      "Iteration 25, loss = 0.00163502\n",
      "Iteration 26, loss = 0.00132488\n",
      "Iteration 27, loss = 0.00109301\n",
      "Iteration 28, loss = 0.00136031\n",
      "Iteration 29, loss = 0.00100026\n",
      "Iteration 30, loss = 0.00118002\n",
      "Iteration 31, loss = 0.00116586\n",
      "Iteration 32, loss = 0.00105868\n",
      "Iteration 33, loss = 0.00122389\n",
      "Iteration 34, loss = 0.00097488\n",
      "Iteration 35, loss = 0.00099475\n",
      "Iteration 36, loss = 0.00102057\n",
      "Iteration 37, loss = 0.00099135\n",
      "Iteration 38, loss = 0.00120528\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(128, 128), max_iter=1000, verbose=2)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(128,128), max_iter=1000,verbose=2)  \n",
    "mlp.fit(X_train_scaled, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.000\n",
      "Test set score: 0.998\n",
      "Accuracy:  0.9982214527425828\n",
      "[[126815     59]\n",
      " [   167     29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.33      0.15      0.20       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.66      0.57      0.60    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test_scaled) \n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net MLPClassifier without SMOTE, hidden layer (256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.01333551\n",
      "Iteration 2, loss = 0.00905991\n",
      "Iteration 3, loss = 0.00856621\n",
      "Iteration 4, loss = 0.00822532\n",
      "Iteration 5, loss = 0.00783202\n",
      "Iteration 6, loss = 0.00734392\n",
      "Iteration 7, loss = 0.00690428\n",
      "Iteration 8, loss = 0.00623014\n",
      "Iteration 9, loss = 0.00565417\n",
      "Iteration 10, loss = 0.00488429\n",
      "Iteration 11, loss = 0.00402599\n",
      "Iteration 12, loss = 0.00363028\n",
      "Iteration 13, loss = 0.00303103\n",
      "Iteration 14, loss = 0.00268986\n",
      "Iteration 15, loss = 0.00224893\n",
      "Iteration 16, loss = 0.00220428\n",
      "Iteration 17, loss = 0.00194787\n",
      "Iteration 18, loss = 0.00197772\n",
      "Iteration 19, loss = 0.00152614\n",
      "Iteration 20, loss = 0.00179804\n",
      "Iteration 21, loss = 0.00152980\n",
      "Iteration 22, loss = 0.00138332\n",
      "Iteration 23, loss = 0.00153718\n",
      "Iteration 24, loss = 0.00154729\n",
      "Iteration 25, loss = 0.00119351\n",
      "Iteration 26, loss = 0.00125033\n",
      "Iteration 27, loss = 0.00162130\n",
      "Iteration 28, loss = 0.00132638\n",
      "Iteration 29, loss = 0.00118966\n",
      "Iteration 30, loss = 0.00116198\n",
      "Iteration 31, loss = 0.00118432\n",
      "Iteration 32, loss = 0.00157698\n",
      "Iteration 33, loss = 0.00121565\n",
      "Iteration 34, loss = 0.00105708\n",
      "Iteration 35, loss = 0.00133570\n",
      "Iteration 36, loss = 0.00095710\n",
      "Iteration 37, loss = 0.00118717\n",
      "Iteration 38, loss = 0.00117364\n",
      "Iteration 39, loss = 0.00119370\n",
      "Iteration 40, loss = 0.00103275\n",
      "Iteration 41, loss = 0.00107473\n",
      "Iteration 42, loss = 0.00096644\n",
      "Iteration 43, loss = 0.00113386\n",
      "Iteration 44, loss = 0.00112900\n",
      "Iteration 45, loss = 0.00105717\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(256, 256), max_iter=1000, verbose=2)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(256,256), max_iter=1000,verbose=2)  \n",
    "mlp.fit(X_train_scaled, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.000\n",
      "Test set score: 0.998\n",
      "Accuracy:  0.9981270166050209\n",
      "[[126797     77]\n",
      " [   161     35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.31      0.18      0.23       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.66      0.59      0.61    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test_scaled) \n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net MLP Without SMOTE, 3 Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net MLPClassifier without SMOTE, hidden layer (16,16,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.03247254\n",
      "Iteration 2, loss = 0.00991868\n",
      "Iteration 3, loss = 0.00924188\n",
      "Iteration 4, loss = 0.00894157\n",
      "Iteration 5, loss = 0.00862097\n",
      "Iteration 6, loss = 0.00846934\n",
      "Iteration 7, loss = 0.00826118\n",
      "Iteration 8, loss = 0.00814138\n",
      "Iteration 9, loss = 0.00799924\n",
      "Iteration 10, loss = 0.00791417\n",
      "Iteration 11, loss = 0.00781667\n",
      "Iteration 12, loss = 0.00770384\n",
      "Iteration 13, loss = 0.00759006\n",
      "Iteration 14, loss = 0.00750664\n",
      "Iteration 15, loss = 0.00747064\n",
      "Iteration 16, loss = 0.00736252\n",
      "Iteration 17, loss = 0.00730348\n",
      "Iteration 18, loss = 0.00723770\n",
      "Iteration 19, loss = 0.00715603\n",
      "Iteration 20, loss = 0.00713630\n",
      "Iteration 21, loss = 0.00707110\n",
      "Iteration 22, loss = 0.00693103\n",
      "Iteration 23, loss = 0.00690295\n",
      "Iteration 24, loss = 0.00682379\n",
      "Iteration 25, loss = 0.00678287\n",
      "Iteration 26, loss = 0.00675451\n",
      "Iteration 27, loss = 0.00672160\n",
      "Iteration 28, loss = 0.00664810\n",
      "Iteration 29, loss = 0.00664652\n",
      "Iteration 30, loss = 0.00655806\n",
      "Iteration 31, loss = 0.00652222\n",
      "Iteration 32, loss = 0.00652426\n",
      "Iteration 33, loss = 0.00642542\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(16, 16, 16), max_iter=1000, verbose=2)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(16,16,16), max_iter=1000,verbose=2)  \n",
    "mlp.fit(X_train_scaled, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.999\n",
      "Test set score: 0.998\n",
      "Accuracy:  0.9984339340520972\n",
      "[[126850     24]\n",
      " [   175     21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.47      0.11      0.17       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.73      0.55      0.59    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test_scaled) \n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net MLPClassifier without SMOTE, hidden layer (32,32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.01687682\n",
      "Iteration 2, loss = 0.00925996\n",
      "Iteration 3, loss = 0.00876164\n",
      "Iteration 4, loss = 0.00831094\n",
      "Iteration 5, loss = 0.00805896\n",
      "Iteration 6, loss = 0.00779113\n",
      "Iteration 7, loss = 0.00757084\n",
      "Iteration 8, loss = 0.00726907\n",
      "Iteration 9, loss = 0.00704150\n",
      "Iteration 10, loss = 0.00684071\n",
      "Iteration 11, loss = 0.00670136\n",
      "Iteration 12, loss = 0.00652418\n",
      "Iteration 13, loss = 0.00624341\n",
      "Iteration 14, loss = 0.00606548\n",
      "Iteration 15, loss = 0.00596826\n",
      "Iteration 16, loss = 0.00564162\n",
      "Iteration 17, loss = 0.00549828\n",
      "Iteration 18, loss = 0.00539949\n",
      "Iteration 19, loss = 0.00525263\n",
      "Iteration 20, loss = 0.00508037\n",
      "Iteration 21, loss = 0.00498077\n",
      "Iteration 22, loss = 0.00474948\n",
      "Iteration 23, loss = 0.00456456\n",
      "Iteration 24, loss = 0.00453506\n",
      "Iteration 25, loss = 0.00440651\n",
      "Iteration 26, loss = 0.00430441\n",
      "Iteration 27, loss = 0.00416649\n",
      "Iteration 28, loss = 0.00396258\n",
      "Iteration 29, loss = 0.00391752\n",
      "Iteration 30, loss = 0.00375532\n",
      "Iteration 31, loss = 0.00354803\n",
      "Iteration 32, loss = 0.00373201\n",
      "Iteration 33, loss = 0.00346132\n",
      "Iteration 34, loss = 0.00335068\n",
      "Iteration 35, loss = 0.00332458\n",
      "Iteration 36, loss = 0.00314881\n",
      "Iteration 37, loss = 0.00317332\n",
      "Iteration 38, loss = 0.00291803\n",
      "Iteration 39, loss = 0.00292803\n",
      "Iteration 40, loss = 0.00279925\n",
      "Iteration 41, loss = 0.00291150\n",
      "Iteration 42, loss = 0.00270664\n",
      "Iteration 43, loss = 0.00267187\n",
      "Iteration 44, loss = 0.00239163\n",
      "Iteration 45, loss = 0.00254526\n",
      "Iteration 46, loss = 0.00239357\n",
      "Iteration 47, loss = 0.00254131\n",
      "Iteration 48, loss = 0.00232097\n",
      "Iteration 49, loss = 0.00244335\n",
      "Iteration 50, loss = 0.00198451\n",
      "Iteration 51, loss = 0.00208274\n",
      "Iteration 52, loss = 0.00217244\n",
      "Iteration 53, loss = 0.00203354\n",
      "Iteration 54, loss = 0.00190400\n",
      "Iteration 55, loss = 0.00212425\n",
      "Iteration 56, loss = 0.00193000\n",
      "Iteration 57, loss = 0.00186303\n",
      "Iteration 58, loss = 0.00178709\n",
      "Iteration 59, loss = 0.00181324\n",
      "Iteration 60, loss = 0.00168556\n",
      "Iteration 61, loss = 0.00177703\n",
      "Iteration 62, loss = 0.00210932\n",
      "Iteration 63, loss = 0.00168947\n",
      "Iteration 64, loss = 0.00180285\n",
      "Iteration 65, loss = 0.00143882\n",
      "Iteration 66, loss = 0.00181400\n",
      "Iteration 67, loss = 0.00164465\n",
      "Iteration 68, loss = 0.00161914\n",
      "Iteration 69, loss = 0.00149244\n",
      "Iteration 70, loss = 0.00158529\n",
      "Iteration 71, loss = 0.00142073\n",
      "Iteration 72, loss = 0.00148071\n",
      "Iteration 73, loss = 0.00166644\n",
      "Iteration 74, loss = 0.00161209\n",
      "Iteration 75, loss = 0.00120405\n",
      "Iteration 76, loss = 0.00154255\n",
      "Iteration 77, loss = 0.00154466\n",
      "Iteration 78, loss = 0.00125791\n",
      "Iteration 79, loss = 0.00165643\n",
      "Iteration 80, loss = 0.00126950\n",
      "Iteration 81, loss = 0.00136427\n",
      "Iteration 82, loss = 0.00118770\n",
      "Iteration 83, loss = 0.00154242\n",
      "Iteration 84, loss = 0.00144838\n",
      "Iteration 85, loss = 0.00133448\n",
      "Iteration 86, loss = 0.00137524\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(32, 32, 32), max_iter=1000, verbose=2)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(32,32,32), max_iter=1000,verbose=2)  \n",
    "mlp.fit(X_train_scaled, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.000\n",
      "Test set score: 0.998\n",
      "Accuracy:  0.9979302746517668\n",
      "[[126789     85]\n",
      " [   178     18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.17      0.09      0.12       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.59      0.55      0.56    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test_scaled) \n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net MLPClassifier without SMOTE, hidden layer (64,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.01450565\n",
      "Iteration 2, loss = 0.00904398\n",
      "Iteration 3, loss = 0.00842792\n",
      "Iteration 4, loss = 0.00805782\n",
      "Iteration 5, loss = 0.00768643\n",
      "Iteration 6, loss = 0.00728007\n",
      "Iteration 7, loss = 0.00694338\n",
      "Iteration 8, loss = 0.00661602\n",
      "Iteration 9, loss = 0.00621866\n",
      "Iteration 10, loss = 0.00583565\n",
      "Iteration 11, loss = 0.00538112\n",
      "Iteration 12, loss = 0.00505010\n",
      "Iteration 13, loss = 0.00459227\n",
      "Iteration 14, loss = 0.00424962\n",
      "Iteration 15, loss = 0.00393260\n",
      "Iteration 16, loss = 0.00361489\n",
      "Iteration 17, loss = 0.00352889\n",
      "Iteration 18, loss = 0.00307653\n",
      "Iteration 19, loss = 0.00278620\n",
      "Iteration 20, loss = 0.00261050\n",
      "Iteration 21, loss = 0.00269197\n",
      "Iteration 22, loss = 0.00216699\n",
      "Iteration 23, loss = 0.00198147\n",
      "Iteration 24, loss = 0.00215315\n",
      "Iteration 25, loss = 0.00201066\n",
      "Iteration 26, loss = 0.00183700\n",
      "Iteration 27, loss = 0.00181484\n",
      "Iteration 28, loss = 0.00171677\n",
      "Iteration 29, loss = 0.00148100\n",
      "Iteration 30, loss = 0.00175646\n",
      "Iteration 31, loss = 0.00160171\n",
      "Iteration 32, loss = 0.00158397\n",
      "Iteration 33, loss = 0.00130862\n",
      "Iteration 34, loss = 0.00131682\n",
      "Iteration 35, loss = 0.00124552\n",
      "Iteration 36, loss = 0.00151246\n",
      "Iteration 37, loss = 0.00131341\n",
      "Iteration 38, loss = 0.00107468\n",
      "Iteration 39, loss = 0.00140737\n",
      "Iteration 40, loss = 0.00131136\n",
      "Iteration 41, loss = 0.00112414\n",
      "Iteration 42, loss = 0.00142386\n",
      "Iteration 43, loss = 0.00099874\n",
      "Iteration 44, loss = 0.00103659\n",
      "Iteration 45, loss = 0.00131084\n",
      "Iteration 46, loss = 0.00097386\n",
      "Iteration 47, loss = 0.00120580\n",
      "Iteration 48, loss = 0.00129976\n",
      "Iteration 49, loss = 0.00082301\n",
      "Iteration 50, loss = 0.00115538\n",
      "Iteration 51, loss = 0.00118788\n",
      "Iteration 52, loss = 0.00083961\n",
      "Iteration 53, loss = 0.00123452\n",
      "Iteration 54, loss = 0.00134850\n",
      "Iteration 55, loss = 0.00094015\n",
      "Iteration 56, loss = 0.00085478\n",
      "Iteration 57, loss = 0.00106160\n",
      "Iteration 58, loss = 0.00105459\n",
      "Iteration 59, loss = 0.00090333\n",
      "Iteration 60, loss = 0.00076775\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(64, 64, 64), max_iter=1000, verbose=2)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(64,64,64), max_iter=1000,verbose=2)  \n",
    "mlp.fit(X_train_scaled, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.000\n",
      "Test set score: 0.998\n",
      "Accuracy:  0.9980483198237192\n",
      "[[126805     69]\n",
      " [   179     17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.20      0.09      0.12       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.60      0.54      0.56    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test_scaled) \n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net MLP Without SMOTE, 4 Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net MLPClassifier without SMOTE, hidden layer (16,16,16,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.02524599\n",
      "Iteration 2, loss = 0.00956328\n",
      "Iteration 3, loss = 0.00905083\n",
      "Iteration 4, loss = 0.00867674\n",
      "Iteration 5, loss = 0.00846559\n",
      "Iteration 6, loss = 0.00833427\n",
      "Iteration 7, loss = 0.00816070\n",
      "Iteration 8, loss = 0.00800837\n",
      "Iteration 9, loss = 0.00783140\n",
      "Iteration 10, loss = 0.00777309\n",
      "Iteration 11, loss = 0.00758488\n",
      "Iteration 12, loss = 0.00760016\n",
      "Iteration 13, loss = 0.00745872\n",
      "Iteration 14, loss = 0.00736269\n",
      "Iteration 15, loss = 0.00723986\n",
      "Iteration 16, loss = 0.00718082\n",
      "Iteration 17, loss = 0.00704991\n",
      "Iteration 18, loss = 0.00696456\n",
      "Iteration 19, loss = 0.00684522\n",
      "Iteration 20, loss = 0.00677328\n",
      "Iteration 21, loss = 0.00679965\n",
      "Iteration 22, loss = 0.00659705\n",
      "Iteration 23, loss = 0.00659670\n",
      "Iteration 24, loss = 0.00650733\n",
      "Iteration 25, loss = 0.00651026\n",
      "Iteration 26, loss = 0.00638667\n",
      "Iteration 27, loss = 0.00634684\n",
      "Iteration 28, loss = 0.00624132\n",
      "Iteration 29, loss = 0.00625947\n",
      "Iteration 30, loss = 0.00616823\n",
      "Iteration 31, loss = 0.00607952\n",
      "Iteration 32, loss = 0.00613154\n",
      "Iteration 33, loss = 0.00607217\n",
      "Iteration 34, loss = 0.00597658\n",
      "Iteration 35, loss = 0.00601847\n",
      "Iteration 36, loss = 0.00595521\n",
      "Iteration 37, loss = 0.00582825\n",
      "Iteration 38, loss = 0.00589781\n",
      "Iteration 39, loss = 0.00583199\n",
      "Iteration 40, loss = 0.00578106\n",
      "Iteration 41, loss = 0.00572271\n",
      "Iteration 42, loss = 0.00578144\n",
      "Iteration 43, loss = 0.00562893\n",
      "Iteration 44, loss = 0.00567438\n",
      "Iteration 45, loss = 0.00558795\n",
      "Iteration 46, loss = 0.00562747\n",
      "Iteration 47, loss = 0.00549936\n",
      "Iteration 48, loss = 0.00554174\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(16, 16, 16, 16), max_iter=1000, verbose=2)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(16,16,16,16), max_iter=1000,verbose=2)  \n",
    "mlp.fit(X_train_scaled, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.999\n",
      "Test set score: 0.998\n",
      "Accuracy:  0.9980640591799795\n",
      "[[126803     71]\n",
      " [   175     21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.23      0.11      0.15       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.61      0.55      0.57    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test_scaled) \n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net MLPClassifier without SMOTE, hidden layer (32,32,32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.02060188\n",
      "Iteration 2, loss = 0.00939798\n",
      "Iteration 3, loss = 0.00887470\n",
      "Iteration 4, loss = 0.00848955\n",
      "Iteration 5, loss = 0.00821014\n",
      "Iteration 6, loss = 0.00784036\n",
      "Iteration 7, loss = 0.00762253\n",
      "Iteration 8, loss = 0.00743200\n",
      "Iteration 9, loss = 0.00708371\n",
      "Iteration 10, loss = 0.00687517\n",
      "Iteration 11, loss = 0.00676953\n",
      "Iteration 12, loss = 0.00646380\n",
      "Iteration 13, loss = 0.00630976\n",
      "Iteration 14, loss = 0.00606460\n",
      "Iteration 15, loss = 0.00594007\n",
      "Iteration 16, loss = 0.00569612\n",
      "Iteration 17, loss = 0.00551500\n",
      "Iteration 18, loss = 0.00540405\n",
      "Iteration 19, loss = 0.00520506\n",
      "Iteration 20, loss = 0.00503870\n",
      "Iteration 21, loss = 0.00491007\n",
      "Iteration 22, loss = 0.00479826\n",
      "Iteration 23, loss = 0.00456265\n",
      "Iteration 24, loss = 0.00440504\n",
      "Iteration 25, loss = 0.00423493\n",
      "Iteration 26, loss = 0.00426504\n",
      "Iteration 27, loss = 0.00411754\n",
      "Iteration 28, loss = 0.00382078\n",
      "Iteration 29, loss = 0.00386096\n",
      "Iteration 30, loss = 0.00373102\n",
      "Iteration 31, loss = 0.00358843\n",
      "Iteration 32, loss = 0.00357044\n",
      "Iteration 33, loss = 0.00321889\n",
      "Iteration 34, loss = 0.00333505\n",
      "Iteration 35, loss = 0.00319677\n",
      "Iteration 36, loss = 0.00316795\n",
      "Iteration 37, loss = 0.00309939\n",
      "Iteration 38, loss = 0.00299325\n",
      "Iteration 39, loss = 0.00266155\n",
      "Iteration 40, loss = 0.00309555\n",
      "Iteration 41, loss = 0.00289447\n",
      "Iteration 42, loss = 0.00272789\n",
      "Iteration 43, loss = 0.00249247\n",
      "Iteration 44, loss = 0.00265383\n",
      "Iteration 45, loss = 0.00235560\n",
      "Iteration 46, loss = 0.00273080\n",
      "Iteration 47, loss = 0.00233069\n",
      "Iteration 48, loss = 0.00259950\n",
      "Iteration 49, loss = 0.00247079\n",
      "Iteration 50, loss = 0.00249436\n",
      "Iteration 51, loss = 0.00233207\n",
      "Iteration 52, loss = 0.00208613\n",
      "Iteration 53, loss = 0.00213365\n",
      "Iteration 54, loss = 0.00202673\n",
      "Iteration 55, loss = 0.00227976\n",
      "Iteration 56, loss = 0.00209033\n",
      "Iteration 57, loss = 0.00204977\n",
      "Iteration 58, loss = 0.00182742\n",
      "Iteration 59, loss = 0.00198285\n",
      "Iteration 60, loss = 0.00191021\n",
      "Iteration 61, loss = 0.00201240\n",
      "Iteration 62, loss = 0.00194332\n",
      "Iteration 63, loss = 0.00214822\n",
      "Iteration 64, loss = 0.00188516\n",
      "Iteration 65, loss = 0.00165164\n",
      "Iteration 66, loss = 0.00192308\n",
      "Iteration 67, loss = 0.00172003\n",
      "Iteration 68, loss = 0.00190815\n",
      "Iteration 69, loss = 0.00189859\n",
      "Iteration 70, loss = 0.00171544\n",
      "Iteration 71, loss = 0.00175599\n",
      "Iteration 72, loss = 0.00174218\n",
      "Iteration 73, loss = 0.00175300\n",
      "Iteration 74, loss = 0.00184368\n",
      "Iteration 75, loss = 0.00145093\n",
      "Iteration 76, loss = 0.00152960\n",
      "Iteration 77, loss = 0.00180128\n",
      "Iteration 78, loss = 0.00204371\n",
      "Iteration 79, loss = 0.00157039\n",
      "Iteration 80, loss = 0.00137980\n",
      "Iteration 81, loss = 0.00157871\n",
      "Iteration 82, loss = 0.00145425\n",
      "Iteration 83, loss = 0.00180718\n",
      "Iteration 84, loss = 0.00141990\n",
      "Iteration 85, loss = 0.00176940\n",
      "Iteration 86, loss = 0.00142948\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(32, 32, 32, 32), max_iter=1000, verbose=2)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(32,32,32,32), max_iter=1000,verbose=2)  \n",
    "mlp.fit(X_train_scaled, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.000\n",
      "Test set score: 0.998\n",
      "Accuracy:  0.997796490123554\n",
      "[[126764    110]\n",
      " [   170     26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.19      0.13      0.16       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.59      0.57      0.58    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test_scaled) \n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net With SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net 2 Layers (128,128) With SMOTE ss=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.09611138\n",
      "Iteration 2, loss = 0.02031363\n",
      "Iteration 3, loss = 0.01022498\n",
      "Iteration 4, loss = 0.00673551\n",
      "Iteration 5, loss = 0.00542338\n",
      "Iteration 6, loss = 0.00451051\n",
      "Iteration 7, loss = 0.00391167\n",
      "Iteration 8, loss = 0.00319716\n",
      "Iteration 9, loss = 0.00315895\n",
      "Iteration 10, loss = 0.00267208\n",
      "Iteration 11, loss = 0.00293035\n",
      "Iteration 12, loss = 0.00240604\n",
      "Iteration 13, loss = 0.00251038\n",
      "Iteration 14, loss = 0.00243056\n",
      "Iteration 15, loss = 0.00246847\n",
      "Iteration 16, loss = 0.00170390\n",
      "Iteration 17, loss = 0.00191249\n",
      "Iteration 18, loss = 0.00233943\n",
      "Iteration 19, loss = 0.00177143\n",
      "Iteration 20, loss = 0.00171501\n",
      "Iteration 21, loss = 0.00159257\n",
      "Iteration 22, loss = 0.00205090\n",
      "Iteration 23, loss = 0.00130562\n",
      "Iteration 24, loss = 0.00164942\n",
      "Iteration 25, loss = 0.00192917\n",
      "Iteration 26, loss = 0.00160532\n",
      "Iteration 27, loss = 0.00141411\n",
      "Iteration 28, loss = 0.00186949\n",
      "Iteration 29, loss = 0.00180681\n",
      "Iteration 30, loss = 0.00099458\n",
      "Iteration 31, loss = 0.00212689\n",
      "Iteration 32, loss = 0.00079997\n",
      "Iteration 33, loss = 0.00170287\n",
      "Iteration 34, loss = 0.00118454\n",
      "Iteration 35, loss = 0.00170126\n",
      "Iteration 36, loss = 0.00162496\n",
      "Iteration 37, loss = 0.00102784\n",
      "Iteration 38, loss = 0.00095767\n",
      "Iteration 39, loss = 0.00183490\n",
      "Iteration 40, loss = 0.00124536\n",
      "Iteration 41, loss = 0.00166636\n",
      "Iteration 42, loss = 0.00125723\n",
      "Iteration 43, loss = 0.00109555\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(128, 128), max_iter=1000, verbose=2)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(128,128), max_iter=1000,verbose=2)  \n",
    "mlp.fit(X_train_scaled_ss_01, y_train_scaled_ss_01)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.000\n",
      "Test set score: 0.998\n",
      "Accuracy:  0.9976548359172109\n",
      "[[126745    129]\n",
      " [   169     27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.17      0.14      0.15       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.59      0.57      0.58    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test_scaled) \n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mlp.score(X_train_scaled_ss_01, y_train_scaled_ss_01)))\n",
    "print(\"Test set score: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net 2 Layers (128,128) With SMOTE ss=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.10246173\n",
      "Iteration 2, loss = 0.01810243\n",
      "Iteration 3, loss = 0.00930705\n",
      "Iteration 4, loss = 0.00687465\n",
      "Iteration 5, loss = 0.00500010\n",
      "Iteration 6, loss = 0.00459419\n",
      "Iteration 7, loss = 0.00362363\n",
      "Iteration 8, loss = 0.00303814\n",
      "Iteration 9, loss = 0.00339911\n",
      "Iteration 10, loss = 0.00302665\n",
      "Iteration 11, loss = 0.00263082\n",
      "Iteration 12, loss = 0.00263715\n",
      "Iteration 13, loss = 0.00169144\n",
      "Iteration 14, loss = 0.00247739\n",
      "Iteration 15, loss = 0.00190357\n",
      "Iteration 16, loss = 0.00229790\n",
      "Iteration 17, loss = 0.00216568\n",
      "Iteration 18, loss = 0.00153684\n",
      "Iteration 19, loss = 0.00239258\n",
      "Iteration 20, loss = 0.00166406\n",
      "Iteration 21, loss = 0.00175785\n",
      "Iteration 22, loss = 0.00192530\n",
      "Iteration 23, loss = 0.00132579\n",
      "Iteration 24, loss = 0.00163806\n",
      "Iteration 25, loss = 0.00161066\n",
      "Iteration 26, loss = 0.00167471\n",
      "Iteration 27, loss = 0.00142564\n",
      "Iteration 28, loss = 0.00118278\n",
      "Iteration 29, loss = 0.00168659\n",
      "Iteration 30, loss = 0.00189243\n",
      "Iteration 31, loss = 0.00127145\n",
      "Iteration 32, loss = 0.00150828\n",
      "Iteration 33, loss = 0.00159992\n",
      "Iteration 34, loss = 0.00168992\n",
      "Iteration 35, loss = 0.00069243\n",
      "Iteration 36, loss = 0.00131282\n",
      "Iteration 37, loss = 0.00126228\n",
      "Iteration 38, loss = 0.00117916\n",
      "Iteration 39, loss = 0.00134309\n",
      "Iteration 40, loss = 0.00155820\n",
      "Iteration 41, loss = 0.00103777\n",
      "Iteration 42, loss = 0.00142437\n",
      "Iteration 43, loss = 0.00127064\n",
      "Iteration 44, loss = 0.00099592\n",
      "Iteration 45, loss = 0.00092299\n",
      "Iteration 46, loss = 0.00160399\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(128, 128), max_iter=1000, verbose=2)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(128,128), max_iter=1000,verbose=2)  \n",
    "mlp.fit(X_train_scaled_ss_02, y_train_scaled_ss_02)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.000\n",
      "Test set score: 0.998\n",
      "Accuracy:  0.99760761784843\n",
      "[[126740    134]\n",
      " [   170     26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.16      0.13      0.15       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.58      0.57      0.57    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test_scaled) \n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mlp.score(X_train_scaled_ss_02, y_train_scaled_ss_02)))\n",
    "print(\"Test set score: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net 2 Layers (128,128) With SMOTE ss=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.10244016\n",
      "Iteration 2, loss = 0.01661901\n",
      "Iteration 3, loss = 0.00935829\n",
      "Iteration 4, loss = 0.00652101\n",
      "Iteration 5, loss = 0.00477094\n",
      "Iteration 6, loss = 0.00462746\n",
      "Iteration 7, loss = 0.00386214\n",
      "Iteration 8, loss = 0.00328040\n",
      "Iteration 9, loss = 0.00289427\n",
      "Iteration 10, loss = 0.00245733\n",
      "Iteration 11, loss = 0.00303632\n",
      "Iteration 12, loss = 0.00217675\n",
      "Iteration 13, loss = 0.00176792\n",
      "Iteration 14, loss = 0.00199189\n",
      "Iteration 15, loss = 0.00183862\n",
      "Iteration 16, loss = 0.00176302\n",
      "Iteration 17, loss = 0.00196084\n",
      "Iteration 18, loss = 0.00158847\n",
      "Iteration 19, loss = 0.00186617\n",
      "Iteration 20, loss = 0.00168283\n",
      "Iteration 21, loss = 0.00163009\n",
      "Iteration 22, loss = 0.00162482\n",
      "Iteration 23, loss = 0.00131110\n",
      "Iteration 24, loss = 0.00163698\n",
      "Iteration 25, loss = 0.00146579\n",
      "Iteration 26, loss = 0.00154497\n",
      "Iteration 27, loss = 0.00127869\n",
      "Iteration 28, loss = 0.00154674\n",
      "Iteration 29, loss = 0.00107987\n",
      "Iteration 30, loss = 0.00156440\n",
      "Iteration 31, loss = 0.00129610\n",
      "Iteration 32, loss = 0.00172374\n",
      "Iteration 33, loss = 0.00136342\n",
      "Iteration 34, loss = 0.00095585\n",
      "Iteration 35, loss = 0.00124972\n",
      "Iteration 36, loss = 0.00143748\n",
      "Iteration 37, loss = 0.00125418\n",
      "Iteration 38, loss = 0.00098869\n",
      "Iteration 39, loss = 0.00125196\n",
      "Iteration 40, loss = 0.00148283\n",
      "Iteration 41, loss = 0.00132373\n",
      "Iteration 42, loss = 0.00090866\n",
      "Iteration 43, loss = 0.00138406\n",
      "Iteration 44, loss = 0.00138979\n",
      "Iteration 45, loss = 0.00112076\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(128, 128), max_iter=1000, verbose=2)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(128,128), max_iter=1000,verbose=2)  \n",
    "mlp.fit(X_train_scaled_ss_03, y_train_scaled_ss_03)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.000\n",
      "Test set score: 0.998\n",
      "Accuracy:  0.9976627055953412\n",
      "[[126754    120]\n",
      " [   177     19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.14      0.10      0.11       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.57      0.55      0.56    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test_scaled) \n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mlp.score(X_train_scaled_ss_03, y_train_scaled_ss_03)))\n",
    "print(\"Test set score: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net 3 Layers (16,16,16) With SMOTE ss=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.17286824\n",
      "Iteration 2, loss = 0.10572242\n",
      "Iteration 3, loss = 0.08419216\n",
      "Iteration 4, loss = 0.07147941\n",
      "Iteration 5, loss = 0.06293917\n",
      "Iteration 6, loss = 0.05727832\n",
      "Iteration 7, loss = 0.05354606\n",
      "Iteration 8, loss = 0.05034034\n",
      "Iteration 9, loss = 0.04805442\n",
      "Iteration 10, loss = 0.04642072\n",
      "Iteration 11, loss = 0.04527234\n",
      "Iteration 12, loss = 0.04397521\n",
      "Iteration 13, loss = 0.04291172\n",
      "Iteration 14, loss = 0.04185435\n",
      "Iteration 15, loss = 0.04133933\n",
      "Iteration 16, loss = 0.04041780\n",
      "Iteration 17, loss = 0.03987537\n",
      "Iteration 18, loss = 0.03915265\n",
      "Iteration 19, loss = 0.03848842\n",
      "Iteration 20, loss = 0.03792928\n",
      "Iteration 21, loss = 0.03741648\n",
      "Iteration 22, loss = 0.03702463\n",
      "Iteration 23, loss = 0.03645112\n",
      "Iteration 24, loss = 0.03587792\n",
      "Iteration 25, loss = 0.03550754\n",
      "Iteration 26, loss = 0.03520021\n",
      "Iteration 27, loss = 0.03474780\n",
      "Iteration 28, loss = 0.03443528\n",
      "Iteration 29, loss = 0.03428781\n",
      "Iteration 30, loss = 0.03388006\n",
      "Iteration 31, loss = 0.03354663\n",
      "Iteration 32, loss = 0.03338064\n",
      "Iteration 33, loss = 0.03318431\n",
      "Iteration 34, loss = 0.03286632\n",
      "Iteration 35, loss = 0.03288880\n",
      "Iteration 36, loss = 0.03237276\n",
      "Iteration 37, loss = 0.03236074\n",
      "Iteration 38, loss = 0.03210704\n",
      "Iteration 39, loss = 0.03176570\n",
      "Iteration 40, loss = 0.03199034\n",
      "Iteration 41, loss = 0.03172376\n",
      "Iteration 42, loss = 0.03134563\n",
      "Iteration 43, loss = 0.03138786\n",
      "Iteration 44, loss = 0.03102830\n",
      "Iteration 45, loss = 0.03059474\n",
      "Iteration 46, loss = 0.03069586\n",
      "Iteration 47, loss = 0.03048433\n",
      "Iteration 48, loss = 0.03020723\n",
      "Iteration 49, loss = 0.02981678\n",
      "Iteration 50, loss = 0.02956911\n",
      "Iteration 51, loss = 0.02971417\n",
      "Iteration 52, loss = 0.02952059\n",
      "Iteration 53, loss = 0.02939048\n",
      "Iteration 54, loss = 0.02940468\n",
      "Iteration 55, loss = 0.02890559\n",
      "Iteration 56, loss = 0.02879885\n",
      "Iteration 57, loss = 0.02872628\n",
      "Iteration 58, loss = 0.02866959\n",
      "Iteration 59, loss = 0.02866060\n",
      "Iteration 60, loss = 0.02859470\n",
      "Iteration 61, loss = 0.02837512\n",
      "Iteration 62, loss = 0.02838363\n",
      "Iteration 63, loss = 0.02840734\n",
      "Iteration 64, loss = 0.02790156\n",
      "Iteration 65, loss = 0.02818941\n",
      "Iteration 66, loss = 0.02805750\n",
      "Iteration 67, loss = 0.02805983\n",
      "Iteration 68, loss = 0.02809597\n",
      "Iteration 69, loss = 0.02782262\n",
      "Iteration 70, loss = 0.02787061\n",
      "Iteration 71, loss = 0.02790388\n",
      "Iteration 72, loss = 0.02755876\n",
      "Iteration 73, loss = 0.02773728\n",
      "Iteration 74, loss = 0.02768601\n",
      "Iteration 75, loss = 0.02734821\n",
      "Iteration 76, loss = 0.02766160\n",
      "Iteration 77, loss = 0.02736315\n",
      "Iteration 78, loss = 0.02714753\n",
      "Iteration 79, loss = 0.02729304\n",
      "Iteration 80, loss = 0.02735600\n",
      "Iteration 81, loss = 0.02729355\n",
      "Iteration 82, loss = 0.02691457\n",
      "Iteration 83, loss = 0.02702891\n",
      "Iteration 84, loss = 0.02699304\n",
      "Iteration 85, loss = 0.02680840\n",
      "Iteration 86, loss = 0.02712863\n",
      "Iteration 87, loss = 0.02681194\n",
      "Iteration 88, loss = 0.02693121\n",
      "Iteration 89, loss = 0.02665815\n",
      "Iteration 90, loss = 0.02684633\n",
      "Iteration 91, loss = 0.02666882\n",
      "Iteration 92, loss = 0.02655266\n",
      "Iteration 93, loss = 0.02665110\n",
      "Iteration 94, loss = 0.02655377\n",
      "Iteration 95, loss = 0.02668159\n",
      "Iteration 96, loss = 0.02653842\n",
      "Iteration 97, loss = 0.02647537\n",
      "Iteration 98, loss = 0.02631530\n",
      "Iteration 99, loss = 0.02628336\n",
      "Iteration 100, loss = 0.02637802\n",
      "Iteration 101, loss = 0.02634326\n",
      "Iteration 102, loss = 0.02613793\n",
      "Iteration 103, loss = 0.02630185\n",
      "Iteration 104, loss = 0.02616468\n",
      "Iteration 105, loss = 0.02630473\n",
      "Iteration 106, loss = 0.02589710\n",
      "Iteration 107, loss = 0.02610296\n",
      "Iteration 108, loss = 0.02607955\n",
      "Iteration 109, loss = 0.02600301\n",
      "Iteration 110, loss = 0.02591069\n",
      "Iteration 111, loss = 0.02584015\n",
      "Iteration 112, loss = 0.02576436\n",
      "Iteration 113, loss = 0.02582434\n",
      "Iteration 114, loss = 0.02563157\n",
      "Iteration 115, loss = 0.02567145\n",
      "Iteration 116, loss = 0.02565515\n",
      "Iteration 117, loss = 0.02569536\n",
      "Iteration 118, loss = 0.02566497\n",
      "Iteration 119, loss = 0.02551687\n",
      "Iteration 120, loss = 0.02562193\n",
      "Iteration 121, loss = 0.02576311\n",
      "Iteration 122, loss = 0.02547469\n",
      "Iteration 123, loss = 0.02548081\n",
      "Iteration 124, loss = 0.02545197\n",
      "Iteration 125, loss = 0.02545840\n",
      "Iteration 126, loss = 0.02559209\n",
      "Iteration 127, loss = 0.02537029\n",
      "Iteration 128, loss = 0.02503685\n",
      "Iteration 129, loss = 0.02532807\n",
      "Iteration 130, loss = 0.02518509\n",
      "Iteration 131, loss = 0.02534564\n",
      "Iteration 132, loss = 0.02506874\n",
      "Iteration 133, loss = 0.02479781\n",
      "Iteration 134, loss = 0.02521969\n",
      "Iteration 135, loss = 0.02499811\n",
      "Iteration 136, loss = 0.02522361\n",
      "Iteration 137, loss = 0.02500237\n",
      "Iteration 138, loss = 0.02489169\n",
      "Iteration 139, loss = 0.02510056\n",
      "Iteration 140, loss = 0.02504041\n",
      "Iteration 141, loss = 0.02495591\n",
      "Iteration 142, loss = 0.02480039\n",
      "Iteration 143, loss = 0.02513885\n",
      "Iteration 144, loss = 0.02480704\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(16, 16, 16), max_iter=1000, verbose=2)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(16,16,16), max_iter=1000,verbose=2)  \n",
    "mlp.fit(X_train_scaled_ss_01, y_train_scaled_ss_01)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.992\n",
      "Test set score: 0.990\n",
      "Accuracy:  0.990044857165342\n",
      "[[125762   1112]\n",
      " [   153     43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    126874\n",
      "           1       0.04      0.22      0.06       196\n",
      "\n",
      "    accuracy                           0.99    127070\n",
      "   macro avg       0.52      0.61      0.53    127070\n",
      "weighted avg       1.00      0.99      0.99    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test_scaled) \n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mlp.score(X_train_scaled_ss_01, y_train_scaled_ss_01)))\n",
    "print(\"Test set score: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net 3 Layers (16,16,16) With SMOTE ss=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.23705735\n",
      "Iteration 2, loss = 0.13291069\n",
      "Iteration 3, loss = 0.10217515\n",
      "Iteration 4, loss = 0.08944936\n",
      "Iteration 5, loss = 0.08168185\n",
      "Iteration 6, loss = 0.07592235\n",
      "Iteration 7, loss = 0.07152449\n",
      "Iteration 8, loss = 0.06775245\n",
      "Iteration 9, loss = 0.06464497\n",
      "Iteration 10, loss = 0.06190626\n",
      "Iteration 11, loss = 0.05972143\n",
      "Iteration 12, loss = 0.05743406\n",
      "Iteration 13, loss = 0.05609894\n",
      "Iteration 14, loss = 0.05462765\n",
      "Iteration 15, loss = 0.05327712\n",
      "Iteration 16, loss = 0.05221840\n",
      "Iteration 17, loss = 0.05104458\n",
      "Iteration 18, loss = 0.05054718\n",
      "Iteration 19, loss = 0.04964867\n",
      "Iteration 20, loss = 0.04920488\n",
      "Iteration 21, loss = 0.04854713\n",
      "Iteration 22, loss = 0.04793646\n",
      "Iteration 23, loss = 0.04694068\n",
      "Iteration 24, loss = 0.04656222\n",
      "Iteration 25, loss = 0.04595769\n",
      "Iteration 26, loss = 0.04527621\n",
      "Iteration 27, loss = 0.04504048\n",
      "Iteration 28, loss = 0.04449417\n",
      "Iteration 29, loss = 0.04394237\n",
      "Iteration 30, loss = 0.04366339\n",
      "Iteration 31, loss = 0.04343293\n",
      "Iteration 32, loss = 0.04293243\n",
      "Iteration 33, loss = 0.04253204\n",
      "Iteration 34, loss = 0.04242399\n",
      "Iteration 35, loss = 0.04211514\n",
      "Iteration 36, loss = 0.04170138\n",
      "Iteration 37, loss = 0.04126995\n",
      "Iteration 38, loss = 0.04124435\n",
      "Iteration 39, loss = 0.04087620\n",
      "Iteration 40, loss = 0.04054631\n",
      "Iteration 41, loss = 0.04010000\n",
      "Iteration 42, loss = 0.03990474\n",
      "Iteration 43, loss = 0.03938049\n",
      "Iteration 44, loss = 0.03937543\n",
      "Iteration 45, loss = 0.03908082\n",
      "Iteration 46, loss = 0.03883307\n",
      "Iteration 47, loss = 0.03880077\n",
      "Iteration 48, loss = 0.03847275\n",
      "Iteration 49, loss = 0.03806520\n",
      "Iteration 50, loss = 0.03789653\n",
      "Iteration 51, loss = 0.03780752\n",
      "Iteration 52, loss = 0.03771738\n",
      "Iteration 53, loss = 0.03754685\n",
      "Iteration 54, loss = 0.03722996\n",
      "Iteration 55, loss = 0.03703250\n",
      "Iteration 56, loss = 0.03698495\n",
      "Iteration 57, loss = 0.03664271\n",
      "Iteration 58, loss = 0.03666170\n",
      "Iteration 59, loss = 0.03664880\n",
      "Iteration 60, loss = 0.03622103\n",
      "Iteration 61, loss = 0.03662979\n",
      "Iteration 62, loss = 0.03583613\n",
      "Iteration 63, loss = 0.03590953\n",
      "Iteration 64, loss = 0.03604910\n",
      "Iteration 65, loss = 0.03548554\n",
      "Iteration 66, loss = 0.03567121\n",
      "Iteration 67, loss = 0.03539983\n",
      "Iteration 68, loss = 0.03545110\n",
      "Iteration 69, loss = 0.03484437\n",
      "Iteration 70, loss = 0.03524427\n",
      "Iteration 71, loss = 0.03530905\n",
      "Iteration 72, loss = 0.03470102\n",
      "Iteration 73, loss = 0.03472537\n",
      "Iteration 74, loss = 0.03471822\n",
      "Iteration 75, loss = 0.03468062\n",
      "Iteration 76, loss = 0.03454408\n",
      "Iteration 77, loss = 0.03466675\n",
      "Iteration 78, loss = 0.03426294\n",
      "Iteration 79, loss = 0.03425806\n",
      "Iteration 80, loss = 0.03424278\n",
      "Iteration 81, loss = 0.03353220\n",
      "Iteration 82, loss = 0.03407076\n",
      "Iteration 83, loss = 0.03339522\n",
      "Iteration 84, loss = 0.03402902\n",
      "Iteration 85, loss = 0.03313428\n",
      "Iteration 86, loss = 0.03380557\n",
      "Iteration 87, loss = 0.03355409\n",
      "Iteration 88, loss = 0.03338874\n",
      "Iteration 89, loss = 0.03320874\n",
      "Iteration 90, loss = 0.03333925\n",
      "Iteration 91, loss = 0.03300019\n",
      "Iteration 92, loss = 0.03281339\n",
      "Iteration 93, loss = 0.03304222\n",
      "Iteration 94, loss = 0.03279303\n",
      "Iteration 95, loss = 0.03298356\n",
      "Iteration 96, loss = 0.03292757\n",
      "Iteration 97, loss = 0.03275726\n",
      "Iteration 98, loss = 0.03265999\n",
      "Iteration 99, loss = 0.03239258\n",
      "Iteration 100, loss = 0.03225922\n",
      "Iteration 101, loss = 0.03251750\n",
      "Iteration 102, loss = 0.03234812\n",
      "Iteration 103, loss = 0.03220466\n",
      "Iteration 104, loss = 0.03217502\n",
      "Iteration 105, loss = 0.03208803\n",
      "Iteration 106, loss = 0.03174772\n",
      "Iteration 107, loss = 0.03194870\n",
      "Iteration 108, loss = 0.03188865\n",
      "Iteration 109, loss = 0.03158961\n",
      "Iteration 110, loss = 0.03172504\n",
      "Iteration 111, loss = 0.03141843\n",
      "Iteration 112, loss = 0.03158197\n",
      "Iteration 113, loss = 0.03184122\n",
      "Iteration 114, loss = 0.03155389\n",
      "Iteration 115, loss = 0.03156862\n",
      "Iteration 116, loss = 0.03117402\n",
      "Iteration 117, loss = 0.03170011\n",
      "Iteration 118, loss = 0.03130171\n",
      "Iteration 119, loss = 0.03119642\n",
      "Iteration 120, loss = 0.03109830\n",
      "Iteration 121, loss = 0.03120821\n",
      "Iteration 122, loss = 0.03127959\n",
      "Iteration 123, loss = 0.03119705\n",
      "Iteration 124, loss = 0.03104631\n",
      "Iteration 125, loss = 0.03107210\n",
      "Iteration 126, loss = 0.03072156\n",
      "Iteration 127, loss = 0.03110988\n",
      "Iteration 128, loss = 0.03071897\n",
      "Iteration 129, loss = 0.03079991\n",
      "Iteration 130, loss = 0.03072102\n",
      "Iteration 131, loss = 0.03087842\n",
      "Iteration 132, loss = 0.03072536\n",
      "Iteration 133, loss = 0.03080471\n",
      "Iteration 134, loss = 0.03060050\n",
      "Iteration 135, loss = 0.03024518\n",
      "Iteration 136, loss = 0.03060283\n",
      "Iteration 137, loss = 0.03035039\n",
      "Iteration 138, loss = 0.03066881\n",
      "Iteration 139, loss = 0.03055320\n",
      "Iteration 140, loss = 0.03023904\n",
      "Iteration 141, loss = 0.03054189\n",
      "Iteration 142, loss = 0.03032843\n",
      "Iteration 143, loss = 0.03026989\n",
      "Iteration 144, loss = 0.03040515\n",
      "Iteration 145, loss = 0.03036163\n",
      "Iteration 146, loss = 0.03009860\n",
      "Iteration 147, loss = 0.03023139\n",
      "Iteration 148, loss = 0.02996821\n",
      "Iteration 149, loss = 0.03008276\n",
      "Iteration 150, loss = 0.03012529\n",
      "Iteration 151, loss = 0.03013071\n",
      "Iteration 152, loss = 0.03027679\n",
      "Iteration 153, loss = 0.03001989\n",
      "Iteration 154, loss = 0.03007232\n",
      "Iteration 155, loss = 0.02981817\n",
      "Iteration 156, loss = 0.02982771\n",
      "Iteration 157, loss = 0.03013134\n",
      "Iteration 158, loss = 0.02992974\n",
      "Iteration 159, loss = 0.03012334\n",
      "Iteration 160, loss = 0.03048418\n",
      "Iteration 161, loss = 0.02962714\n",
      "Iteration 162, loss = 0.02987307\n",
      "Iteration 163, loss = 0.02980504\n",
      "Iteration 164, loss = 0.02981860\n",
      "Iteration 165, loss = 0.02964949\n",
      "Iteration 166, loss = 0.03000371\n",
      "Iteration 167, loss = 0.03017002\n",
      "Iteration 168, loss = 0.02961377\n",
      "Iteration 169, loss = 0.02977928\n",
      "Iteration 170, loss = 0.02907718\n",
      "Iteration 171, loss = 0.03005426\n",
      "Iteration 172, loss = 0.02975179\n",
      "Iteration 173, loss = 0.02955226\n",
      "Iteration 174, loss = 0.02965507\n",
      "Iteration 175, loss = 0.02939280\n",
      "Iteration 176, loss = 0.02992364\n",
      "Iteration 177, loss = 0.02961864\n",
      "Iteration 178, loss = 0.02942632\n",
      "Iteration 179, loss = 0.02948277\n",
      "Iteration 180, loss = 0.02974683\n",
      "Iteration 181, loss = 0.02929768\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(16, 16, 16), max_iter=1000, verbose=2)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(16,16,16), max_iter=1000,verbose=2)  \n",
    "mlp.fit(X_train_scaled_ss_02, y_train_scaled_ss_02)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.991\n",
      "Test set score: 0.988\n",
      "Accuracy:  0.9876288659793815\n",
      "[[125454   1420]\n",
      " [   152     44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    126874\n",
      "           1       0.03      0.22      0.05       196\n",
      "\n",
      "    accuracy                           0.99    127070\n",
      "   macro avg       0.51      0.61      0.52    127070\n",
      "weighted avg       1.00      0.99      0.99    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test_scaled) \n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mlp.score(X_train_scaled_ss_02, y_train_scaled_ss_02)))\n",
    "print(\"Test set score: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net 3 Layers (32,32,32) With SMOTE ss=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.13758460\n",
      "Iteration 2, loss = 0.06000932\n",
      "Iteration 3, loss = 0.03861061\n",
      "Iteration 4, loss = 0.02940814\n",
      "Iteration 5, loss = 0.02445351\n",
      "Iteration 6, loss = 0.02112724\n",
      "Iteration 7, loss = 0.01841729\n",
      "Iteration 8, loss = 0.01640673\n",
      "Iteration 9, loss = 0.01526268\n",
      "Iteration 10, loss = 0.01431872\n",
      "Iteration 11, loss = 0.01300030\n",
      "Iteration 12, loss = 0.01203704\n",
      "Iteration 13, loss = 0.01170048\n",
      "Iteration 14, loss = 0.01050871\n",
      "Iteration 15, loss = 0.01006815\n",
      "Iteration 16, loss = 0.00940718\n",
      "Iteration 17, loss = 0.00905076\n",
      "Iteration 18, loss = 0.00875992\n",
      "Iteration 19, loss = 0.00804553\n",
      "Iteration 20, loss = 0.00807823\n",
      "Iteration 21, loss = 0.00764789\n",
      "Iteration 22, loss = 0.00745748\n",
      "Iteration 23, loss = 0.00714133\n",
      "Iteration 24, loss = 0.00676898\n",
      "Iteration 25, loss = 0.00623030\n",
      "Iteration 26, loss = 0.00684035\n",
      "Iteration 27, loss = 0.00624628\n",
      "Iteration 28, loss = 0.00600694\n",
      "Iteration 29, loss = 0.00597187\n",
      "Iteration 30, loss = 0.00562859\n",
      "Iteration 31, loss = 0.00528837\n",
      "Iteration 32, loss = 0.00553410\n",
      "Iteration 33, loss = 0.00533457\n",
      "Iteration 34, loss = 0.00461782\n",
      "Iteration 35, loss = 0.00533439\n",
      "Iteration 36, loss = 0.00462480\n",
      "Iteration 37, loss = 0.00542848\n",
      "Iteration 38, loss = 0.00434424\n",
      "Iteration 39, loss = 0.00568585\n",
      "Iteration 40, loss = 0.00465791\n",
      "Iteration 41, loss = 0.00418798\n",
      "Iteration 42, loss = 0.00412237\n",
      "Iteration 43, loss = 0.00446079\n",
      "Iteration 44, loss = 0.00493381\n",
      "Iteration 45, loss = 0.00385990\n",
      "Iteration 46, loss = 0.00430161\n",
      "Iteration 47, loss = 0.00371299\n",
      "Iteration 48, loss = 0.00401933\n",
      "Iteration 49, loss = 0.00419721\n",
      "Iteration 50, loss = 0.00394265\n",
      "Iteration 51, loss = 0.00372829\n",
      "Iteration 52, loss = 0.00380426\n",
      "Iteration 53, loss = 0.00384842\n",
      "Iteration 54, loss = 0.00350365\n",
      "Iteration 55, loss = 0.00359321\n",
      "Iteration 56, loss = 0.00340653\n",
      "Iteration 57, loss = 0.00404673\n",
      "Iteration 58, loss = 0.00325994\n",
      "Iteration 59, loss = 0.00392112\n",
      "Iteration 60, loss = 0.00368641\n",
      "Iteration 61, loss = 0.00329292\n",
      "Iteration 62, loss = 0.00346144\n",
      "Iteration 63, loss = 0.00282466\n",
      "Iteration 64, loss = 0.00285192\n",
      "Iteration 65, loss = 0.00435165\n",
      "Iteration 66, loss = 0.00243750\n",
      "Iteration 67, loss = 0.00306481\n",
      "Iteration 68, loss = 0.00379859\n",
      "Iteration 69, loss = 0.00230106\n",
      "Iteration 70, loss = 0.00350313\n",
      "Iteration 71, loss = 0.00315855\n",
      "Iteration 72, loss = 0.00279914\n",
      "Iteration 73, loss = 0.00323930\n",
      "Iteration 74, loss = 0.00284647\n",
      "Iteration 75, loss = 0.00246396\n",
      "Iteration 76, loss = 0.00317816\n",
      "Iteration 77, loss = 0.00249274\n",
      "Iteration 78, loss = 0.00336207\n",
      "Iteration 79, loss = 0.00272007\n",
      "Iteration 80, loss = 0.00252972\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(32, 32, 32), max_iter=1000, verbose=2)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(32,32,32), max_iter=1000,verbose=2)  \n",
    "mlp.fit(X_train_scaled_ss_01, y_train_scaled_ss_01)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.999\n",
      "Test set score: 0.996\n",
      "Accuracy:  0.996458644841426\n",
      "[[126593    281]\n",
      " [   169     27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.09      0.14      0.11       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.54      0.57      0.55    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test_scaled) \n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mlp.score(X_train_scaled_ss_01, y_train_scaled_ss_01)))\n",
    "print(\"Test set score: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net 3 Layers (32,32,32) With SMOTE ss=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.17179854\n",
      "Iteration 2, loss = 0.05423930\n",
      "Iteration 3, loss = 0.03329077\n",
      "Iteration 4, loss = 0.02555743\n",
      "Iteration 5, loss = 0.02209740\n",
      "Iteration 6, loss = 0.01864232\n",
      "Iteration 7, loss = 0.01705147\n",
      "Iteration 8, loss = 0.01539982\n",
      "Iteration 9, loss = 0.01453026\n",
      "Iteration 10, loss = 0.01303831\n",
      "Iteration 11, loss = 0.01272511\n",
      "Iteration 12, loss = 0.01198284\n",
      "Iteration 13, loss = 0.01034534\n",
      "Iteration 14, loss = 0.01024312\n",
      "Iteration 15, loss = 0.01001801\n",
      "Iteration 16, loss = 0.00929132\n",
      "Iteration 17, loss = 0.00863927\n",
      "Iteration 18, loss = 0.00841412\n",
      "Iteration 19, loss = 0.00819021\n",
      "Iteration 20, loss = 0.00741401\n",
      "Iteration 21, loss = 0.00734826\n",
      "Iteration 22, loss = 0.00682828\n",
      "Iteration 23, loss = 0.00674814\n",
      "Iteration 24, loss = 0.00647085\n",
      "Iteration 25, loss = 0.00667029\n",
      "Iteration 26, loss = 0.00650387\n",
      "Iteration 27, loss = 0.00570212\n",
      "Iteration 28, loss = 0.00583539\n",
      "Iteration 29, loss = 0.00553806\n",
      "Iteration 30, loss = 0.00588990\n",
      "Iteration 31, loss = 0.00492343\n",
      "Iteration 32, loss = 0.00544832\n",
      "Iteration 33, loss = 0.00504103\n",
      "Iteration 34, loss = 0.00511946\n",
      "Iteration 35, loss = 0.00532604\n",
      "Iteration 36, loss = 0.00461520\n",
      "Iteration 37, loss = 0.00513189\n",
      "Iteration 38, loss = 0.00424896\n",
      "Iteration 39, loss = 0.00422810\n",
      "Iteration 40, loss = 0.00448434\n",
      "Iteration 41, loss = 0.00389258\n",
      "Iteration 42, loss = 0.00486894\n",
      "Iteration 43, loss = 0.00436557\n",
      "Iteration 44, loss = 0.00400339\n",
      "Iteration 45, loss = 0.00369947\n",
      "Iteration 46, loss = 0.00477265\n",
      "Iteration 47, loss = 0.00388573\n",
      "Iteration 48, loss = 0.00382410\n",
      "Iteration 49, loss = 0.00424101\n",
      "Iteration 50, loss = 0.00374557\n",
      "Iteration 51, loss = 0.00371435\n",
      "Iteration 52, loss = 0.00388486\n",
      "Iteration 53, loss = 0.00354807\n",
      "Iteration 54, loss = 0.00355849\n",
      "Iteration 55, loss = 0.00361011\n",
      "Iteration 56, loss = 0.00323970\n",
      "Iteration 57, loss = 0.00335557\n",
      "Iteration 58, loss = 0.00330033\n",
      "Iteration 59, loss = 0.00317077\n",
      "Iteration 60, loss = 0.00338764\n",
      "Iteration 61, loss = 0.00334133\n",
      "Iteration 62, loss = 0.00311199\n",
      "Iteration 63, loss = 0.00281252\n",
      "Iteration 64, loss = 0.00347459\n",
      "Iteration 65, loss = 0.00287690\n",
      "Iteration 66, loss = 0.00348640\n",
      "Iteration 67, loss = 0.00346310\n",
      "Iteration 68, loss = 0.00250146\n",
      "Iteration 69, loss = 0.00349045\n",
      "Iteration 70, loss = 0.00251555\n",
      "Iteration 71, loss = 0.00322446\n",
      "Iteration 72, loss = 0.00290688\n",
      "Iteration 73, loss = 0.00299691\n",
      "Iteration 74, loss = 0.00309206\n",
      "Iteration 75, loss = 0.00268359\n",
      "Iteration 76, loss = 0.00284749\n",
      "Iteration 77, loss = 0.00283229\n",
      "Iteration 78, loss = 0.00241536\n",
      "Iteration 79, loss = 0.00317243\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(32, 32, 32), max_iter=1000, verbose=2)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(32,32,32), max_iter=1000,verbose=2)  \n",
    "mlp.fit(X_train_scaled_ss_02, y_train_scaled_ss_02)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.000\n",
      "Test set score: 0.996\n",
      "Accuracy:  0.9959628551192257\n",
      "[[126527    347]\n",
      " [   166     30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.08      0.15      0.10       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.54      0.58      0.55    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test_scaled) \n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mlp.score(X_train_scaled_ss_02, y_train_scaled_ss_02)))\n",
    "print(\"Test set score: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net With 4 Layers (16,16,16,16) SMOTE ss=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.17207928\n",
      "Iteration 2, loss = 0.10656078\n",
      "Iteration 3, loss = 0.08565846\n",
      "Iteration 4, loss = 0.07458580\n",
      "Iteration 5, loss = 0.06696533\n",
      "Iteration 6, loss = 0.06140410\n",
      "Iteration 7, loss = 0.05724502\n",
      "Iteration 8, loss = 0.05394902\n",
      "Iteration 9, loss = 0.05092154\n",
      "Iteration 10, loss = 0.04903449\n",
      "Iteration 11, loss = 0.04722999\n",
      "Iteration 12, loss = 0.04578201\n",
      "Iteration 13, loss = 0.04481346\n",
      "Iteration 14, loss = 0.04360742\n",
      "Iteration 15, loss = 0.04269283\n",
      "Iteration 16, loss = 0.04173238\n",
      "Iteration 17, loss = 0.04095272\n",
      "Iteration 18, loss = 0.04061006\n",
      "Iteration 19, loss = 0.03958253\n",
      "Iteration 20, loss = 0.03923834\n",
      "Iteration 21, loss = 0.03872025\n",
      "Iteration 22, loss = 0.03854328\n",
      "Iteration 23, loss = 0.03793877\n",
      "Iteration 24, loss = 0.03724375\n",
      "Iteration 25, loss = 0.03671070\n",
      "Iteration 26, loss = 0.03652642\n",
      "Iteration 27, loss = 0.03632135\n",
      "Iteration 28, loss = 0.03596089\n",
      "Iteration 29, loss = 0.03555129\n",
      "Iteration 30, loss = 0.03561411\n",
      "Iteration 31, loss = 0.03469250\n",
      "Iteration 32, loss = 0.03485789\n",
      "Iteration 33, loss = 0.03455456\n",
      "Iteration 34, loss = 0.03441640\n",
      "Iteration 35, loss = 0.03380324\n",
      "Iteration 36, loss = 0.03383524\n",
      "Iteration 37, loss = 0.03350562\n",
      "Iteration 38, loss = 0.03349691\n",
      "Iteration 39, loss = 0.03329229\n",
      "Iteration 40, loss = 0.03334289\n",
      "Iteration 41, loss = 0.03251149\n",
      "Iteration 42, loss = 0.03268508\n",
      "Iteration 43, loss = 0.03243594\n",
      "Iteration 44, loss = 0.03196461\n",
      "Iteration 45, loss = 0.03232718\n",
      "Iteration 46, loss = 0.03199708\n",
      "Iteration 47, loss = 0.03154777\n",
      "Iteration 48, loss = 0.03121618\n",
      "Iteration 49, loss = 0.03129054\n",
      "Iteration 50, loss = 0.03122397\n",
      "Iteration 51, loss = 0.03098096\n",
      "Iteration 52, loss = 0.03095282\n",
      "Iteration 53, loss = 0.03125001\n",
      "Iteration 54, loss = 0.03054303\n",
      "Iteration 55, loss = 0.03054155\n",
      "Iteration 56, loss = 0.03037904\n",
      "Iteration 57, loss = 0.03025803\n",
      "Iteration 58, loss = 0.03029923\n",
      "Iteration 59, loss = 0.02988991\n",
      "Iteration 60, loss = 0.03005250\n",
      "Iteration 61, loss = 0.02976157\n",
      "Iteration 62, loss = 0.02972973\n",
      "Iteration 63, loss = 0.02969313\n",
      "Iteration 64, loss = 0.02943890\n",
      "Iteration 65, loss = 0.02969533\n",
      "Iteration 66, loss = 0.02940415\n",
      "Iteration 67, loss = 0.02903001\n",
      "Iteration 68, loss = 0.02894004\n",
      "Iteration 69, loss = 0.02897134\n",
      "Iteration 70, loss = 0.02894305\n",
      "Iteration 71, loss = 0.02868712\n",
      "Iteration 72, loss = 0.02881999\n",
      "Iteration 73, loss = 0.02877631\n",
      "Iteration 74, loss = 0.02839114\n",
      "Iteration 75, loss = 0.02858428\n",
      "Iteration 76, loss = 0.02865800\n",
      "Iteration 77, loss = 0.02819979\n",
      "Iteration 78, loss = 0.02812287\n",
      "Iteration 79, loss = 0.02819728\n",
      "Iteration 80, loss = 0.02795362\n",
      "Iteration 81, loss = 0.02827387\n",
      "Iteration 82, loss = 0.02764758\n",
      "Iteration 83, loss = 0.02787518\n",
      "Iteration 84, loss = 0.02774732\n",
      "Iteration 85, loss = 0.02782933\n",
      "Iteration 86, loss = 0.02763494\n",
      "Iteration 87, loss = 0.02734920\n",
      "Iteration 88, loss = 0.02711371\n",
      "Iteration 89, loss = 0.02725240\n",
      "Iteration 90, loss = 0.02731116\n",
      "Iteration 91, loss = 0.02699983\n",
      "Iteration 92, loss = 0.02735517\n",
      "Iteration 93, loss = 0.02706046\n",
      "Iteration 94, loss = 0.02696576\n",
      "Iteration 95, loss = 0.02722292\n",
      "Iteration 96, loss = 0.02697687\n",
      "Iteration 97, loss = 0.02640416\n",
      "Iteration 98, loss = 0.02658994\n",
      "Iteration 99, loss = 0.02643911\n",
      "Iteration 100, loss = 0.02707258\n",
      "Iteration 101, loss = 0.02654956\n",
      "Iteration 102, loss = 0.02635883\n",
      "Iteration 103, loss = 0.02626288\n",
      "Iteration 104, loss = 0.02642595\n",
      "Iteration 105, loss = 0.02632506\n",
      "Iteration 106, loss = 0.02610350\n",
      "Iteration 107, loss = 0.02622588\n",
      "Iteration 108, loss = 0.02632171\n",
      "Iteration 109, loss = 0.02617031\n",
      "Iteration 110, loss = 0.02604288\n",
      "Iteration 111, loss = 0.02562434\n",
      "Iteration 112, loss = 0.02553148\n",
      "Iteration 113, loss = 0.02616552\n",
      "Iteration 114, loss = 0.02552748\n",
      "Iteration 115, loss = 0.02551256\n",
      "Iteration 116, loss = 0.02548739\n",
      "Iteration 117, loss = 0.02516975\n",
      "Iteration 118, loss = 0.02530525\n",
      "Iteration 119, loss = 0.02533032\n",
      "Iteration 120, loss = 0.02555366\n",
      "Iteration 121, loss = 0.02563821\n",
      "Iteration 122, loss = 0.02531011\n",
      "Iteration 123, loss = 0.02556684\n",
      "Iteration 124, loss = 0.02538479\n",
      "Iteration 125, loss = 0.02476315\n",
      "Iteration 126, loss = 0.02515693\n",
      "Iteration 127, loss = 0.02465806\n",
      "Iteration 128, loss = 0.02514103\n",
      "Iteration 129, loss = 0.02517641\n",
      "Iteration 130, loss = 0.02515437\n",
      "Iteration 131, loss = 0.02503233\n",
      "Iteration 132, loss = 0.02483287\n",
      "Iteration 133, loss = 0.02491750\n",
      "Iteration 134, loss = 0.02473802\n",
      "Iteration 135, loss = 0.02481991\n",
      "Iteration 136, loss = 0.02478401\n",
      "Iteration 137, loss = 0.02496615\n",
      "Iteration 138, loss = 0.02471207\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(16, 16, 16, 16), max_iter=1000, verbose=2)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(16,16,16,16), max_iter=1000,verbose=2)  \n",
    "mlp.fit(X_train_scaled_ss_01, y_train_scaled_ss_01)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.990\n",
      "Test set score: 0.992\n",
      "Accuracy:  0.9923978909262611\n",
      "[[126067    807]\n",
      " [   159     37]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00    126874\n",
      "           1       0.04      0.19      0.07       196\n",
      "\n",
      "    accuracy                           0.99    127070\n",
      "   macro avg       0.52      0.59      0.53    127070\n",
      "weighted avg       1.00      0.99      0.99    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test_scaled) \n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mlp.score(X_train_scaled_ss_01, y_train_scaled_ss_01)))\n",
    "print(\"Test set score: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net With 4 Layers (16,16,16,16) SMOTE ss=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.22027067\n",
      "Iteration 2, loss = 0.12232506\n",
      "Iteration 3, loss = 0.09703940\n",
      "Iteration 4, loss = 0.08472463\n",
      "Iteration 5, loss = 0.07608470\n",
      "Iteration 6, loss = 0.06987898\n",
      "Iteration 7, loss = 0.06561415\n",
      "Iteration 8, loss = 0.06153037\n",
      "Iteration 9, loss = 0.05925825\n",
      "Iteration 10, loss = 0.05733607\n",
      "Iteration 11, loss = 0.05524645\n",
      "Iteration 12, loss = 0.05369757\n",
      "Iteration 13, loss = 0.05253601\n",
      "Iteration 14, loss = 0.05131633\n",
      "Iteration 15, loss = 0.04976630\n",
      "Iteration 16, loss = 0.04899205\n",
      "Iteration 17, loss = 0.04854301\n",
      "Iteration 18, loss = 0.04739479\n",
      "Iteration 19, loss = 0.04737889\n",
      "Iteration 20, loss = 0.04614715\n",
      "Iteration 21, loss = 0.04559122\n",
      "Iteration 22, loss = 0.04548585\n",
      "Iteration 23, loss = 0.04458633\n",
      "Iteration 24, loss = 0.04440766\n",
      "Iteration 25, loss = 0.04391308\n",
      "Iteration 26, loss = 0.04303194\n",
      "Iteration 27, loss = 0.04308927\n",
      "Iteration 28, loss = 0.04221589\n",
      "Iteration 29, loss = 0.04225609\n",
      "Iteration 30, loss = 0.04208371\n",
      "Iteration 31, loss = 0.04132471\n",
      "Iteration 32, loss = 0.04111720\n",
      "Iteration 33, loss = 0.04116161\n",
      "Iteration 34, loss = 0.04070686\n",
      "Iteration 35, loss = 0.04044929\n",
      "Iteration 36, loss = 0.03998314\n",
      "Iteration 37, loss = 0.03972794\n",
      "Iteration 38, loss = 0.03957141\n",
      "Iteration 39, loss = 0.03899281\n",
      "Iteration 40, loss = 0.03891509\n",
      "Iteration 41, loss = 0.03864824\n",
      "Iteration 42, loss = 0.03877167\n",
      "Iteration 43, loss = 0.03861464\n",
      "Iteration 44, loss = 0.03755582\n",
      "Iteration 45, loss = 0.03827778\n",
      "Iteration 46, loss = 0.03769648\n",
      "Iteration 47, loss = 0.03736798\n",
      "Iteration 48, loss = 0.03777107\n",
      "Iteration 49, loss = 0.03726372\n",
      "Iteration 50, loss = 0.03692648\n",
      "Iteration 51, loss = 0.03679704\n",
      "Iteration 52, loss = 0.03663846\n",
      "Iteration 53, loss = 0.03675117\n",
      "Iteration 54, loss = 0.03678501\n",
      "Iteration 55, loss = 0.03647666\n",
      "Iteration 56, loss = 0.03642293\n",
      "Iteration 57, loss = 0.03586190\n",
      "Iteration 58, loss = 0.03670429\n",
      "Iteration 59, loss = 0.03555337\n",
      "Iteration 60, loss = 0.03575630\n",
      "Iteration 61, loss = 0.03589789\n",
      "Iteration 62, loss = 0.03528765\n",
      "Iteration 63, loss = 0.03533986\n",
      "Iteration 64, loss = 0.03527338\n",
      "Iteration 65, loss = 0.03545680\n",
      "Iteration 66, loss = 0.03491665\n",
      "Iteration 67, loss = 0.03494049\n",
      "Iteration 68, loss = 0.03452995\n",
      "Iteration 69, loss = 0.03493897\n",
      "Iteration 70, loss = 0.03420542\n",
      "Iteration 71, loss = 0.03387932\n",
      "Iteration 72, loss = 0.03397523\n",
      "Iteration 73, loss = 0.03405376\n",
      "Iteration 74, loss = 0.03359949\n",
      "Iteration 75, loss = 0.03364715\n",
      "Iteration 76, loss = 0.03311421\n",
      "Iteration 77, loss = 0.03304317\n",
      "Iteration 78, loss = 0.03286093\n",
      "Iteration 79, loss = 0.03298276\n",
      "Iteration 80, loss = 0.03248530\n",
      "Iteration 81, loss = 0.03259005\n",
      "Iteration 82, loss = 0.03231236\n",
      "Iteration 83, loss = 0.03260525\n",
      "Iteration 84, loss = 0.03221409\n",
      "Iteration 85, loss = 0.03209093\n",
      "Iteration 86, loss = 0.03194757\n",
      "Iteration 87, loss = 0.03207659\n",
      "Iteration 88, loss = 0.03173278\n",
      "Iteration 89, loss = 0.03155435\n",
      "Iteration 90, loss = 0.03145024\n",
      "Iteration 91, loss = 0.03125356\n",
      "Iteration 92, loss = 0.03132762\n",
      "Iteration 93, loss = 0.03102816\n",
      "Iteration 94, loss = 0.03099623\n",
      "Iteration 95, loss = 0.03080901\n",
      "Iteration 96, loss = 0.03082111\n",
      "Iteration 97, loss = 0.03089138\n",
      "Iteration 98, loss = 0.03091776\n",
      "Iteration 99, loss = 0.03071936\n",
      "Iteration 100, loss = 0.03040164\n",
      "Iteration 101, loss = 0.03052756\n",
      "Iteration 102, loss = 0.03070421\n",
      "Iteration 103, loss = 0.02998556\n",
      "Iteration 104, loss = 0.03049751\n",
      "Iteration 105, loss = 0.02986979\n",
      "Iteration 106, loss = 0.03003275\n",
      "Iteration 107, loss = 0.02993412\n",
      "Iteration 108, loss = 0.02982176\n",
      "Iteration 109, loss = 0.02986692\n",
      "Iteration 110, loss = 0.02965032\n",
      "Iteration 111, loss = 0.03011531\n",
      "Iteration 112, loss = 0.03003342\n",
      "Iteration 113, loss = 0.02973956\n",
      "Iteration 114, loss = 0.02981179\n",
      "Iteration 115, loss = 0.02966914\n",
      "Iteration 116, loss = 0.02944249\n",
      "Iteration 117, loss = 0.02935105\n",
      "Iteration 118, loss = 0.02924902\n",
      "Iteration 119, loss = 0.02903387\n",
      "Iteration 120, loss = 0.02928592\n",
      "Iteration 121, loss = 0.02893325\n",
      "Iteration 122, loss = 0.02904867\n",
      "Iteration 123, loss = 0.02908734\n",
      "Iteration 124, loss = 0.02864149\n",
      "Iteration 125, loss = 0.02884658\n",
      "Iteration 126, loss = 0.02856185\n",
      "Iteration 127, loss = 0.02857225\n",
      "Iteration 128, loss = 0.02847795\n",
      "Iteration 129, loss = 0.02871995\n",
      "Iteration 130, loss = 0.02825341\n",
      "Iteration 131, loss = 0.02822163\n",
      "Iteration 132, loss = 0.02863513\n",
      "Iteration 133, loss = 0.02842808\n",
      "Iteration 134, loss = 0.02833852\n",
      "Iteration 135, loss = 0.02834673\n",
      "Iteration 136, loss = 0.02823853\n",
      "Iteration 137, loss = 0.02780190\n",
      "Iteration 138, loss = 0.02845049\n",
      "Iteration 139, loss = 0.02813305\n",
      "Iteration 140, loss = 0.02803539\n",
      "Iteration 141, loss = 0.02846529\n",
      "Iteration 142, loss = 0.02753234\n",
      "Iteration 143, loss = 0.02812991\n",
      "Iteration 144, loss = 0.02782541\n",
      "Iteration 145, loss = 0.02797712\n",
      "Iteration 146, loss = 0.02772808\n",
      "Iteration 147, loss = 0.02770304\n",
      "Iteration 148, loss = 0.02765323\n",
      "Iteration 149, loss = 0.02791423\n",
      "Iteration 150, loss = 0.02744435\n",
      "Iteration 151, loss = 0.02765757\n",
      "Iteration 152, loss = 0.02786653\n",
      "Iteration 153, loss = 0.02754191\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(16, 16, 16, 16), max_iter=1000, verbose=2)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(16,16,16,16), max_iter=1000,verbose=2)  \n",
    "mlp.fit(X_train_scaled_ss_02, y_train_scaled_ss_02)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.992\n",
      "Test set score: 0.988\n",
      "Accuracy:  0.9878256079326355\n",
      "[[125472   1402]\n",
      " [   145     51]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    126874\n",
      "           1       0.04      0.26      0.06       196\n",
      "\n",
      "    accuracy                           0.99    127070\n",
      "   macro avg       0.52      0.62      0.53    127070\n",
      "weighted avg       1.00      0.99      0.99    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test_scaled) \n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mlp.score(X_train_scaled_ss_02, y_train_scaled_ss_02)))\n",
    "print(\"Test set score: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net With 4 Layers (32,32,32,32) SMOTE ss=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.13339497\n",
      "Iteration 2, loss = 0.05355025\n",
      "Iteration 3, loss = 0.03392418\n",
      "Iteration 4, loss = 0.02469152\n",
      "Iteration 5, loss = 0.02103507\n",
      "Iteration 6, loss = 0.01895932\n",
      "Iteration 7, loss = 0.01615737\n",
      "Iteration 8, loss = 0.01524168\n",
      "Iteration 9, loss = 0.01428103\n",
      "Iteration 10, loss = 0.01288816\n",
      "Iteration 11, loss = 0.01205065\n",
      "Iteration 12, loss = 0.01135119\n",
      "Iteration 13, loss = 0.01081009\n",
      "Iteration 14, loss = 0.01024013\n",
      "Iteration 15, loss = 0.00982240\n",
      "Iteration 16, loss = 0.00921986\n",
      "Iteration 17, loss = 0.00857861\n",
      "Iteration 18, loss = 0.00886507\n",
      "Iteration 19, loss = 0.00759356\n",
      "Iteration 20, loss = 0.00839627\n",
      "Iteration 21, loss = 0.00727834\n",
      "Iteration 22, loss = 0.00669538\n",
      "Iteration 23, loss = 0.00674127\n",
      "Iteration 24, loss = 0.00715069\n",
      "Iteration 25, loss = 0.00691574\n",
      "Iteration 26, loss = 0.00582832\n",
      "Iteration 27, loss = 0.00626608\n",
      "Iteration 28, loss = 0.00563559\n",
      "Iteration 29, loss = 0.00575564\n",
      "Iteration 30, loss = 0.00582178\n",
      "Iteration 31, loss = 0.00516414\n",
      "Iteration 32, loss = 0.00571607\n",
      "Iteration 33, loss = 0.00513481\n",
      "Iteration 34, loss = 0.00544895\n",
      "Iteration 35, loss = 0.00500493\n",
      "Iteration 36, loss = 0.00503345\n",
      "Iteration 37, loss = 0.00432540\n",
      "Iteration 38, loss = 0.00490927\n",
      "Iteration 39, loss = 0.00440970\n",
      "Iteration 40, loss = 0.00452713\n",
      "Iteration 41, loss = 0.00449495\n",
      "Iteration 42, loss = 0.00445852\n",
      "Iteration 43, loss = 0.00427970\n",
      "Iteration 44, loss = 0.00391361\n",
      "Iteration 45, loss = 0.00423745\n",
      "Iteration 46, loss = 0.00429735\n",
      "Iteration 47, loss = 0.00379994\n",
      "Iteration 48, loss = 0.00397163\n",
      "Iteration 49, loss = 0.00414281\n",
      "Iteration 50, loss = 0.00349730\n",
      "Iteration 51, loss = 0.00328171\n",
      "Iteration 52, loss = 0.00426412\n",
      "Iteration 53, loss = 0.00407285\n",
      "Iteration 54, loss = 0.00342050\n",
      "Iteration 55, loss = 0.00368346\n",
      "Iteration 56, loss = 0.00363065\n",
      "Iteration 57, loss = 0.00346537\n",
      "Iteration 58, loss = 0.00339378\n",
      "Iteration 59, loss = 0.00309177\n",
      "Iteration 60, loss = 0.00333353\n",
      "Iteration 61, loss = 0.00335269\n",
      "Iteration 62, loss = 0.00330715\n",
      "Iteration 63, loss = 0.00320216\n",
      "Iteration 64, loss = 0.00292215\n",
      "Iteration 65, loss = 0.00346425\n",
      "Iteration 66, loss = 0.00319489\n",
      "Iteration 67, loss = 0.00364424\n",
      "Iteration 68, loss = 0.00328195\n",
      "Iteration 69, loss = 0.00294071\n",
      "Iteration 70, loss = 0.00346315\n",
      "Iteration 71, loss = 0.00267125\n",
      "Iteration 72, loss = 0.00376483\n",
      "Iteration 73, loss = 0.00223813\n",
      "Iteration 74, loss = 0.00318584\n",
      "Iteration 75, loss = 0.00288485\n",
      "Iteration 76, loss = 0.00271950\n",
      "Iteration 77, loss = 0.00275418\n",
      "Iteration 78, loss = 0.00318965\n",
      "Iteration 79, loss = 0.00264474\n",
      "Iteration 80, loss = 0.00281589\n",
      "Iteration 81, loss = 0.00219551\n",
      "Iteration 82, loss = 0.00304842\n",
      "Iteration 83, loss = 0.00238044\n",
      "Iteration 84, loss = 0.00300100\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(32, 32, 32, 32), max_iter=1000, verbose=2)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(32,32,32,32), max_iter=1000,verbose=2)  \n",
    "mlp.fit(X_train_scaled_ss_01, y_train_scaled_ss_01)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.999\n",
      "Test set score: 0.995\n",
      "Accuracy:  0.9951837569843394\n",
      "[[126420    454]\n",
      " [   158     38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.08      0.19      0.11       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.54      0.60      0.55    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test_scaled) \n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mlp.score(X_train_scaled_ss_01, y_train_scaled_ss_01)))\n",
    "print(\"Test set score: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net With SMOTE ss=1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net With 4 Layers (32,32,32,32) SMOTE ss=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.15651324\n",
      "Iteration 2, loss = 0.04485582\n",
      "Iteration 3, loss = 0.02853554\n",
      "Iteration 4, loss = 0.02233710\n",
      "Iteration 5, loss = 0.01797502\n",
      "Iteration 6, loss = 0.01609885\n",
      "Iteration 7, loss = 0.01401507\n",
      "Iteration 8, loss = 0.01393788\n",
      "Iteration 9, loss = 0.01189261\n",
      "Iteration 10, loss = 0.01120514\n",
      "Iteration 11, loss = 0.01109739\n",
      "Iteration 12, loss = 0.01022266\n",
      "Iteration 13, loss = 0.00932680\n",
      "Iteration 14, loss = 0.00882786\n",
      "Iteration 15, loss = 0.00876033\n",
      "Iteration 16, loss = 0.00810792\n",
      "Iteration 17, loss = 0.00793529\n",
      "Iteration 18, loss = 0.00729094\n",
      "Iteration 19, loss = 0.00741692\n",
      "Iteration 20, loss = 0.00688547\n",
      "Iteration 21, loss = 0.00643791\n",
      "Iteration 22, loss = 0.00683622\n",
      "Iteration 23, loss = 0.00602773\n",
      "Iteration 24, loss = 0.00625929\n",
      "Iteration 25, loss = 0.00561432\n",
      "Iteration 26, loss = 0.00613331\n",
      "Iteration 27, loss = 0.00525087\n",
      "Iteration 28, loss = 0.00523967\n",
      "Iteration 29, loss = 0.00537190\n",
      "Iteration 30, loss = 0.00556560\n",
      "Iteration 31, loss = 0.00487161\n",
      "Iteration 32, loss = 0.00517050\n",
      "Iteration 33, loss = 0.00458486\n",
      "Iteration 34, loss = 0.00465568\n",
      "Iteration 35, loss = 0.00472462\n",
      "Iteration 36, loss = 0.00416031\n",
      "Iteration 37, loss = 0.00423198\n",
      "Iteration 38, loss = 0.00447378\n",
      "Iteration 39, loss = 0.00454042\n",
      "Iteration 40, loss = 0.00379135\n",
      "Iteration 41, loss = 0.00417133\n",
      "Iteration 42, loss = 0.00366202\n",
      "Iteration 43, loss = 0.00402632\n",
      "Iteration 44, loss = 0.00367998\n",
      "Iteration 45, loss = 0.00408471\n",
      "Iteration 46, loss = 0.00329256\n",
      "Iteration 47, loss = 0.00388199\n",
      "Iteration 48, loss = 0.00407289\n",
      "Iteration 49, loss = 0.00290665\n",
      "Iteration 50, loss = 0.00391233\n",
      "Iteration 51, loss = 0.00326178\n",
      "Iteration 52, loss = 0.00357403\n",
      "Iteration 53, loss = 0.00335098\n",
      "Iteration 54, loss = 0.00340696\n",
      "Iteration 55, loss = 0.00352547\n",
      "Iteration 56, loss = 0.00329051\n",
      "Iteration 57, loss = 0.00315784\n",
      "Iteration 58, loss = 0.00352817\n",
      "Iteration 59, loss = 0.00300123\n",
      "Iteration 60, loss = 0.00251263\n",
      "Iteration 61, loss = 0.00336591\n",
      "Iteration 62, loss = 0.00273235\n",
      "Iteration 63, loss = 0.00293349\n",
      "Iteration 64, loss = 0.00304748\n",
      "Iteration 65, loss = 0.00215699\n",
      "Iteration 66, loss = 0.00389490\n",
      "Iteration 67, loss = 0.00216925\n",
      "Iteration 68, loss = 0.00308562\n",
      "Iteration 69, loss = 0.00266718\n",
      "Iteration 70, loss = 0.00284481\n",
      "Iteration 71, loss = 0.00265421\n",
      "Iteration 72, loss = 0.00251803\n",
      "Iteration 73, loss = 0.00269286\n",
      "Iteration 74, loss = 0.00288301\n",
      "Iteration 75, loss = 0.00262509\n",
      "Iteration 76, loss = 0.00303165\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(32, 32, 32, 32), max_iter=1000, verbose=2)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(32,32,32,32), max_iter=1000,verbose=2)  \n",
    "mlp.fit(X_train_scaled_ss_02, y_train_scaled_ss_02)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.999\n",
      "Test set score: 0.995\n",
      "Accuracy:  0.9954828047532855\n",
      "[[126464    410]\n",
      " [   164     32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.07      0.16      0.10       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.54      0.58      0.55    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test_scaled) \n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mlp.score(X_train_scaled_ss_02, y_train_scaled_ss_02)))\n",
    "print(\"Test set score: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net With 4 Layers (32,32,32,32) SMOTE ss=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.14660130\n",
      "Iteration 2, loss = 0.04132074\n",
      "Iteration 3, loss = 0.02791592\n",
      "Iteration 4, loss = 0.02216910\n",
      "Iteration 5, loss = 0.01853869\n",
      "Iteration 6, loss = 0.01634886\n",
      "Iteration 7, loss = 0.01495367\n",
      "Iteration 8, loss = 0.01368400\n",
      "Iteration 9, loss = 0.01223319\n",
      "Iteration 10, loss = 0.01192523\n",
      "Iteration 11, loss = 0.01110994\n",
      "Iteration 12, loss = 0.01038465\n",
      "Iteration 13, loss = 0.00937631\n",
      "Iteration 14, loss = 0.00937778\n",
      "Iteration 15, loss = 0.00872488\n",
      "Iteration 16, loss = 0.00814743\n",
      "Iteration 17, loss = 0.00781805\n",
      "Iteration 18, loss = 0.00761393\n",
      "Iteration 19, loss = 0.00685108\n",
      "Iteration 20, loss = 0.00693112\n",
      "Iteration 21, loss = 0.00669896\n",
      "Iteration 22, loss = 0.00656909\n",
      "Iteration 23, loss = 0.00645464\n",
      "Iteration 24, loss = 0.00578230\n",
      "Iteration 25, loss = 0.00582598\n",
      "Iteration 26, loss = 0.00549720\n",
      "Iteration 27, loss = 0.00534752\n",
      "Iteration 28, loss = 0.00573510\n",
      "Iteration 29, loss = 0.00497255\n",
      "Iteration 30, loss = 0.00504671\n",
      "Iteration 31, loss = 0.00438947\n",
      "Iteration 32, loss = 0.00497555\n",
      "Iteration 33, loss = 0.00478943\n",
      "Iteration 34, loss = 0.00430500\n",
      "Iteration 35, loss = 0.00416218\n",
      "Iteration 36, loss = 0.00425343\n",
      "Iteration 37, loss = 0.00413157\n",
      "Iteration 38, loss = 0.00408164\n",
      "Iteration 39, loss = 0.00417938\n",
      "Iteration 40, loss = 0.00386718\n",
      "Iteration 41, loss = 0.00359135\n",
      "Iteration 42, loss = 0.00394586\n",
      "Iteration 43, loss = 0.00374467\n",
      "Iteration 44, loss = 0.00394885\n",
      "Iteration 45, loss = 0.00305194\n",
      "Iteration 46, loss = 0.00379175\n",
      "Iteration 47, loss = 0.00380282\n",
      "Iteration 48, loss = 0.00340005\n",
      "Iteration 49, loss = 0.00313262\n",
      "Iteration 50, loss = 0.00320186\n",
      "Iteration 51, loss = 0.00302222\n",
      "Iteration 52, loss = 0.00368728\n",
      "Iteration 53, loss = 0.00301675\n",
      "Iteration 54, loss = 0.00305439\n",
      "Iteration 55, loss = 0.00293003\n",
      "Iteration 56, loss = 0.00346152\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(32, 32, 32, 32), max_iter=1000, verbose=2)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(32,32,32,32), max_iter=1000,verbose=2)  \n",
    "mlp.fit(X_train_scaled_ss_05, y_train_scaled_ss_05)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.000\n",
      "Test set score: 0.996\n",
      "Accuracy:  0.9955772408908475\n",
      "[[126468    406]\n",
      " [   156     40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.09      0.20      0.12       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.54      0.60      0.56    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test_scaled) \n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mlp.score(X_train_scaled_ss_05, y_train_scaled_ss_05)))\n",
    "print(\"Test set score: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net With 4 Layers (32,32,32,32) SMOTE ss=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.11604227\n",
      "Iteration 2, loss = 0.03173838\n",
      "Iteration 3, loss = 0.02319945\n",
      "Iteration 4, loss = 0.01899796\n",
      "Iteration 5, loss = 0.01644877\n",
      "Iteration 6, loss = 0.01442764\n",
      "Iteration 7, loss = 0.01341342\n",
      "Iteration 8, loss = 0.01269000\n",
      "Iteration 9, loss = 0.01110869\n",
      "Iteration 10, loss = 0.01087883\n",
      "Iteration 11, loss = 0.00974009\n",
      "Iteration 12, loss = 0.00898092\n",
      "Iteration 13, loss = 0.00825962\n",
      "Iteration 14, loss = 0.00873855\n",
      "Iteration 15, loss = 0.00745496\n",
      "Iteration 16, loss = 0.00708929\n",
      "Iteration 17, loss = 0.00691486\n",
      "Iteration 18, loss = 0.00660847\n",
      "Iteration 19, loss = 0.00666481\n",
      "Iteration 20, loss = 0.00620412\n",
      "Iteration 21, loss = 0.00568480\n",
      "Iteration 22, loss = 0.00548427\n",
      "Iteration 23, loss = 0.00602051\n",
      "Iteration 24, loss = 0.00534291\n",
      "Iteration 25, loss = 0.00514543\n",
      "Iteration 26, loss = 0.00481538\n",
      "Iteration 27, loss = 0.00470267\n",
      "Iteration 28, loss = 0.00504599\n",
      "Iteration 29, loss = 0.00459687\n",
      "Iteration 30, loss = 0.00438158\n",
      "Iteration 31, loss = 0.00444506\n",
      "Iteration 32, loss = 0.00441882\n",
      "Iteration 33, loss = 0.00395593\n",
      "Iteration 34, loss = 0.00437897\n",
      "Iteration 35, loss = 0.00399974\n",
      "Iteration 36, loss = 0.00385249\n",
      "Iteration 37, loss = 0.00421987\n",
      "Iteration 38, loss = 0.00362701\n",
      "Iteration 39, loss = 0.00374505\n",
      "Iteration 40, loss = 0.00376404\n",
      "Iteration 41, loss = 0.00355240\n",
      "Iteration 42, loss = 0.00352645\n",
      "Iteration 43, loss = 0.00331679\n",
      "Iteration 44, loss = 0.00344219\n",
      "Iteration 45, loss = 0.00298267\n",
      "Iteration 46, loss = 0.00374328\n",
      "Iteration 47, loss = 0.00314073\n",
      "Iteration 48, loss = 0.00301235\n",
      "Iteration 49, loss = 0.00296636\n",
      "Iteration 50, loss = 0.00314926\n",
      "Iteration 51, loss = 0.00284487\n",
      "Iteration 52, loss = 0.00270327\n",
      "Iteration 53, loss = 0.00310632\n",
      "Iteration 54, loss = 0.00292831\n",
      "Iteration 55, loss = 0.00294226\n",
      "Iteration 56, loss = 0.00266574\n",
      "Iteration 57, loss = 0.00274960\n",
      "Iteration 58, loss = 0.00286092\n",
      "Iteration 59, loss = 0.00303631\n",
      "Iteration 60, loss = 0.00259017\n",
      "Iteration 61, loss = 0.00262822\n",
      "Iteration 62, loss = 0.00250618\n",
      "Iteration 63, loss = 0.00279609\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(32, 32, 32, 32), max_iter=1000, verbose=2)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(32,32,32,32), max_iter=1000,verbose=2)  \n",
    "mlp.fit(X_train_scaled_ss_10, y_train_scaled_ss_10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.999\n",
      "Test set score: 0.995\n",
      "Accuracy:  0.9949555363185646\n",
      "[[126394    480]\n",
      " [   161     35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.07      0.18      0.10       196\n",
      "\n",
      "    accuracy                           0.99    127070\n",
      "   macro avg       0.53      0.59      0.55    127070\n",
      "weighted avg       1.00      0.99      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test_scaled) \n",
    "\n",
    "# Score\n",
    "print(\"Training set score: {:.3f}\".format(mlp.score(X_train_scaled_ss_10, y_train_scaled_ss_10)))\n",
    "print(\"Test set score: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful when running this, about 2 full days are needed to run this!!!\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "test_scores = []\n",
    "train_scores = []\n",
    "\n",
    "for i in range(1,15):\n",
    "\n",
    "    knn = KNeighborsClassifier(i)\n",
    "    knn.fit(X_train_scaled,y_train)\n",
    "    \n",
    "    train_scores.append(knn.score(X_train_scaled,y_train))\n",
    "    test_scores.append(knn.score(X_test_scaled,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max train score 100.0 % and k = [1]\n"
     ]
    }
   ],
   "source": [
    "## score that comes from testing on the same datapoints that were used for training\n",
    "max_train_score = max(train_scores)\n",
    "train_scores_ind = [i for i, v in enumerate(train_scores) if v == max_train_score]\n",
    "print('Max train score {} % and k = {}'.format(max_train_score*100,list(map(lambda x: x+1, train_scores_ind))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max test score 99.84968914771386 % and k = [7, 8]\n"
     ]
    }
   ],
   "source": [
    "## score that comes from testing on the datapoints that were split in the beginning to be used for testing solely\n",
    "max_test_score = max(test_scores)\n",
    "test_scores_ind = [i for i, v in enumerate(test_scores) if v == max_test_score]\n",
    "print('Max test score {} % and k = {}'.format(max_test_score*100,list(map(lambda x: x+1, test_scores_ind))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2389a99f988>]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(range(1,15),train_scores,marker='*',label='Train Score')\n",
    "plt.plot(range(1,15),test_scores,marker='o',label='Test Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# From the above, the best KNN is at k=8\n",
    "#Setup a knn classifier with k neighbors\n",
    "best_knn = KNeighborsClassifier(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9984968914771386"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the KNN model with training data and score the test data\n",
    "\n",
    "best_knn.fit(X_train_scaled,y_train)\n",
    "best_knn.score(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename = 'best_knn_without_smote.sav'\n",
    "pickle.dump(best_knn, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk, NO NEED TO RUN IF NOT NECESSARY\n",
    "knn_loaded_model = pickle.load(open(filename, 'rb'))\n",
    "#result = knn_loaded_model.score(X_test, y_test)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.999\n",
      "Test set score: 0.998\n",
      "Accuracy:  0.9984968914771386\n",
      "[[126868      6]\n",
      " [   185     11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    126874\n",
      "           1       0.65      0.06      0.10       196\n",
      "\n",
      "    accuracy                           1.00    127070\n",
      "   macro avg       0.82      0.53      0.55    127070\n",
      "weighted avg       1.00      1.00      1.00    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_knn.predict(X_test_scaled)\n",
    "# Score for Best KNN, No SMOTE\n",
    "print(\"Training set score: {:.3f}\".format(best_knn.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(best_knn.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN With SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN With SMOTE ss=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=8)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the KNN model with training data and score the test data\n",
    "best_knn.fit(X_train_scaled_ss_01,y_train_scaled_ss_01)\n",
    "#best_knn.score(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'best_knn_with_smote_ss_01.sav'\n",
    "pickle.dump(best_knn, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "knn_loaded_model = pickle.load(open(filename, 'rb'))\n",
    "#result = knn_loaded_model.score(X_test, y_test)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.991\n",
      "Test set score: 0.985\n",
      "Accuracy:  0.9850869599433383\n",
      "[[125110   1764]\n",
      " [   131     65]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    126874\n",
      "           1       0.04      0.33      0.06       196\n",
      "\n",
      "    accuracy                           0.99    127070\n",
      "   macro avg       0.52      0.66      0.53    127070\n",
      "weighted avg       1.00      0.99      0.99    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_knn.predict(X_test_scaled)\n",
    "# Score for Best KNN, with SMOTE\n",
    "print(\"Training set score: {:.3f}\".format(best_knn.score(X_train_scaled_ss_01, y_train_scaled_ss_01)))\n",
    "print(\"Test set score: {:.3f}\".format(best_knn.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN With SMOTE ss=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=8)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the KNN model with training data and score the test data\n",
    "best_knn.fit(X_train_scaled_ss_05,y_train_scaled_ss_05)\n",
    "#best_knn.score(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'best_knn_with_smote_ss_05.sav'\n",
    "pickle.dump(best_knn, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "knn_loaded_model = pickle.load(open(filename, 'rb'))\n",
    "#result = knn_loaded_model.score(X_test, y_test)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.991\n",
      "Test set score: 0.980\n",
      "Accuracy:  0.9802156291807665\n",
      "[[124485   2389]\n",
      " [   125     71]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99    126874\n",
      "           1       0.03      0.36      0.05       196\n",
      "\n",
      "    accuracy                           0.98    127070\n",
      "   macro avg       0.51      0.67      0.52    127070\n",
      "weighted avg       1.00      0.98      0.99    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_knn.predict(X_test_scaled)\n",
    "# Score for Best KNN, with SMOTE\n",
    "print(\"Training set score: {:.3f}\".format(best_knn.score(X_train_scaled_ss_05, y_train_scaled_ss_05)))\n",
    "print(\"Test set score: {:.3f}\".format(best_knn.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN With SMOTE ss=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=8)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the KNN model with training data and score the test data\n",
    "best_knn.fit(X_train_scaled_ss_10,y_train_scaled_ss_10)\n",
    "#best_knn.score(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'best_knn_with_smote_ss_10.sav'\n",
    "pickle.dump(best_knn, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "knn_loaded_model = pickle.load(open(filename, 'rb'))\n",
    "#result = knn_loaded_model.score(X_test, y_test)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.993\n",
      "Test set score: 0.980\n",
      "Accuracy:  0.9798536239867789\n",
      "[[124439   2435]\n",
      " [   125     71]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99    126874\n",
      "           1       0.03      0.36      0.05       196\n",
      "\n",
      "    accuracy                           0.98    127070\n",
      "   macro avg       0.51      0.67      0.52    127070\n",
      "weighted avg       1.00      0.98      0.99    127070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_knn.predict(X_test_scaled)\n",
    "# Score for Best KNN, with SMOTE\n",
    "print(\"Training set score: {:.3f}\".format(best_knn.score(X_train_scaled_ss_10, y_train_scaled_ss_10)))\n",
    "print(\"Test set score: {:.3f}\".format(best_knn.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
