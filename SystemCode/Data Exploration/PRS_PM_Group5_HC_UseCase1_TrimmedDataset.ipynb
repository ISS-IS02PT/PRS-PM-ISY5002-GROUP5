{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parkway Project Use Case 1: Write Off Cases Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', 500)\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "import pickle\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Users\\mokky\\Documents\\GitHub\\nus-iss\\PRS-PM-ISY5002-GROUP5\\SystemCode\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('d:/Users/mokky/Documents/GitHub/nus-iss/PRS-PM-ISY5002-GROUP5/SystemCode')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from datapipeline import Datapipeline\n",
    "dpl = Datapipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = './data/uc1'\n",
    "dict_X_train_file_paths = {\n",
    "    'GHL' : [file_dir + 'GHL_new_train_X_uc1.pkl'],\n",
    "    'MEH' : [file_dir + 'MEH_new_train_X_uc1.pkl'],\n",
    "    'PEH' : [file_dir + 'PEH_new_train_X_uc1.pkl'],\n",
    "    'PNH' : [file_dir + 'PNH_new_train_X_uc1.pkl']\n",
    "}\n",
    "dict_y_train_file_paths = {\n",
    "    'GHL' : file_dir + 'GHL_data_y_train.pkl',\n",
    "    'MEH' : file_dir + 'MEH_data_y_train.pkl',\n",
    "    'PEH' : file_dir + 'PEH_data_y_train.pkl',\n",
    "    'PNH' : file_dir + 'PNH_data_y_train.pkl'\n",
    "}\n",
    "dict_X_test_file_paths = {\n",
    "    'GHL' : [file_dir + 'GHL_new_test_X_uc1.pkl'],\n",
    "    'MEH' : [file_dir + 'MEH_new_test_X_uc1.pkl'],\n",
    "    'PEH' : [file_dir + 'PEH_new_test_X_uc1.pkl'],\n",
    "    'PNH' : [file_dir + 'PNH_new_test_X_uc1.pkl']\n",
    "}\n",
    "dict_y_test_file_paths = {\n",
    "    'GHL' : file_dir + 'GHL_data_y_test.pkl',\n",
    "    'MEH' : file_dir + 'MEH_data_y_test.pkl',\n",
    "    'PEH' : file_dir + 'PEH_data_y_test.pkl',\n",
    "    'PNH' : file_dir + 'PNH_data_y_test.pkl'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/uc1GHL_new_train_X_uc1.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-189728f4e692>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mhosp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdict_X_train_file_paths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     dict_df_X_train[hosp] = pd.concat([pd.read_pickle(file_path)\n\u001b[1;32m----> 8\u001b[1;33m                                        for file_path in dict_X_train_file_paths[hosp]])\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'X_train {hosp} {dict_df_X_train[hosp].shape}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-189728f4e692>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mhosp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdict_X_train_file_paths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     dict_df_X_train[hosp] = pd.concat([pd.read_pickle(file_path)\n\u001b[1;32m----> 8\u001b[1;33m                                        for file_path in dict_X_train_file_paths[hosp]])\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'X_train {hosp} {dict_df_X_train[hosp].shape}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\prpms\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcompression\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"infer\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[0mcompression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# 1) try standard library Pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\prpms\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/uc1GHL_new_train_X_uc1.pkl'"
     ]
    }
   ],
   "source": [
    "dict_df_X_train = {}\n",
    "dict_df_y_train = {}\n",
    "dict_df_X_test = {}\n",
    "dict_df_y_test = {}\n",
    "\n",
    "for hosp in dict_X_train_file_paths:\n",
    "    dict_df_X_train[hosp] = pd.concat([pd.read_pickle(file_path)\n",
    "                                       for file_path in dict_X_train_file_paths[hosp]])\n",
    "    print(f'X_train {hosp} {dict_df_X_train[hosp].shape}')\n",
    "    \n",
    "    dict_df_y_train[hosp] = pd.read_pickle(dict_y_train_file_paths[hosp])\n",
    "    print(f'y_train {hosp} {dict_df_y_train[hosp].shape}')\n",
    "\n",
    "    dict_df_X_test[hosp] = pd.concat([pd.read_pickle(file_path)\n",
    "                                      for file_path in dict_X_test_file_paths[hosp]])\n",
    "    print(f'X_test {hosp} {dict_df_X_test[hosp].shape}')\n",
    "\n",
    "    dict_df_y_test[hosp] = pd.read_pickle(dict_y_test_file_paths[hosp])\n",
    "    print(f'y_test {hosp} {dict_df_y_test[hosp].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y(df):\n",
    "    df1 = dpl.bin_column(df.to_frame(), col='WRITE_OFF', bin_thresh = [500])\n",
    "    df1 = pd.get_dummies(df1['bin_WRITE_OFF'])\n",
    "    df1 = df1.drop(0, axis=1)\n",
    "    df1.columns = ['WRITE_OFF_LABEL']\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hosp in dict_df_y_train:\n",
    "    dict_df_y_train[hosp] = convert_y(dict_df_y_train[hosp])\n",
    "    dict_df_y_test[hosp] = convert_y(dict_df_y_test[hosp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECISION TREE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree WITHOUT SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "from sklearn.tree import export_graphviz\n",
    "from subprocess import call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = 'entropy'\n",
    "rand_seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hosp in dict_df_X_train:\n",
    "    model = DecisionTreeClassifier(criterion=criterion,random_state=rand_seed)\n",
    "    model.fit(dict_df_X_train[hosp], dict_df_y_train[hosp])\n",
    "    print(model)\n",
    "    print(f\"Accuracy on {hosp} training set without SMOTE decision tree: {model.score(dict_df_X_train[hosp], dict_df_y_train[hosp])}\")\n",
    "    print(f\"Accuracy on {hosp} test set without SMOTE decision tree: {model.score(dict_df_X_test[hosp], dict_df_y_test[hosp])}\")\n",
    "    \n",
    "    filename = file_dir + f'{hosp}_uc1_no_smote_dt_model.pkl'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    \n",
    "    y_pred = model.predict(dict_df_X_test[hosp])\n",
    "    print(hosp, 'decision tree\\n', confusion_matrix(dict_df_y_test[hosp], y_pred))  \n",
    "    print(hosp, 'decision tree\\n', classification_report(dict_df_y_test[hosp], y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree WITH SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree WITH SMOTE SS = 0.1 ~ 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for hosp in dict_df_X_train:\n",
    "    for sample in np.arange(0.1, 1.1, 0.1):\n",
    "        sm_ss = SMOTE(random_state=55,sampling_strategy=sample)\n",
    "        X_train_ss, y_train_ss = sm_ss.fit_sample(dict_df_X_train[hosp], dict_df_y_train[hosp])\n",
    "        \n",
    "        model = DecisionTreeClassifier(criterion=criterion,random_state=rand_seed)\n",
    "        model.fit(X_train_ss, y_train_ss)\n",
    "        print(model)\n",
    "        print(f\"Accuracy on {hosp} training set with {sample} SMOTE decision tree: {model.score(X_train_ss, y_train_ss)}\")\n",
    "        print(f\"Accuracy on {hosp} test set with {sample} SMOTE decision tree: {model.score(dict_df_X_test[hosp], dict_df_y_test[hosp])}\")\n",
    "    \n",
    "        filename = file_dir + f'{hosp}_uc1_{sample}_smote_dt_model.pkl'\n",
    "        pickle.dump(model, open(filename, 'wb'))\n",
    "        \n",
    "        y_pred = model.predict(dict_df_X_test[hosp])\n",
    "        print(hosp, 'decision tree \\n', confusion_matrix(dict_df_y_test[hosp], y_pred))  \n",
    "        print(hosp, 'decision tree \\n', classification_report(dict_df_y_test[hosp], y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_strength = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hosp in dict_df_X_train:\n",
    "    model = LogisticRegression(C=reg_strength).fit(dict_df_X_train[hosp], dict_df_y_train[hosp])\n",
    "    print(model)\n",
    "    print(f\"{hosp} Training set without SMOTE log reg score: {model.score(dict_df_X_train[hosp], dict_df_y_train[hosp])}\")\n",
    "    print(f\"{hosp} Test set without SMOTE log reg score: {model.score(dict_df_X_test[hosp], dict_df_y_test[hosp])}\")\n",
    "    \n",
    "    filename = file_dir + f'{hosp}_uc1_no_smote_logreg_model.pkl'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    \n",
    "    y_pred = model.predict(dict_df_X_test[hosp])\n",
    "    print(hosp, 'log reg \\n', confusion_matrix(dict_df_y_test[hosp], y_pred))  \n",
    "    print(hosp, 'log reg \\n', classification_report(dict_df_y_test[hosp], y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression With SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression With SMOTE ss=0.1 ~ 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hosp in dict_df_X_train:\n",
    "    for sample in np.arange(0.1, 1.1, 0.1):\n",
    "        sm_ss = SMOTE(random_state=55,sampling_strategy=sample)\n",
    "        X_train_ss, y_train_ss = sm_ss.fit_sample(dict_df_X_train[hosp], dict_df_y_train[hosp])\n",
    "        \n",
    "        model = LogisticRegression(C=reg_strength).fit(X_train_ss, y_train_ss)\n",
    "        print(model)\n",
    "        print(f\"{hosp} Training set with {sample} SMOTE log reg score: {model.score(X_train_ss, y_train_ss)}\")\n",
    "        print(f\"{hosp} Test set with {sample} SMOTE log reg score: {model.score(dict_df_X_test[hosp], dict_df_y_test[hosp])}\")\n",
    "\n",
    "        filename = file_dir + f'{hosp}_uc1_{sample}_smote_logreg_model.pkl'\n",
    "        pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "        y_pred = model.predict(dict_df_X_test[hosp])\n",
    "        print(hosp, 'log reg \\n', confusion_matrix(dict_df_y_test[hosp], y_pred))  \n",
    "        print(hosp, 'log reg \\n', classification_report(dict_df_y_test[hosp], y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAIVE BAYES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hosp in dict_df_X_train:\n",
    "    # Initiating the Gaussian Classifier\n",
    "    model = GaussianNB()\n",
    "\n",
    "    # Training your model \n",
    "    model.fit(dict_df_X_train[hosp], dict_df_y_train[hosp])\n",
    "    print(model)\n",
    "    filename = file_dir + f'{hosp}_uc1_no_smote_nb_model.pkl'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "    # Score\n",
    "    print(f\"{hosp} Training set without SMOTE Naive Bayes score: {model.score(dict_df_X_train[hosp], dict_df_y_train[hosp])}\")\n",
    "    print(f\"{hosp} Test set without SMOTE Naive Bayes score: {model.score(dict_df_X_test[hosp], dict_df_y_test[hosp])}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    y_pred = model.predict(dict_df_X_test[hosp])\n",
    "    print(hosp, 'Naive Bayes \\n', confusion_matrix(dict_df_y_test[hosp], y_pred))  \n",
    "    print(hosp, 'Naive Bayes \\n', classification_report(dict_df_y_test[hosp], y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes With SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Without SMOTE ss=0.1 ~ 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hosp in dict_df_X_train:\n",
    "    for sample in np.arange(0.1, 1.1, 0.1):\n",
    "        sm_ss = SMOTE(random_state=55,sampling_strategy=sample)\n",
    "        X_train_ss, y_train_ss = sm_ss.fit_sample(dict_df_X_train[hosp], dict_df_y_train[hosp])\n",
    "        \n",
    "        # Initiating the Gaussian Classifier\n",
    "        model = GaussianNB()\n",
    "        \n",
    "        # Training your model \n",
    "        model.fit(X_train_ss, y_train_ss)\n",
    "        print(model)\n",
    "        filename = file_dir + f'{hosp}_uc1_{sample}_smote_nb_model.pkl'\n",
    "        pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "        # Score\n",
    "        print(f\"{hosp} Training set with {sample} SMOTE Naive Bayes score: {model.score(X_train_ss, y_train_ss)}\")\n",
    "        print(f\"{hosp} Test set with {sample} SMOTE Naive Bayes score: {model.score(dict_df_X_test[hosp], dict_df_y_test[hosp])}\")\n",
    "\n",
    "        # Confusion Matrix\n",
    "        y_pred = model.predict(dict_df_X_test[hosp])\n",
    "        print(hosp, 'Naive Bayes\\n', confusion_matrix(dict_df_y_test[hosp], y_pred))  \n",
    "        print(hosp, 'Naive Bayes\\n', classification_report(dict_df_y_test[hosp], y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## NEURAL NET MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net MLP Without SMOTE, 2 Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier  \n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_hid_layers = [(128,128), (16,16,16), (32,32,32), (16,16,16,16), (32,32,32,32)]\n",
    "max_iter = 1000\n",
    "list_smote_sampling = [0.1, 0.2, 0.3, 0.5, 1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net MLPClassifier without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hosp in dict_df_X_train:\n",
    "    for hid_layers in list_hid_layers:\n",
    "        model = MLPClassifier(hidden_layer_sizes=hid_layers, max_iter=max_iter,verbose=1)  \n",
    "        model.fit(dict_df_X_train[hosp], dict_df_y_train[hosp])\n",
    "        print(model)\n",
    "        filename = file_dir + f'{hosp}_uc1_no_smote_mlp_{hid_layers}_model.pkl'\n",
    "        pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "        predictions = mlp.predict(dict_df_X_test[hosp]) \n",
    "\n",
    "        # Score\n",
    "        print(f\"{hosp} Training set without SMOTE mlp {hid_layers} score: {model.score(dict_df_X_train[hosp], dict_df_y_train[hosp])}\")\n",
    "        print(f\"{hosp} Test set without SMOTE mlp {hid_layers} score: {model.score(dict_df_X_test[hosp], dict_df_y_test[hosp])}\")\n",
    "\n",
    "        print(f\"{hosp} Accuracy without SMOTE mlp {hid_layers}: \", metrics.accuracy_score(dict_df_y_test[hosp], predictions))\n",
    "        print(hosp, f'mlp {hid_layers}\\n', confusion_matrix(dict_df_y_test[hosp],predictions))  \n",
    "        print(hosp, f'mlp {hid_layers}\\n', classification_report(dict_df_y_test[hosp],predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net With SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_hid_layers = [(16,16), (32,32), (64,64), (128,128), (256,256),\n",
    "                   (16,16,16), (32,32,32), (64,64,64),\n",
    "                   (16,16,16,16), (32,32,32,32)]\n",
    "max_iter = 1000\n",
    "list_smote_sampling = [0.1, 0.2, 0.3, 0.5, 1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net Layers With SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hosp in dict_df_X_train:\n",
    "    for hid_layers in list_hid_layers:\n",
    "        for sample in list_smote_sampling:\n",
    "            sm_ss = SMOTE(random_state=55,sampling_strategy=sample)\n",
    "            X_train_ss, y_train_ss = sm_ss.fit_sample(dict_df_X_train[hosp], dict_df_y_train[hosp])\n",
    "        \n",
    "            model = MLPClassifier(hidden_layer_sizes=hid_layers, max_iter=max_iter,verbose=1)  \n",
    "            model.fit(X_train_ss, y_train_ss)  \n",
    "            print(model)\n",
    "            filename = file_dir + f'{hosp}_uc1_{sample}_smote_mlp_{hid_layers}_model.pkl'\n",
    "            pickle.dump(model, open(filename, 'wb'))\n",
    "            \n",
    "            predictions = model.predict(dict_df_X_test[hosp]) \n",
    "\n",
    "            # Score\n",
    "            print(f\"{hosp} Training set {sample} SMOTE mlp {hid_layers} score: {model.score(X_train_ss, y_train_ss)}\")\n",
    "            print(f\"{hosp} Test set {sample} SMOTE mlp {hid_layers} score: {model.score(dict_df_X_test[hosp], dict_df_y_test[hosp])}\")\n",
    "\n",
    "            print(f\"{hosp} Accuracy: \", metrics.accuracy_score(dict_df_y_test[hosp], predictions))\n",
    "            print(hosp, f'mlp {hid_layers}\\n', confusion_matrix(dict_df_y_test[hosp],predictions))  \n",
    "            print(hosp, f'mlp {hid_layers}\\n', classification_report(dict_df_y_test[hosp],predictions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful when running this, about 2 full days are needed to run this!!!\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hosp in dict_df_X_train:\n",
    "    test_scores = []\n",
    "    train_scores = []\n",
    "\n",
    "    for i in range(1,15):\n",
    "\n",
    "        knn = KNeighborsClassifier(i)\n",
    "        knn.fit(dict_df_X_train[hosp],dict_df_y_train[hosp])\n",
    "\n",
    "        train_scores.append(knn.score(dict_df_X_train[hosp],dict_df_y_train[hosp]))\n",
    "        test_scores.append(knn.score(dict_df_X_test[hosp],dict_df_y_test[hosp]))\n",
    "\n",
    "    ## score that comes from testing on the same datapoints that were used for training\n",
    "    max_train_score = max(train_scores)\n",
    "    train_scores_ind = [i for i, v in enumerate(train_scores) if v == max_train_score]\n",
    "    print(f'{hosp} Max train score {max_train_score*100} % and k = {list(map(lambda x: x+1, train_scores_ind))}')\n",
    "\n",
    "    ## score that comes from testing on the datapoints that were split in the beginning to be used for testing solely\n",
    "    max_test_score = max(test_scores)\n",
    "    test_scores_ind = [i for i, v in enumerate(test_scores) if v == max_test_score]\n",
    "    print(f'{hosp} Max test score {max_test_score*100} % and k = {list(map(lambda x: x+1, test_scores_ind))}')\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.plot(range(1,15),train_scores,marker='*',label='Train Score')\n",
    "    plt.plot(range(1,15),test_scores,marker='o',label='Test Score')\n",
    "    plt.title(f'{hosp} KNN')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# From the above, the best KNN is at k=8\n",
    "#Setup a knn classifier with k neighbors\n",
    "best_knn = KNeighborsClassifier(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbours = 8\n",
    "for hosp in dict_df_X_train:\n",
    "    # Fit the KNN model with training data and score the test data\n",
    "    best_knn = KNeighborsClassifier(n_neighbours)\n",
    "    \n",
    "    best_knn.fit(dict_df_X_train[hosp],dict_df_y_train[hosp])\n",
    "    best_knn.score(dict_df_X_test[hosp],dict_df_y_test[hosp])\n",
    "    \n",
    "    # save the model to disk\n",
    "    filename = f'{hosp}_best_knn_without_smote.pkl'\n",
    "    pickle.dump(best_knn, open(filename, 'wb'))\n",
    "    \n",
    "    y_pred = best_knn.predict(dict_df_X_test[hosp])\n",
    "    # Score for Best KNN, No SMOTE\n",
    "    print(f\"{hosp} Training set without SMOTE KNN({n_neighbours}) score: {best_knn.score(dict_df_X_train[hosp], dict_df_y_train[hosp])}\")\n",
    "    print(f\"{hosp} Test set without SMOTE KNN({n_neighbours}) score: {best_knn.score(dict_df_X_test[hosp], dict_df_y_test[hosp])}\")\n",
    "\n",
    "    print(f\"{hosp} Accuracy without SMOTE KNN({n_neighbours}): {metrics.accuracy_score(dict_df_y_test[hosp], y_pred)}\")\n",
    "    print(hosp, f'KNN({n_neighbours})\\n', confusion_matrix(dict_df_y_test[hosp],y_pred))  \n",
    "    print(hosp, f'KNN({n_neighbours})\\n', classification_report(dict_df_y_test[hosp],y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN With SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN With SMOTE ss=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbours = 8\n",
    "list_smote_sampling = [0.1, 0.5, 1.0]\n",
    "for hosp in dict_df_X_train:\n",
    "    for sample in list_smote_sampling:\n",
    "        sm_ss = SMOTE(random_state=55,sampling_strategy=sample)\n",
    "        X_train_ss, y_train_ss = sm_ss.fit_sample(dict_df_X_train[hosp], dict_df_y_train[hosp])\n",
    "        \n",
    "        # Fit the KNN model with training data and score the test data\n",
    "        best_knn = KNeighborsClassifier(n_neighbours)    \n",
    "        best_knn.fit(X_train_ss,y_train_ss)\n",
    "        #best_knn.score(dict_df_X_test[hosp],dict_df_y_test[hosp])\n",
    "        \n",
    "        # save the model to disk\n",
    "        filename = f'{hosp}_best_knn_{sample}_smote.pkl'\n",
    "        pickle.dump(best_knn, open(filename, 'wb'))\n",
    "        \n",
    "        y_pred = best_knn.predict(dict_df_X_test[hosp])\n",
    "        # Score for Best KNN, with SMOTE\n",
    "        print(f\"{hosp} Training set {sample} SMOTE KNN({n_neighbours}) score: {best_knn.score(X_train_ss, y_train_ss)}\")\n",
    "        print(f\"{hosp} Test set {sample} SMOTE KNN({n_neighbours}) score: {best_knn.score(dict_df_X_test[hosp], dict_df_y_test[hosp])}\")\n",
    "\n",
    "        print(f\"{hosp} Accuracy {sample} SMOTE KNN({n_neighbours}): \", metrics.accuracy_score(dict_df_y_test[hosp], y_pred))\n",
    "        print(confusion_matrix(dict_df_y_test[hosp],y_pred))  \n",
    "        print(classification_report(dict_df_y_test[hosp],y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
