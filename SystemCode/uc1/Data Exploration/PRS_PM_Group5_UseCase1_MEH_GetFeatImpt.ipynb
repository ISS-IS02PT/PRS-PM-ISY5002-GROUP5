{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parkway Project Use Case 1: Write Off Cases Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Users\\mokky\\Documents\\GitHub\\nus-iss\\PRS-PM-ISY5002-GROUP5\\SystemCode\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('d:/Users/mokky/Documents/GitHub/nus-iss/PRS-PM-ISY5002-GROUP5/SystemCode')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_X_train_file_paths = {\n",
    "    'MEH' : ['./Data Exploration/data/MEH_data_X_train_0.pkl',\n",
    "             './Data Exploration/data/MEH_data_X_train_1.pkl',\n",
    "             './Data Exploration/data/MEH_data_X_train_2.pkl',\n",
    "             './Data Exploration/data/MEH_data_X_train_3.pkl',\n",
    "             './Data Exploration/data/MEH_data_X_train_4.pkl',\n",
    "             './Data Exploration/data/MEH_data_X_train_5.pkl',\n",
    "             './Data Exploration/data/MEH_data_X_train_6.pkl',\n",
    "             './Data Exploration/data/MEH_data_X_train_7.pkl',\n",
    "             './Data Exploration/data/MEH_data_X_train_8.pkl',\n",
    "             './Data Exploration/data/MEH_data_X_train_9.pkl']}\n",
    "dict_y_train_file_paths = {\n",
    "    'GHL' : './Data Exploration/data/GHL_data_y_train.pkl',\n",
    "    'MEH' : './Data Exploration/data/MEH_data_y_train.pkl',\n",
    "    'PEH' : './Data Exploration/data/PEH_data_y_train.pkl',\n",
    "    'PNH' : './Data Exploration/data/PNH_data_y_train.pkl'}\n",
    "dict_X_test_file_paths = {\n",
    "    'GHL' : ['./Data Exploration/data/GHL_data_X_test_0.pkl',\n",
    "             './Data Exploration/data/GHL_data_X_test_1.pkl',\n",
    "             './Data Exploration/data/GHL_data_X_test_2.pkl'],\n",
    "    'MEH' : ['./Data Exploration/data/MEH_data_X_test_0.pkl',\n",
    "             './Data Exploration/data/MEH_data_X_test_1.pkl',\n",
    "             './Data Exploration/data/MEH_data_X_test_2.pkl',\n",
    "             './Data Exploration/data/MEH_data_X_test_3.pkl'],\n",
    "    'PEH' : ['./Data Exploration/data/PEH_data_X_test_0.pkl'],\n",
    "    'PNH' : ['./Data Exploration/data/PNH_data_X_test_0.pkl',\n",
    "             './Data Exploration/data/PNH_data_X_test_1.pkl',\n",
    "             './Data Exploration/data/PNH_data_X_test_2.pkl']}\n",
    "dict_y_test_file_paths = {\n",
    "    'GHL' : './Data Exploration/data/GHL_data_y_test.pkl',\n",
    "    'MEH' : './Data Exploration/data/MEH_data_y_test.pkl',\n",
    "    'PEH' : './Data Exploration/data/PEH_data_y_test.pkl',\n",
    "    'PNH' : './Data Exploration/data/PNH_data_y_test.pkl'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train GHL (79672, 38885)\n",
      "X_train MEH (98296, 38885)\n",
      "X_train PEH (28604, 38885)\n",
      "X_train PNH (79336, 38885)\n",
      "y_train GHL (79672,)\n",
      "y_train MEH (98296,)\n",
      "y_train PEH (28604,)\n",
      "y_train PNH (79336,)\n",
      "X_test GHL (26557, 38885)\n",
      "X_test MEH (32766, 38885)\n",
      "X_test PEH (9534, 38885)\n",
      "X_test PNH (26445, 38885)\n",
      "y_test GHL (26557,)\n",
      "y_test MEH (32766,)\n",
      "y_test PEH (9534,)\n",
      "y_test PNH (26445,)\n"
     ]
    }
   ],
   "source": [
    "for hosp in dict_X_train_file_paths:\n",
    "    df_X_train = pd.concat([pd.read_pickle(file_path)\n",
    "                                  for file_path in dict_X_train_file_paths[hosp]])\n",
    "    print(f'X_train {hosp} {df_X_train.shape}')\n",
    "    \n",
    "for hosp in dict_y_train_file_paths:\n",
    "    df_y_train = pd.read_pickle(dict_y_train_file_paths[hosp])\n",
    "    print(f'y_train {hosp} {df_y_train.shape}')\n",
    "\n",
    "for hosp in dict_X_test_file_paths:\n",
    "    df_X_test = pd.concat([pd.read_pickle(file_path)\n",
    "                                  for file_path in dict_X_test_file_paths[hosp]])\n",
    "    print(f'X_test {hosp} {df_X_test.shape}')\n",
    "\n",
    "for hosp in dict_y_test_file_paths:\n",
    "    df_y_test = pd.read_pickle(dict_y_test_file_paths[hosp])\n",
    "    print(f'y_test {hosp} {df_y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train GHL (79672, 38885)\n",
      "y_train GHL (79672,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "impt_threshold = 0.0\n",
    "\n",
    "dict_forest_file_paths = {}\n",
    "dict_feat_impt_file_paths = {}\n",
    "dict_new_X_train_file_paths = {}\n",
    "dict_new_X_test_file_paths = {}\n",
    "for hosp in dict_X_train_file_paths:\n",
    "    save_folder_paths = os.path.dirname(dict_X_train_file_paths[hosp][0])\n",
    "    \n",
    "    df_X_train = pd.concat([pd.read_pickle(file_path)\n",
    "                            for file_path in dict_X_train_file_paths[hosp]])\n",
    "    print(f'X_train {hosp} {df_X_train.shape}')\n",
    "    \n",
    "    df_y_train = pd.read_pickle(dict_y_train_file_paths[hosp])\n",
    "    print(f'y_train {hosp} {df_y_train.shape}')\n",
    "    \n",
    "    # forest\n",
    "    forest = RandomForestRegressor(random_state=42)\n",
    "    forest.fit(df_X_train, df_y_train)\n",
    "    \n",
    "    forest_pkl_file_path = f'{save_folder_paths}/{hosp}_forest_model_uc1.pkl'\n",
    "    with open(forest_pkl_file_path, 'wb') as file:\n",
    "        pickle.dump(forest, file)\n",
    "    dict_forest_file_paths[hosp] = forest_pkl_file_path\n",
    "    \n",
    "    # feature importance\n",
    "    print(f'{sum(forest.feature_importances_ > impt_threshold)} / {len(forest.feature_importances_)}')\n",
    "    feature_importance_file_path = f'{save_folder_paths}/{hosp}_forest_feat_impt_uc1.npy'\n",
    "    np.save(feature_importance_file_path, forest.feature_importances_ > impt_threshold)\n",
    "    dict_feat_impt_file_paths[hosp] = feature_importance_file_path\n",
    "    \n",
    "    # new training files\n",
    "    df_train_new_X = df_X_train.loc[:, forest.feature_importances_ > impt_threshold]\n",
    "    print(df_train_new_X.shape)\n",
    "    new_X_train_pkl_file_path = f'{save_dir}/{hosp}_new_train_X_uc1.pkl'\n",
    "    df_train_new_X.to_pickle(new_X_train_pkl_file_path)\n",
    "    dict_new_X_train_file_paths[hosp] = new_X_train_pkl_file_path\n",
    "    \n",
    "    # new test files\n",
    "    df_test_new_X = df_X_test.loc[:, forest.feature_importances_ > impt_threshold]\n",
    "    print(df_test_new_X.shape)\n",
    "    new_X_test_pkl_file_path = f'{save_dir}/{hosp}_new_test_X_uc1.pkl'\n",
    "    df_test_new_X.to_pickle(new_X_test_pkl_file_path)\n",
    "    dict_new_X_test_file_paths[hosp] = new_X_test_pkl_file_path\n",
    "\n",
    "print('forest:\\n', dict_forest_file_paths)\n",
    "print('feature importance:\\n', dict_feat_impt_file_paths)\n",
    "print('New X_train:\\n', dict_new_X_train_file_paths)\n",
    "print('New X_test:\\n', dict_new_X_test_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
