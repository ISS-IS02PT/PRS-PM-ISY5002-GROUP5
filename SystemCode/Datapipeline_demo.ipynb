{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.8 64-bit ('base': conda)",
   "display_name": "Python 3.7.8 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a31f979fd7ec5616a47c88a389106f065111c8af2b950adc2b080f56172a5b7a"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datapipeline import Datapipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpl = Datapipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_hosp_filepaths = {\n",
    "    'GHL': './Data Exploration/data/GHL_data.h5',\n",
    "    'MEH': './Data Exploration/data/MEH_data.h5',\n",
    "    'PEH': './Data Exploration/data/PEH_data.h5',\n",
    "    'PNH': './Data Exploration/data/PNH_data.h5'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'GHL': './Data Exploration/data/GHL_data.pkl', 'MEH': './Data Exploration/data/MEH_data.pkl', 'PEH': './Data Exploration/data/PEH_data.pkl', 'PNH': './Data Exploration/data/PNH_data.pkl'}\n"
     ]
    }
   ],
   "source": [
    "raw_data_path = './Data Exploration/data/ParkwaySampleDataForProject_09_withTOSP3.xlsx'\n",
    "dict_hosp_filepaths = dpl.transform_raw_data(raw_data_path)\n",
    "print(dict_hosp_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GHL 106229\n",
      "MEH 131062\n",
      "PEH 38138\n",
      "PNH 105781\n"
     ]
    }
   ],
   "source": [
    "dict_hosp_df = {}\n",
    "for hosp in dict_hosp_filepaths:\n",
    "    dict_hosp_df[hosp] = pd.read_pickle(dict_hosp_filepaths[hosp])\n",
    "    print(hosp, len(dict_hosp_df[hosp]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 131062 entries, 2016063345 to 2019131221\nData columns (total 45 columns):\n #   Column              Non-Null Count   Dtype  \n---  ------              --------------   -----  \n 0   TOTAL_PAID_AMT      131062 non-null  float64\n 1   PAYER_CODE_1        131062 non-null  object \n 2   PAYER_1_PAID_AMT    131062 non-null  float64\n 3   PAYER_CODE_2        131062 non-null  object \n 4   PAYER_2_PAID_AMT    131062 non-null  float64\n 5   PAYER_CODE_3        131062 non-null  object \n 6   PAYER_3_PAID_AMT    131062 non-null  float64\n 7   PAYER_CODE_4        131062 non-null  object \n 8   PAYER_4_PAID_AMT    131062 non-null  float64\n 9   PAYER_CODE_5        131062 non-null  object \n 10  PAYER_5_PAID_AMT    131062 non-null  float64\n 11  BED_TYPE            131062 non-null  object \n 12  REFERRAL_TYPE       131062 non-null  object \n 13  TREATMENT_CATEGORY  131062 non-null  object \n 14  ADMISSION_TYPE      131062 non-null  object \n 15  DISCHARGE_TYPE      131062 non-null  int64  \n 16  LOS_DAYS            131062 non-null  int64  \n 17  DOCTOR_CODE         131062 non-null  object \n 18  SPECIALTY_CODE      131062 non-null  object \n 19  SPECIALTY_GRP       131062 non-null  object \n 20  TOSP_COUNT          131062 non-null  int64  \n 21  TOSP_CODE1          131062 non-null  object \n 22  TOSP_CODE2          131062 non-null  object \n 23  TOSP_CODE3          131062 non-null  object \n 24  TOSP_CODE4          131062 non-null  object \n 25  NATIONALITY         131062 non-null  object \n 26  NONRESID_FLAG       131062 non-null  int32  \n 27  GENDER              131062 non-null  object \n 28  DECEASED_FLAG       131062 non-null  int32  \n 29  MARITAL_STATUS      131062 non-null  object \n 30  RELIGION            131062 non-null  object \n 31  VIP_FLAG            131062 non-null  int32  \n 32  RACE                131062 non-null  object \n 33  PACKAGE_PRICE       131062 non-null  float64\n 34  PACKAGE_EXCL        131062 non-null  float64\n 35  PACKAGE_ADJ         131062 non-null  float64\n 36  PACKAGE_CODE1       131062 non-null  object \n 37  PACKAGE_CODE2       131062 non-null  object \n 38  ICD_CODE1           131062 non-null  object \n 39  ICD_CODE2           131062 non-null  object \n 40  ICD_CODE3           131062 non-null  object \n 41  PROF_FEE            131062 non-null  float64\n 42  TOTAL_FEES          131062 non-null  float64\n 43  WRITE_OFF           131062 non-null  float64\n 44  Admission_Age       131062 non-null  int64  \ndtypes: float64(12), int32(3), int64(4), object(26)\nmemory usage: 44.5+ MB\nNone\n"
     ]
    }
   ],
   "source": [
    "for hosp in dict_hosp_df:\n",
    "    df = dict_hosp_df[hosp]\n",
    "    print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(98296, 45) (32766, 45)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 98296 entries, 2016063345 to 2019131221\n",
      "Data columns (total 45 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   TOTAL_PAID_AMT      98296 non-null  float64\n",
      " 1   PAYER_CODE_1        98296 non-null  object \n",
      " 2   PAYER_1_PAID_AMT    98296 non-null  float64\n",
      " 3   PAYER_CODE_2        98296 non-null  object \n",
      " 4   PAYER_2_PAID_AMT    98296 non-null  float64\n",
      " 5   PAYER_CODE_3        98296 non-null  object \n",
      " 6   PAYER_3_PAID_AMT    98296 non-null  float64\n",
      " 7   PAYER_CODE_4        98296 non-null  object \n",
      " 8   PAYER_4_PAID_AMT    98296 non-null  float64\n",
      " 9   PAYER_CODE_5        98296 non-null  object \n",
      " 10  PAYER_5_PAID_AMT    98296 non-null  float64\n",
      " 11  BED_TYPE            98296 non-null  object \n",
      " 12  REFERRAL_TYPE       98296 non-null  object \n",
      " 13  TREATMENT_CATEGORY  98296 non-null  object \n",
      " 14  ADMISSION_TYPE      98296 non-null  object \n",
      " 15  DISCHARGE_TYPE      98296 non-null  int64  \n",
      " 16  LOS_DAYS            98296 non-null  int64  \n",
      " 17  DOCTOR_CODE         98296 non-null  object \n",
      " 18  SPECIALTY_CODE      98296 non-null  object \n",
      " 19  SPECIALTY_GRP       98296 non-null  object \n",
      " 20  TOSP_COUNT          98296 non-null  int64  \n",
      " 21  TOSP_CODE1          98296 non-null  object \n",
      " 22  TOSP_CODE2          98296 non-null  object \n",
      " 23  TOSP_CODE3          98296 non-null  object \n",
      " 24  TOSP_CODE4          98296 non-null  object \n",
      " 25  NATIONALITY         98296 non-null  object \n",
      " 26  NONRESID_FLAG       98296 non-null  int32  \n",
      " 27  GENDER              98296 non-null  object \n",
      " 28  DECEASED_FLAG       98296 non-null  int32  \n",
      " 29  MARITAL_STATUS      98296 non-null  object \n",
      " 30  RELIGION            98296 non-null  object \n",
      " 31  VIP_FLAG            98296 non-null  int32  \n",
      " 32  RACE                98296 non-null  object \n",
      " 33  PACKAGE_PRICE       98296 non-null  float64\n",
      " 34  PACKAGE_EXCL        98296 non-null  float64\n",
      " 35  PACKAGE_ADJ         98296 non-null  float64\n",
      " 36  PACKAGE_CODE1       98296 non-null  object \n",
      " 37  PACKAGE_CODE2       98296 non-null  object \n",
      " 38  ICD_CODE1           98296 non-null  object \n",
      " 39  ICD_CODE2           98296 non-null  object \n",
      " 40  ICD_CODE3           98296 non-null  object \n",
      " 41  PROF_FEE            98296 non-null  float64\n",
      " 42  TOTAL_FEES          98296 non-null  float64\n",
      " 43  WRITE_OFF           98296 non-null  float64\n",
      " 44  Admission_Age       98296 non-null  int64  \n",
      "dtypes: float64(12), int32(3), int64(4), object(26)\n",
      "memory usage: 33.4+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32766 entries, 2016078293 to 2019131213\n",
      "Data columns (total 45 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   TOTAL_PAID_AMT      32766 non-null  float64\n",
      " 1   PAYER_CODE_1        32766 non-null  object \n",
      " 2   PAYER_1_PAID_AMT    32766 non-null  float64\n",
      " 3   PAYER_CODE_2        32766 non-null  object \n",
      " 4   PAYER_2_PAID_AMT    32766 non-null  float64\n",
      " 5   PAYER_CODE_3        32766 non-null  object \n",
      " 6   PAYER_3_PAID_AMT    32766 non-null  float64\n",
      " 7   PAYER_CODE_4        32766 non-null  object \n",
      " 8   PAYER_4_PAID_AMT    32766 non-null  float64\n",
      " 9   PAYER_CODE_5        32766 non-null  object \n",
      " 10  PAYER_5_PAID_AMT    32766 non-null  float64\n",
      " 11  BED_TYPE            32766 non-null  object \n",
      " 12  REFERRAL_TYPE       32766 non-null  object \n",
      " 13  TREATMENT_CATEGORY  32766 non-null  object \n",
      " 14  ADMISSION_TYPE      32766 non-null  object \n",
      " 15  DISCHARGE_TYPE      32766 non-null  int64  \n",
      " 16  LOS_DAYS            32766 non-null  int64  \n",
      " 17  DOCTOR_CODE         32766 non-null  object \n",
      " 18  SPECIALTY_CODE      32766 non-null  object \n",
      " 19  SPECIALTY_GRP       32766 non-null  object \n",
      " 20  TOSP_COUNT          32766 non-null  int64  \n",
      " 21  TOSP_CODE1          32766 non-null  object \n",
      " 22  TOSP_CODE2          32766 non-null  object \n",
      " 23  TOSP_CODE3          32766 non-null  object \n",
      " 24  TOSP_CODE4          32766 non-null  object \n",
      " 25  NATIONALITY         32766 non-null  object \n",
      " 26  NONRESID_FLAG       32766 non-null  int32  \n",
      " 27  GENDER              32766 non-null  object \n",
      " 28  DECEASED_FLAG       32766 non-null  int32  \n",
      " 29  MARITAL_STATUS      32766 non-null  object \n",
      " 30  RELIGION            32766 non-null  object \n",
      " 31  VIP_FLAG            32766 non-null  int32  \n",
      " 32  RACE                32766 non-null  object \n",
      " 33  PACKAGE_PRICE       32766 non-null  float64\n",
      " 34  PACKAGE_EXCL        32766 non-null  float64\n",
      " 35  PACKAGE_ADJ         32766 non-null  float64\n",
      " 36  PACKAGE_CODE1       32766 non-null  object \n",
      " 37  PACKAGE_CODE2       32766 non-null  object \n",
      " 38  ICD_CODE1           32766 non-null  object \n",
      " 39  ICD_CODE2           32766 non-null  object \n",
      " 40  ICD_CODE3           32766 non-null  object \n",
      " 41  PROF_FEE            32766 non-null  float64\n",
      " 42  TOTAL_FEES          32766 non-null  float64\n",
      " 43  WRITE_OFF           32766 non-null  float64\n",
      " 44  Admission_Age       32766 non-null  int64  \n",
      "dtypes: float64(12), int32(3), int64(4), object(26)\n",
      "memory usage: 11.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dict_df_train = {}\n",
    "dict_df_test = {}\n",
    "for hosp in dict_hosp_df:\n",
    "    df_train, df_test = dpl.train_test_split(df[hosp], random_state=0)\n",
    "    dict_df_train[hosp] = df_train\n",
    "    dict_df_test[hosp] = df_test\n",
    "    print(df_train.shape, df_test.shape)\n",
    "    print(df_train.info())\n",
    "    print(df_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'GHL': './Data Exploration/data/GHL_data.pkl',\n",
       " 'MEH': './Data Exploration/data/MEH_data.pkl',\n",
       " 'PEH': './Data Exploration/data/PEH_data.pkl',\n",
       " 'PNH': './Data Exploration/data/PNH_data.pkl'}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "dict_hosp_filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['TOTAL_PAID_AMT', 'PAYER_CODE_1', 'PAYER_1_PAID_AMT', 'PAYER_CODE_2',\n",
       "       'PAYER_2_PAID_AMT', 'PAYER_CODE_3', 'PAYER_3_PAID_AMT', 'PAYER_CODE_4',\n",
       "       'PAYER_4_PAID_AMT', 'PAYER_CODE_5', 'PAYER_5_PAID_AMT', 'BED_TYPE',\n",
       "       'REFERRAL_TYPE', 'TREATMENT_CATEGORY', 'ADMISSION_TYPE',\n",
       "       'DISCHARGE_TYPE', 'LOS_DAYS', 'DOCTOR_CODE', 'SPECIALTY_CODE',\n",
       "       'SPECIALTY_GRP', 'TOSP_COUNT', 'TOSP_CODE1', 'TOSP_CODE2', 'TOSP_CODE3',\n",
       "       'TOSP_CODE4', 'NATIONALITY', 'NONRESID_FLAG', 'GENDER', 'DECEASED_FLAG',\n",
       "       'MARITAL_STATUS', 'RELIGION', 'VIP_FLAG', 'RACE', 'PACKAGE_PRICE',\n",
       "       'PACKAGE_EXCL', 'PACKAGE_ADJ', 'PACKAGE_CODE1', 'PACKAGE_CODE2',\n",
       "       'ICD_CODE1', 'ICD_CODE2', 'ICD_CODE3', 'PROF_FEE', 'TOTAL_FEES',\n",
       "       'WRITE_OFF', 'Admission_Age'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df_temp = pd.read_pickle(dict_hosp_filepaths['MEH'])\n",
    "df_temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 10000\n",
      "10000 20000\n",
      "20000 30000\n",
      "30000 40000\n",
      "40000 50000\n",
      "50000 60000\n",
      "60000 70000\n",
      "70000 80000\n",
      "80000 90000\n",
      "90000 100000\n",
      "['./Data Exploration/data/MEH_data_X_train_0.pkl', './Data Exploration/data/MEH_data_X_train_1.pkl', './Data Exploration/data/MEH_data_X_train_2.pkl', './Data Exploration/data/MEH_data_X_train_3.pkl', './Data Exploration/data/MEH_data_X_train_4.pkl', './Data Exploration/data/MEH_data_X_train_5.pkl', './Data Exploration/data/MEH_data_X_train_6.pkl', './Data Exploration/data/MEH_data_X_train_7.pkl', './Data Exploration/data/MEH_data_X_train_8.pkl', './Data Exploration/data/MEH_data_X_train_9.pkl']\n",
      "./Data Exploration/data/MEH_data_y_train.pkl\n"
     ]
    }
   ],
   "source": [
    "dict_X_train_file_paths = {}\n",
    "dict_y_train_file_paths = {}\n",
    "dict_X_test_file_paths = {}\n",
    "dict_y_test_file_paths = {}\n",
    "for hosp in dict_hosp_filepaths\n",
    "    X_train_file_paths, y_train_file_path, X_test_file_paths, y_test_file_path = dpl.transform_train_test_data(dict_hosp_filepaths[hosp])\n",
    "    dict_X_train_file_paths[hosp] = X_train_file_paths\n",
    "    dict_y_train_file_paths[hosp] = y_train_file_path\n",
    "    dict_X_test_file_paths[hosp] = X_test_file_paths\n",
    "    dict_y_test_file_paths[hosp] = y_test_file_path\n",
    "print(dict_X_train_file_paths)\n",
    "print(dict_y_train_file_paths)\n",
    "print(dict_X_test_file_paths)\n",
    "print(dict_y_test_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 98296 entries, 2016063345 to 2019131221\nColumns: 38885 entries, TOTAL_PAID_AMT to ICD_CODE3_Z992\ndtypes: float64(38885)\nmemory usage: 28.5 GB\nNone\n"
     ]
    }
   ],
   "source": [
    "dict_df_train_X = {}\n",
    "dict_save_folder_paths = {}\n",
    "for hosp in dict_X_train_file_paths:\n",
    "    dict_df_train_X[hosp] = pd.concat([\n",
    "        pd.read_pickle(X_train_file_path)\n",
    "        for X_train_file_path in dict_X_train_file_paths[hosp]])\n",
    "    dict_save_folder_paths[hosp] = os.path.dirname(dict_X_train_file_paths[hosp][0])\n",
    "    print('\\n', hosp)\n",
    "    print(df_train_X.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "for hosp in dict_df_train_X:\n",
    "    print(dict_df_train_X[hosp].select_dtypes(exclude='float64').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['TOTAL_PAID_AMT', 'PAYER_1_PAID_AMT', 'PAYER_2_PAID_AMT',\n",
       "       'PAYER_3_PAID_AMT', 'PAYER_4_PAID_AMT', 'PAYER_5_PAID_AMT',\n",
       "       'DISCHARGE_TYPE', 'LOS_DAYS', 'TOSP_COUNT', 'NONRESID_FLAG',\n",
       "       ...\n",
       "       'ICD_CODE3_Z969', 'ICD_CODE3_Z975', 'ICD_CODE3_Z978', 'ICD_CODE3_Z98',\n",
       "       'ICD_CODE3_Z980', 'ICD_CODE3_Z981', 'ICD_CODE3_Z982', 'ICD_CODE3_Z988',\n",
       "       'ICD_CODE3_Z990', 'ICD_CODE3_Z992'],\n",
       "      dtype='object', length=38885)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "for hosp in dict_df_train_X:\n",
    "    print(dict_df_train_X[hosp].select_dtypes(exclude='object').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(98296,)\n"
     ]
    }
   ],
   "source": [
    "dict_df_train_y = {}\n",
    "for hosp in dict_y_train_file_paths:\n",
    "    dict_df_train_y[hosp] = pd.read_pickle(dict_y_train_file_paths[hosp])\n",
    "    print('\\n', hosp)\n",
    "    print(df_train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_forest = {}\n",
    "dict_forest_file_path = {}\n",
    "for hosp in dict_df_train_X:\n",
    "    if hosp in dict_df_train_y:\n",
    "        forest = RandomForestRegressor(random_state=42)\n",
    "        forest.fit(dict_df_train_X[hosp], dict_df_train_y[hosp])\n",
    "        pkl_file_path = f'{dict_save_folder_paths[hosp]}/{hosp}_forest_model.pkl'\n",
    "        with open(pkl_file_path, 'wb') as file:\n",
    "            pickle.dump(forest, file)\n",
    "        dict_forest[hosp] = file_path\n",
    "print(dict_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "38885\n4975\n"
     ]
    }
   ],
   "source": [
    "for hosp in dict_forest:\n",
    "    print(len(forest.feature_importances_))\n",
    "    print(sum(forest.feature_importances_ > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(98296, 4975)\n"
     ]
    }
   ],
   "source": [
    "dict_new_train_X_file_path = {}\n",
    "for hosp in dict_df_train_X:\n",
    "    if hosp in dict_forest:\n",
    "        forest = pickle.load(open(dict_forest[hosp], 'rb'))\n",
    "        df_train_new_X = dict_df_train_X[hosp].loc[:, forest.feature_importances_ > 0]\n",
    "        pkl_file_path = f'{dict_save_folder_paths[hosp]}/{hosp}_new_train_X.pkl'\n",
    "        df_train_new_X.to_pickle(pkl_file_path)\n",
    "        dict_new_train_X_file_path[hosp] = pkl_file_path\n",
    "        print(df_train_new_X.shape)\n",
    "print(dict_new_train_X_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_new_test_X_file_path = {}\n",
    "for hosp in dict_X_test_file_paths:\n",
    "    df_test_X = pd.concat([\n",
    "        pd.read_pickle(X_test_file_path)\n",
    "        for X_test_file_path in dict_X_test_file_paths[hosp]])\n",
    "    save_dir = os.path.dirname(dict_X_test_file_paths[hosp][0])\n",
    "    if hosp in dict_forest:\n",
    "        df_test_new_X = df_test_X.loc[:, dict_forest[hosp].feature_importances_ > 0]\n",
    "        pkl_file_path = f'{save_dir}/{hosp}_new_test_X.pkl'\n",
    "        df_test_new_X.to_pickle(pkl_file_path)\n",
    "        dict_new_test_X_file_path[hosp] = pkl_file_path\n",
    "        print(df_test_new_X.shape)\n",
    "print(dict_new_test_X_file_path)"
   ]
  }
 ]
}